<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Docker | nyuusen blog</title>
<meta name="keywords" content="">
<meta name="description" content="概要
なんとなく触っているDockerを以下を題材にきちんと学ぶ。
入門 Docker
基礎編
Dockerとは

Dockerは任意のタイミングの状態（ランタイム・ライブラリ・コードのバージョン）を1つのスナップショットとして保存している
従来のVM型の仮想化は、物理レイヤの仮想化から行なっている

つまりVMには、


一方DockerはLinuxカーネルの機能を用いて1プロセスとして隔離された環境を実現している
なのでDockerの方が軽量でオーバーヘッドが少ない環境を実現できる
DockerはImmutable InfrastructureをDockerfileとイメージという機能で実現

任意の時点で確実に動作するスナップショット（何か変更する場合は新しく構築する）
かつてはサーバーへ変更を加えて実現するMutableなものだった
また、イメージにはバージョン情報がつくので、それを指定することでロールバックが可能になり、可用性が向上する


コンテナ自体は古くからある概念で、Dockerが流行ったのは「配布の容易性」がある（スナップショットを取得し配布を標準の機能として提供している）

VMとDocker

どちらも隔離された環境を提供する技術
VMはコンピュータ自体の抽象化（仮想化）するのに対し、Dockerはプロセス自体の抽象化（仮想化）を行う

この2つは競合するのではなく、むしろ共存する



VM

ハードウェアから上、ハードウェア・カーネル（OS）、ユーザースペースの低レイヤから仮想化を行う
例えばmacOS上でWindowsを動かすことが可能だったりして、非常に自由度が高い
仮想化の対象となる領域が広いためオーバーヘッドが大きくなる

Docker


Linuxカーネルの機能を用いた技術で、cgroup・namespace・Capabilityのような機能を組み合わせて実現している


VMとは異なり、ホストOSとリソースを共有し、効率的にホストOSのリソースを使うことができるので、高速化つ軽量な仮想化を実現している


Linuxカーネルとは？

OSの中核となる部分で、ハードウェアとアプリケーションの間を取り持つ橋渡し役
例えばファイルの読み書き・ネットワーク通信・メモリ管理・CPU割り当てなどの低レイヤ処理を全てカーネルが担っている
UbuntuやCentOSなどのディストリビューションは全てLinuxカーネルをベースにしている
カーネルが主に行なっているのは以下の4つ

プロセス管理：プロセスに対してCPU割り当て（今どのプロセスにCPU時間を割り当てるかをスケジュール・切り替え＝コンテキストスイッチ）
メモリ管理：アプリケーションへのメモリ割り当て（他のプロセスのメモリ領域を勝手にアクセスできないようにしたり、メモリ不足時はディスクにスワッピングしたり）
ファイルシステム管理：ファイル操作を仲介（実際にディスクを触るのはカーネルが行なっている）
ネットワーク管理：カーネルがパケット処理を行なっている





でもDockerfileでFROM句にubuntu:latestみたいな記述をしているよね&hellip;？

ホスト側のLinuxカーネルを使うのに、コンテナ側でOS指定が必要な理由は何？という話
結論、これはユーザースペースのOS環境を指定しているだけ
ユーザースペースというのは、コマンドやライブラリ（bashとか）

Distrolessとか軽量なOSイメージを指定すると、デフォルトのままではcurl等のコマンドがインストールされておらず使用できないのは、コンテナ側のユーザースペースを使っているため





Docker Image

イメージは、任意のタイミングのスナップショットとしての役割を持つ
ファイルシステムのスナップショットである

もっとシンプルに表現すると、OSの中身のフォルダ構造一式をZIP圧縮したようなもの
例えばubuntuイメージの中身は、ユーザースペース（ls /した時に見るような bin/,etc/,lib/等）のファイル・フォルダ一式が入っている（でもカーネル部分は含まない）


てっきりイメージ＝プロセスのスナップショットと理解していたけどそれは間違っていて、イメージ＝実行前のファイル群が正しい表現
イメージを指定するときの命名は&lt;イメージ名&gt;:&lt;タグ&gt;であり、&lt;タグ&gt;を省略するとlatestタグが自動的に付与される

レイヤー構造

Dockerイメージはレイヤーの積み重ね
RUNやCOPY毎に新しいレイヤが作られる
レイヤは読み取り専用で、キャッシュとして使い回せる
レイヤー構造である理由

キャッシュ：同じベースイメージなら、そのレイヤはpull済み
ストレージ節約：変更があった部分だけ新しいレイヤに保存

もし仮にレイヤ構造ではない場合はフルフルのものを保存しなければいけない


高速化：レイヤー単位でダウンロード・展開


docker pushすると以下のようなハッシュ値が表示されるが、これがまさにレイヤ構造（レイヤ単位で処理している）
  The push refers to repository [123456789012.dkr.ecr.us-east-1.amazonaws.com/myapp]
  d4f4f6a4b8c2: Pushed 
  7a0437f04f83: Pushed 
  8c662931926f: Pushed 
  ...

各レイヤのコンテンツハッシュ(SHA256)らしい

具体的にはそのレイヤの差分をtarアーカイブをgzipなりで圧縮→圧縮されたバイナリファイルをSHA256ハッシュ計算している




整理すると、Dockerイメージはファイルシステムのスナップショットであり、それはレイヤー構造になっている

以下のDockerfileを例に考えると、
  FROM ubuntu:latest
  RUN apt-get update
  RUN apt-get install -y curl

各行がレイヤとなっていて、そのレイヤで変更があったファイル群を持っているイメージ


この上に、Dockerはコンテナ起動した時に、書き込みできるレイヤを作っている


イメージとコンテナの違い

イメージ: 読み込み専用の複数のレイヤを重ねたもの
コンテナ: イメージに読み書き可能なレイヤを追加して起動したもの


参考リンク

レイヤ — Docker-docs-ja 24.0 ドキュメント
Dockerのまとめ - コンテナとイメージ編 #Docker - Qiita



Dockerfile

COPY

2つの引数を設定する

1つ目はホスト側のディレクトリ、2つ目はDocker側のディレクトリ


ホスト側のディレクトリは docker build . で指定したディレクトリ

この場合 . を指定しており、カレントディレクトリが参照される


Docker側はデフォルトのパス、もしくは WORKDIR で定義されたディレクトリを参照する


EXPOSE

このポートを使いますよというドキュメント的な宣言


CMD

Dockerはここで設定したコマンドがフォアグラウンドで実行されている間が生存期間となる



RUN vs CMD

RUN:

イメージビルド時に実行される
レイヤとしてファイルシステムに反映されキャッシュが効く


CMD:

コンテナ起動時に実行される
イメージには反映せず、ただの実行時オプション



CMD vs ENTRYPOINT

CMDはデフォルト設定で、オーバーライド可能
一方、ENTRYPOINTは起動時に必ず実行される
テクニックとしてENTRYPOINTでコマンドを指定し、CMDで引数を指定するというのがある（引数だけ利用者側で指定可能となる）

基本的に CMD を使うのが良いでしょう。
ENTRYPOINT はDocker起動時のコマンドを強制します。
コマンドのラップをするDocker Image の場合は ENTRYPOINT のほうが好ましいですが、一般的なWebアプリケーションの場合は CMD を使用する方がユーザーにとって使いやすいDocker Image になります。
COPYは最後に実行するとキャッシュが効きやすい

Dockerfileの前段で、COPY . .を実行してしまうと、ローカル側のソースコードが1文字でも変わっていると、そのレイヤのキャッシュが効かなくなる
レイヤーのキャッシュは、親が変わると問答無用でキャッシュ無効化されるので、COPY . .以降は全てキャッシュが利用されなくなる（レイヤは差分を持っているようなものだから、親が変更があったら当然子にも影響あるよねということだと理解した）
なので、変更が頻繁にあるようなCOPY . .の処理は、Dockerfileの中で後ろの方に持っていくと良い
Nodeならpackage系だけを最初にコピーする→依存関係をインストール→ソースコードをコピーしてくるみたいな形で工夫できる

Container

イメージがスナップショットだとすると、そのスナップショットから起動したプロセスがコンテナ
コンテナは「1つのコマンド（プロセス）をフォアグラウンドで動かす」ように設計されている

コンテナは1つのコマンドを隔離された環境で実行し、そのコマンドの実行がフォアグラウンドで終了するまで生存する
ライフサイクル

Image &ndash; (docker run &lt;$IMAGE&gt;) &ndash;&gt; RUNNING &ndash; STOPPED &ndash; DELETED
正常終了 or 異常終了 or docker killするとSTOPPED
docker rmするとDELETED
pauseすると停止状態を表すPAUSEDにもなる




プロセスの隔離

コンテナ内のプロセスはホストマシンや他のコンテナと隔離されて実行される
CMDもしくはENTRYPOINTで定義されたプロセスはPID 1となる



Network

Dockerではネットワークの扱いが重要となる
1コンテナでは1プロセスを動かす設計となっている
nginxとphp-fpmのように複数プロセスを協調して動かす必要があるときはソケットではなく、ネットワークで通信を行うことが推奨されている
Dockerでのネットワークは特にKubernetes・ECS・docker-composeのような各種オーケストレーションツールを使用する際に意識する必要がある

Driverの種類

ネットワークドライバーはネットワークの振る舞いの定義で、デフォルトでは2種類ある
複数のコンテナ（プロセス）はネットワークを介して通信を行う

bridge

基本的にはこれ
コンテナごとに仮想IPが割り振られ、同じネットワークに属するコンテナ間で通信が可能
こうすることでコンテナ同士はコンテナ名で互いに名前解決して通信できる
少し深掘りすると..

何も指定せずにコンテナ起動すると、docker0という名前のbridgeネットワークに所属する

docker0というのははホストOS上に仮想ブリッジという仮想スイッチ
hostネットワーク &ndash; docker0（仮想ブリッジ） &ndash; コンテナA, B&hellip;という構成
この構成では、各コンテナに独立した仮想ネットワーク内のIPが与えられ、同じネットワークにいるコンテナ間はIPやホスト名で通信できる
コンテナに対し、外部からアクセスしたい場合はNAT変換によるポートフォワードが必要(ex: docker run -p 8080:80 nginx)


Linuxカーネルのbridgeネットワークを使用する



host

コンテナがホストのIPアドレスとポート空間（ネットワーク名前空間）をそのまま使う

仮想NICやブリッジを介さずに、直接ホストのIP・ポート空間にアクセスできる
例：コンテナが80番でListenすると、それはホスト側の80番ポートを使うことになる


オーバーヘッドが少ない分通信が速いが、ポートの競合に注意する必要がある
ホスト側のlocalhost:80等でそのままコンテナにアクセスできるような仕組み

none

コンテナにネットワークを割り当てない
セキュリティ上、外部から完全に切り離したい時に使う

Docker Composeにおけるネットワークの考え方

Docker Composeはマルチコンテナを簡単に定義・管理できるツール
内部ネットワークは自動で作成される
各サービスは、自動で同じカスタムネットワークに所属するので、互いにサービス名で名前解決が可能となる（内部DNSによって解決されている）

Volume

データを永続化するための機能
Dockerコンテナは基本的にはエフェメラル（短命）なもので、ライフサイクルの終了とともにコンテナ上で作成されたファイルは消失する
ボリュームタイプには以下の2種類がある

Data Volume

コンテナのライフサイクルの外で管理されるファイル/ディレクトリの設定
-v &lt;CONTAINER PATH&gt; or -v &lt;HOST PATH&gt;:&lt;CONTAINER PATH&gt;
コンテナの外側＝ホスト側にファイルが保管される

Data Volume Container

他のコンテナで指定されているボリュームを参照するための機能（コンテナ間でボリュームを共有する）
--volumes-fromでコンテナ名を指定することで、別のコンテナのボリュームを参照できる
今の時代では、Named Volume(-v mydata:data)や上記のData VolumeのBind Mount(-v &lt;HOST PATH&gt;:&lt;CONTAINER PATH&gt;)を使用するケースが多そう

Named Volumeの補足として、Linuxの場合は大抵/var/lib/docker/volumes/mydata/_data/に保存される



プロダクションでの活用Tips
セキュリティ

rootユーザーを使わない
野良のイメージをベースイメージにしない
ビルド時に機微情報を与えない

ビルド時にパスワードや秘密鍵のような機微情報を与え、最終イメージに残らないようにする
ビルド後に環境変数として渡すことがベストプラクティス
もし仮にプライベートリポジトリをクローンするなどをしたい場合、&ndash;secretや&ndash;sshオプションを使用する(シークレット情報を格納したファイルを渡すイメージ)ことで、ビルド時に一時的にファイルにアクセスし、最終的なイメージには残らないようにセキュアなビルドを行うようにする

この方法がなぜイメージに残らないのかというと、一時的なマウント(仮想的なtmpfs)としてビルド中のコンテナに提供されるだけであり、COPYやRUNコマンドで明示的に保存しない限り、イメージのレイヤーには一切含まれないため
逆に1行の中でRUN echo &ldquo;secret&rdquo; &gt; /tmp/hoge.txt &amp;&amp; rm -f /tmp/hoge.txtなどとまとめれば、レイヤーのスナップショットには残らない

これを2行に分けてしまうとRUN echo &ldquo;secret&rdquo; &gt; /tmp/hoge.txtのみキャッシュが効いてしまい、最終イメージにファイルがそのまま残ってしまう






.dockerignoreファイルでローカルの不要なパスを無視する

.envのようなDBへの接続情報が記載されているようなファイルをビルドに含めないように、.dockerignoreを管理する（そうすればビルド時に無視される）

具体的には、Dockerクライアントはdocker build実行時にビルドコンテキスト全体をDockerデーモンに送るが、.dockerignoreで指定されたものは転送対象から除外される（COPYコマンドでも同じ）


まぁそもそも.envに直接ベタでセキュアな情報を残すのも良くないとは思うが（ローカルでは必要ないはずだし、クラウド環境の秘匿情報はクラウド上の適した場所＝AWSならSecretsManager等に保存するべきはずだし..）


イメージを塩漬けにしない

ECRのイメージスキャンやDependabot Security Update等を活用したら良さそう
GitHub ActionsでDocker社公式のdocker/scout-actionというCVEベースの脆弱性検知を行ってくれるみたい
Dockerfileでマルチステージビルドを行い、Dockerfile内でセキュリティツールを実行する
Snykをサイドカーとして動かしてリアルタイムでの自動検知


ファイルのマウントが必要な場合は最小限にする

ホストのファイルをマウントする場合はRead-Onlyなど権限は必要最低限にする
特にdockerソケット(/var/run/docker.sock)の扱いは注意

dockerソケットとは、Dockerデーモンが提供するUNIXソケットファイル
このソケットを通じて、docker buildやrunなどのCLIコマンドはデーモンと通信している（つまりDocker APIの入口）

ホストファイルシステムの改ざん（削除して破壊等）やホストネットワークの操作・盗聴などなど


ただ、CIや監視などでdockerソケットのマウントを要求するツールはあるので、その場合はRead-Onlyでマウントするようにする





マルチステージビルド

イメージのサイズが大きいとPullに時間がかかってしまい、リードタイムが長くなる
リードタイムが長くなると、

デプロイ・ロールバックが遅くなる
スケールアウトが遅くなり、コンテナ起動が間に合わず、リクエストを捌けなくなる
レジストリの保存料が高くなる



イメージの仕組みと設計

DockerイメージはDockerfileによって作成されるスナップショットであり、そのDockerイメージをもとに起動するのがコンテナ
1コンテナ1プロセスの原則

なぜ1コンテナ1プロセスが良いか？

可観測性

プロセス単位でメトリクスやログ収集がしやすい


責務の明確化

まぁ責務は明確にして分離すべきという話


リソース制御

CPUやメモリの利用量をプロセス単位で制御できる


障害隔離性

複数のプロセスが同一コンテナにあると、一方のクラッシュがもう一方に影響しやすい




とは言っても、全てのケースで1コンテナ＝1プロセスといく訳ではないので、1つのコンテナにつき1つの責務を目安にすると良い


コンテナ設計の指針となるThe Twelve-Factor App

The Twelve-Factor App （日本語訳）


ファイルシステム

イメージはRead-Onlyで、その上にRead-Write可能なコンテナレイヤが立ち上がるのがイメージとコンテナの仕組み

下位コンポーネントがイメージ（Read-Only）、上位コンポーネントがコンテナ（Read-Write）




ステートレスなコンテナにする

コンテナは廃棄容易性に優れている反面、データの永続化を苦手としている
ステートを持たないことで特定の環境に依存せず、高い可搬性を実現できる


ログは標準出力に出す

ファイルに吐くとステートを持つことになる
標準出力に吐いて収集するようにする



Dockerfileのベストプラクティス

軽量なベースイメージを選択する

公式が提供するイメージは軽量なslimというタグがついたイメージが存在する
Google Cloudはdistrolessというシェルなどが入っていないシンプルで軽量なイメージを提供している
理想はdisrolessだが、シェルなどのツール群が入っていないのでまずはslimを使用するのがおすすめ
alpineイメージがおすすめできない理由

軽量ではあるが、alpineのベースOSの歴史的系異常扱いが非常に難しい
元々フロッピーディスクに入るような軽量なOSとして開発された軽量化に特化したもので、逆にそれ以外の非機能要件を満たせないことが多々ある
調べると色々出てくるけど、基本的には標準ライブラリが（一般的なLinuxディストリビューションと）異なるための互換性が弱いこととパフォーマンス面に懸念があることっぽい

参考: とりあえずでDockerイメージにAlpine Linuxを選択するのはやめましょうという話 - NIFTY engineering






.dockerignoreを使用する

Dockerビルド時に無視するファイル・ディレクトリを指定することができる
Dockerfile自体不要だし、node_modulesもイメージビルド時にインストールするから不要とかそんな感じ


ビルド時に複数のアーキテクチャに対応させる

Docker v19からbuildxというサブコマンドが増えた（ex: docker buildx build）
以下のようなコマンドで、複数アーキテクチャに対応可能
  $ docker buildx build \
  --load \
  --platform linux/amd64,linux/arm64 \
  -t multi-platform \
  .

本番とローカルでアーキテクチャが異なる場合に便利



自分で調べたこと
識別子
Dockerのイメージやコンテナを識別する時、結局何で識別するんだっけ？となりがちなのでまとめる。
ここでいう識別というのは「イメージを指定してコンテナ起動」とか「コンテナを指定して停止・削除する」とかその辺りを指してます。">
<meta name="author" content="nyuusen">
<link rel="canonical" href="http://localhost:1313/posts/docker/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/posts/docker/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="http://localhost:1313/posts/docker/">
  <meta property="og:site_name" content="nyuusen blog">
  <meta property="og:title" content="Docker">
  <meta property="og:description" content="概要 なんとなく触っているDockerを以下を題材にきちんと学ぶ。
入門 Docker
基礎編 Dockerとは Dockerは任意のタイミングの状態（ランタイム・ライブラリ・コードのバージョン）を1つのスナップショットとして保存している 従来のVM型の仮想化は、物理レイヤの仮想化から行なっている つまりVMには、 一方DockerはLinuxカーネルの機能を用いて1プロセスとして隔離された環境を実現している なのでDockerの方が軽量でオーバーヘッドが少ない環境を実現できる DockerはImmutable InfrastructureをDockerfileとイメージという機能で実現 任意の時点で確実に動作するスナップショット（何か変更する場合は新しく構築する） かつてはサーバーへ変更を加えて実現するMutableなものだった また、イメージにはバージョン情報がつくので、それを指定することでロールバックが可能になり、可用性が向上する コンテナ自体は古くからある概念で、Dockerが流行ったのは「配布の容易性」がある（スナップショットを取得し配布を標準の機能として提供している） VMとDocker どちらも隔離された環境を提供する技術 VMはコンピュータ自体の抽象化（仮想化）するのに対し、Dockerはプロセス自体の抽象化（仮想化）を行う この2つは競合するのではなく、むしろ共存する VM ハードウェアから上、ハードウェア・カーネル（OS）、ユーザースペースの低レイヤから仮想化を行う 例えばmacOS上でWindowsを動かすことが可能だったりして、非常に自由度が高い 仮想化の対象となる領域が広いためオーバーヘッドが大きくなる Docker Linuxカーネルの機能を用いた技術で、cgroup・namespace・Capabilityのような機能を組み合わせて実現している
VMとは異なり、ホストOSとリソースを共有し、効率的にホストOSのリソースを使うことができるので、高速化つ軽量な仮想化を実現している
Linuxカーネルとは？
OSの中核となる部分で、ハードウェアとアプリケーションの間を取り持つ橋渡し役 例えばファイルの読み書き・ネットワーク通信・メモリ管理・CPU割り当てなどの低レイヤ処理を全てカーネルが担っている UbuntuやCentOSなどのディストリビューションは全てLinuxカーネルをベースにしている カーネルが主に行なっているのは以下の4つ プロセス管理：プロセスに対してCPU割り当て（今どのプロセスにCPU時間を割り当てるかをスケジュール・切り替え＝コンテキストスイッチ） メモリ管理：アプリケーションへのメモリ割り当て（他のプロセスのメモリ領域を勝手にアクセスできないようにしたり、メモリ不足時はディスクにスワッピングしたり） ファイルシステム管理：ファイル操作を仲介（実際にディスクを触るのはカーネルが行なっている） ネットワーク管理：カーネルがパケット処理を行なっている でもDockerfileでFROM句にubuntu:latestみたいな記述をしているよね…？
ホスト側のLinuxカーネルを使うのに、コンテナ側でOS指定が必要な理由は何？という話 結論、これはユーザースペースのOS環境を指定しているだけ ユーザースペースというのは、コマンドやライブラリ（bashとか） Distrolessとか軽量なOSイメージを指定すると、デフォルトのままではcurl等のコマンドがインストールされておらず使用できないのは、コンテナ側のユーザースペースを使っているため Docker Image イメージは、任意のタイミングのスナップショットとしての役割を持つ ファイルシステムのスナップショットである もっとシンプルに表現すると、OSの中身のフォルダ構造一式をZIP圧縮したようなもの 例えばubuntuイメージの中身は、ユーザースペース（ls /した時に見るような bin/,etc/,lib/等）のファイル・フォルダ一式が入っている（でもカーネル部分は含まない） てっきりイメージ＝プロセスのスナップショットと理解していたけどそれは間違っていて、イメージ＝実行前のファイル群が正しい表現 イメージを指定するときの命名は&lt;イメージ名&gt;:&lt;タグ&gt;であり、&lt;タグ&gt;を省略するとlatestタグが自動的に付与される レイヤー構造 Dockerイメージはレイヤーの積み重ね RUNやCOPY毎に新しいレイヤが作られる レイヤは読み取り専用で、キャッシュとして使い回せる レイヤー構造である理由 キャッシュ：同じベースイメージなら、そのレイヤはpull済み ストレージ節約：変更があった部分だけ新しいレイヤに保存 もし仮にレイヤ構造ではない場合はフルフルのものを保存しなければいけない 高速化：レイヤー単位でダウンロード・展開 docker pushすると以下のようなハッシュ値が表示されるが、これがまさにレイヤ構造（レイヤ単位で処理している） The push refers to repository [123456789012.dkr.ecr.us-east-1.amazonaws.com/myapp] d4f4f6a4b8c2: Pushed 7a0437f04f83: Pushed 8c662931926f: Pushed ... 各レイヤのコンテンツハッシュ(SHA256)らしい 具体的にはそのレイヤの差分をtarアーカイブをgzipなりで圧縮→圧縮されたバイナリファイルをSHA256ハッシュ計算している 整理すると、Dockerイメージはファイルシステムのスナップショットであり、それはレイヤー構造になっている 以下のDockerfileを例に考えると、 FROM ubuntu:latest RUN apt-get update RUN apt-get install -y curl 各行がレイヤとなっていて、そのレイヤで変更があったファイル群を持っているイメージ この上に、Dockerはコンテナ起動した時に、書き込みできるレイヤを作っている イメージとコンテナの違い イメージ: 読み込み専用の複数のレイヤを重ねたもの コンテナ: イメージに読み書き可能なレイヤを追加して起動したもの 参考リンク レイヤ — Docker-docs-ja 24.0 ドキュメント Dockerのまとめ - コンテナとイメージ編 #Docker - Qiita Dockerfile COPY 2つの引数を設定する 1つ目はホスト側のディレクトリ、2つ目はDocker側のディレクトリ ホスト側のディレクトリは docker build . で指定したディレクトリ この場合 . を指定しており、カレントディレクトリが参照される Docker側はデフォルトのパス、もしくは WORKDIR で定義されたディレクトリを参照する EXPOSE このポートを使いますよというドキュメント的な宣言 CMD Dockerはここで設定したコマンドがフォアグラウンドで実行されている間が生存期間となる RUN vs CMD RUN: イメージビルド時に実行される レイヤとしてファイルシステムに反映されキャッシュが効く CMD: コンテナ起動時に実行される イメージには反映せず、ただの実行時オプション CMD vs ENTRYPOINT CMDはデフォルト設定で、オーバーライド可能 一方、ENTRYPOINTは起動時に必ず実行される テクニックとしてENTRYPOINTでコマンドを指定し、CMDで引数を指定するというのがある（引数だけ利用者側で指定可能となる） 基本的に CMD を使うのが良いでしょう。 ENTRYPOINT はDocker起動時のコマンドを強制します。 コマンドのラップをするDocker Image の場合は ENTRYPOINT のほうが好ましいですが、一般的なWebアプリケーションの場合は CMD を使用する方がユーザーにとって使いやすいDocker Image になります。 COPYは最後に実行するとキャッシュが効きやすい Dockerfileの前段で、COPY . .を実行してしまうと、ローカル側のソースコードが1文字でも変わっていると、そのレイヤのキャッシュが効かなくなる レイヤーのキャッシュは、親が変わると問答無用でキャッシュ無効化されるので、COPY . .以降は全てキャッシュが利用されなくなる（レイヤは差分を持っているようなものだから、親が変更があったら当然子にも影響あるよねということだと理解した） なので、変更が頻繁にあるようなCOPY . .の処理は、Dockerfileの中で後ろの方に持っていくと良い Nodeならpackage系だけを最初にコピーする→依存関係をインストール→ソースコードをコピーしてくるみたいな形で工夫できる Container イメージがスナップショットだとすると、そのスナップショットから起動したプロセスがコンテナ コンテナは「1つのコマンド（プロセス）をフォアグラウンドで動かす」ように設計されている コンテナは1つのコマンドを隔離された環境で実行し、そのコマンドの実行がフォアグラウンドで終了するまで生存する ライフサイクル Image – (docker run &lt;$IMAGE&gt;) –&gt; RUNNING – STOPPED – DELETED 正常終了 or 異常終了 or docker killするとSTOPPED docker rmするとDELETED pauseすると停止状態を表すPAUSEDにもなる プロセスの隔離 コンテナ内のプロセスはホストマシンや他のコンテナと隔離されて実行される CMDもしくはENTRYPOINTで定義されたプロセスはPID 1となる Network Dockerではネットワークの扱いが重要となる 1コンテナでは1プロセスを動かす設計となっている nginxとphp-fpmのように複数プロセスを協調して動かす必要があるときはソケットではなく、ネットワークで通信を行うことが推奨されている Dockerでのネットワークは特にKubernetes・ECS・docker-composeのような各種オーケストレーションツールを使用する際に意識する必要がある Driverの種類 ネットワークドライバーはネットワークの振る舞いの定義で、デフォルトでは2種類ある 複数のコンテナ（プロセス）はネットワークを介して通信を行う bridge 基本的にはこれ コンテナごとに仮想IPが割り振られ、同じネットワークに属するコンテナ間で通信が可能 こうすることでコンテナ同士はコンテナ名で互いに名前解決して通信できる 少し深掘りすると.. 何も指定せずにコンテナ起動すると、docker0という名前のbridgeネットワークに所属する docker0というのははホストOS上に仮想ブリッジという仮想スイッチ hostネットワーク – docker0（仮想ブリッジ） – コンテナA, B…という構成 この構成では、各コンテナに独立した仮想ネットワーク内のIPが与えられ、同じネットワークにいるコンテナ間はIPやホスト名で通信できる コンテナに対し、外部からアクセスしたい場合はNAT変換によるポートフォワードが必要(ex: docker run -p 8080:80 nginx) Linuxカーネルのbridgeネットワークを使用する host コンテナがホストのIPアドレスとポート空間（ネットワーク名前空間）をそのまま使う 仮想NICやブリッジを介さずに、直接ホストのIP・ポート空間にアクセスできる 例：コンテナが80番でListenすると、それはホスト側の80番ポートを使うことになる オーバーヘッドが少ない分通信が速いが、ポートの競合に注意する必要がある ホスト側のlocalhost:80等でそのままコンテナにアクセスできるような仕組み none コンテナにネットワークを割り当てない セキュリティ上、外部から完全に切り離したい時に使う Docker Composeにおけるネットワークの考え方 Docker Composeはマルチコンテナを簡単に定義・管理できるツール 内部ネットワークは自動で作成される 各サービスは、自動で同じカスタムネットワークに所属するので、互いにサービス名で名前解決が可能となる（内部DNSによって解決されている） Volume データを永続化するための機能 Dockerコンテナは基本的にはエフェメラル（短命）なもので、ライフサイクルの終了とともにコンテナ上で作成されたファイルは消失する ボリュームタイプには以下の2種類がある Data Volume コンテナのライフサイクルの外で管理されるファイル/ディレクトリの設定 -v &lt;CONTAINER PATH&gt; or -v &lt;HOST PATH&gt;:&lt;CONTAINER PATH&gt; コンテナの外側＝ホスト側にファイルが保管される Data Volume Container 他のコンテナで指定されているボリュームを参照するための機能（コンテナ間でボリュームを共有する） --volumes-fromでコンテナ名を指定することで、別のコンテナのボリュームを参照できる 今の時代では、Named Volume(-v mydata:data)や上記のData VolumeのBind Mount(-v &lt;HOST PATH&gt;:&lt;CONTAINER PATH&gt;)を使用するケースが多そう Named Volumeの補足として、Linuxの場合は大抵/var/lib/docker/volumes/mydata/_data/に保存される プロダクションでの活用Tips セキュリティ rootユーザーを使わない 野良のイメージをベースイメージにしない ビルド時に機微情報を与えない ビルド時にパスワードや秘密鍵のような機微情報を与え、最終イメージに残らないようにする ビルド後に環境変数として渡すことがベストプラクティス もし仮にプライベートリポジトリをクローンするなどをしたい場合、–secretや–sshオプションを使用する(シークレット情報を格納したファイルを渡すイメージ)ことで、ビルド時に一時的にファイルにアクセスし、最終的なイメージには残らないようにセキュアなビルドを行うようにする この方法がなぜイメージに残らないのかというと、一時的なマウント(仮想的なtmpfs)としてビルド中のコンテナに提供されるだけであり、COPYやRUNコマンドで明示的に保存しない限り、イメージのレイヤーには一切含まれないため 逆に1行の中でRUN echo “secret” &gt; /tmp/hoge.txt &amp;&amp; rm -f /tmp/hoge.txtなどとまとめれば、レイヤーのスナップショットには残らない これを2行に分けてしまうとRUN echo “secret” &gt; /tmp/hoge.txtのみキャッシュが効いてしまい、最終イメージにファイルがそのまま残ってしまう .dockerignoreファイルでローカルの不要なパスを無視する .envのようなDBへの接続情報が記載されているようなファイルをビルドに含めないように、.dockerignoreを管理する（そうすればビルド時に無視される） 具体的には、Dockerクライアントはdocker build実行時にビルドコンテキスト全体をDockerデーモンに送るが、.dockerignoreで指定されたものは転送対象から除外される（COPYコマンドでも同じ） まぁそもそも.envに直接ベタでセキュアな情報を残すのも良くないとは思うが（ローカルでは必要ないはずだし、クラウド環境の秘匿情報はクラウド上の適した場所＝AWSならSecretsManager等に保存するべきはずだし..） イメージを塩漬けにしない ECRのイメージスキャンやDependabot Security Update等を活用したら良さそう GitHub ActionsでDocker社公式のdocker/scout-actionというCVEベースの脆弱性検知を行ってくれるみたい Dockerfileでマルチステージビルドを行い、Dockerfile内でセキュリティツールを実行する Snykをサイドカーとして動かしてリアルタイムでの自動検知 ファイルのマウントが必要な場合は最小限にする ホストのファイルをマウントする場合はRead-Onlyなど権限は必要最低限にする 特にdockerソケット(/var/run/docker.sock)の扱いは注意 dockerソケットとは、Dockerデーモンが提供するUNIXソケットファイル このソケットを通じて、docker buildやrunなどのCLIコマンドはデーモンと通信している（つまりDocker APIの入口） ホストファイルシステムの改ざん（削除して破壊等）やホストネットワークの操作・盗聴などなど ただ、CIや監視などでdockerソケットのマウントを要求するツールはあるので、その場合はRead-Onlyでマウントするようにする マルチステージビルド イメージのサイズが大きいとPullに時間がかかってしまい、リードタイムが長くなる リードタイムが長くなると、 デプロイ・ロールバックが遅くなる スケールアウトが遅くなり、コンテナ起動が間に合わず、リクエストを捌けなくなる レジストリの保存料が高くなる イメージの仕組みと設計 DockerイメージはDockerfileによって作成されるスナップショットであり、そのDockerイメージをもとに起動するのがコンテナ 1コンテナ1プロセスの原則 なぜ1コンテナ1プロセスが良いか？ 可観測性 プロセス単位でメトリクスやログ収集がしやすい 責務の明確化 まぁ責務は明確にして分離すべきという話 リソース制御 CPUやメモリの利用量をプロセス単位で制御できる 障害隔離性 複数のプロセスが同一コンテナにあると、一方のクラッシュがもう一方に影響しやすい とは言っても、全てのケースで1コンテナ＝1プロセスといく訳ではないので、1つのコンテナにつき1つの責務を目安にすると良い コンテナ設計の指針となるThe Twelve-Factor App The Twelve-Factor App （日本語訳） ファイルシステム イメージはRead-Onlyで、その上にRead-Write可能なコンテナレイヤが立ち上がるのがイメージとコンテナの仕組み 下位コンポーネントがイメージ（Read-Only）、上位コンポーネントがコンテナ（Read-Write） ステートレスなコンテナにする コンテナは廃棄容易性に優れている反面、データの永続化を苦手としている ステートを持たないことで特定の環境に依存せず、高い可搬性を実現できる ログは標準出力に出す ファイルに吐くとステートを持つことになる 標準出力に吐いて収集するようにする Dockerfileのベストプラクティス 軽量なベースイメージを選択する 公式が提供するイメージは軽量なslimというタグがついたイメージが存在する Google Cloudはdistrolessというシェルなどが入っていないシンプルで軽量なイメージを提供している 理想はdisrolessだが、シェルなどのツール群が入っていないのでまずはslimを使用するのがおすすめ alpineイメージがおすすめできない理由 軽量ではあるが、alpineのベースOSの歴史的系異常扱いが非常に難しい 元々フロッピーディスクに入るような軽量なOSとして開発された軽量化に特化したもので、逆にそれ以外の非機能要件を満たせないことが多々ある 調べると色々出てくるけど、基本的には標準ライブラリが（一般的なLinuxディストリビューションと）異なるための互換性が弱いこととパフォーマンス面に懸念があることっぽい 参考: とりあえずでDockerイメージにAlpine Linuxを選択するのはやめましょうという話 - NIFTY engineering .dockerignoreを使用する Dockerビルド時に無視するファイル・ディレクトリを指定することができる Dockerfile自体不要だし、node_modulesもイメージビルド時にインストールするから不要とかそんな感じ ビルド時に複数のアーキテクチャに対応させる Docker v19からbuildxというサブコマンドが増えた（ex: docker buildx build） 以下のようなコマンドで、複数アーキテクチャに対応可能 $ docker buildx build \ --load \ --platform linux/amd64,linux/arm64 \ -t multi-platform \ . 本番とローカルでアーキテクチャが異なる場合に便利 自分で調べたこと 識別子 Dockerのイメージやコンテナを識別する時、結局何で識別するんだっけ？となりがちなのでまとめる。 ここでいう識別というのは「イメージを指定してコンテナ起動」とか「コンテナを指定して停止・削除する」とかその辺りを指してます。">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-06-18T11:40:43+09:00">
    <meta property="article:modified_time" content="2025-06-18T11:40:43+09:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Docker">
<meta name="twitter:description" content="概要
なんとなく触っているDockerを以下を題材にきちんと学ぶ。
入門 Docker
基礎編
Dockerとは

Dockerは任意のタイミングの状態（ランタイム・ライブラリ・コードのバージョン）を1つのスナップショットとして保存している
従来のVM型の仮想化は、物理レイヤの仮想化から行なっている

つまりVMには、


一方DockerはLinuxカーネルの機能を用いて1プロセスとして隔離された環境を実現している
なのでDockerの方が軽量でオーバーヘッドが少ない環境を実現できる
DockerはImmutable InfrastructureをDockerfileとイメージという機能で実現

任意の時点で確実に動作するスナップショット（何か変更する場合は新しく構築する）
かつてはサーバーへ変更を加えて実現するMutableなものだった
また、イメージにはバージョン情報がつくので、それを指定することでロールバックが可能になり、可用性が向上する


コンテナ自体は古くからある概念で、Dockerが流行ったのは「配布の容易性」がある（スナップショットを取得し配布を標準の機能として提供している）

VMとDocker

どちらも隔離された環境を提供する技術
VMはコンピュータ自体の抽象化（仮想化）するのに対し、Dockerはプロセス自体の抽象化（仮想化）を行う

この2つは競合するのではなく、むしろ共存する



VM

ハードウェアから上、ハードウェア・カーネル（OS）、ユーザースペースの低レイヤから仮想化を行う
例えばmacOS上でWindowsを動かすことが可能だったりして、非常に自由度が高い
仮想化の対象となる領域が広いためオーバーヘッドが大きくなる

Docker


Linuxカーネルの機能を用いた技術で、cgroup・namespace・Capabilityのような機能を組み合わせて実現している


VMとは異なり、ホストOSとリソースを共有し、効率的にホストOSのリソースを使うことができるので、高速化つ軽量な仮想化を実現している


Linuxカーネルとは？

OSの中核となる部分で、ハードウェアとアプリケーションの間を取り持つ橋渡し役
例えばファイルの読み書き・ネットワーク通信・メモリ管理・CPU割り当てなどの低レイヤ処理を全てカーネルが担っている
UbuntuやCentOSなどのディストリビューションは全てLinuxカーネルをベースにしている
カーネルが主に行なっているのは以下の4つ

プロセス管理：プロセスに対してCPU割り当て（今どのプロセスにCPU時間を割り当てるかをスケジュール・切り替え＝コンテキストスイッチ）
メモリ管理：アプリケーションへのメモリ割り当て（他のプロセスのメモリ領域を勝手にアクセスできないようにしたり、メモリ不足時はディスクにスワッピングしたり）
ファイルシステム管理：ファイル操作を仲介（実際にディスクを触るのはカーネルが行なっている）
ネットワーク管理：カーネルがパケット処理を行なっている





でもDockerfileでFROM句にubuntu:latestみたいな記述をしているよね&hellip;？

ホスト側のLinuxカーネルを使うのに、コンテナ側でOS指定が必要な理由は何？という話
結論、これはユーザースペースのOS環境を指定しているだけ
ユーザースペースというのは、コマンドやライブラリ（bashとか）

Distrolessとか軽量なOSイメージを指定すると、デフォルトのままではcurl等のコマンドがインストールされておらず使用できないのは、コンテナ側のユーザースペースを使っているため





Docker Image

イメージは、任意のタイミングのスナップショットとしての役割を持つ
ファイルシステムのスナップショットである

もっとシンプルに表現すると、OSの中身のフォルダ構造一式をZIP圧縮したようなもの
例えばubuntuイメージの中身は、ユーザースペース（ls /した時に見るような bin/,etc/,lib/等）のファイル・フォルダ一式が入っている（でもカーネル部分は含まない）


てっきりイメージ＝プロセスのスナップショットと理解していたけどそれは間違っていて、イメージ＝実行前のファイル群が正しい表現
イメージを指定するときの命名は&lt;イメージ名&gt;:&lt;タグ&gt;であり、&lt;タグ&gt;を省略するとlatestタグが自動的に付与される

レイヤー構造

Dockerイメージはレイヤーの積み重ね
RUNやCOPY毎に新しいレイヤが作られる
レイヤは読み取り専用で、キャッシュとして使い回せる
レイヤー構造である理由

キャッシュ：同じベースイメージなら、そのレイヤはpull済み
ストレージ節約：変更があった部分だけ新しいレイヤに保存

もし仮にレイヤ構造ではない場合はフルフルのものを保存しなければいけない


高速化：レイヤー単位でダウンロード・展開


docker pushすると以下のようなハッシュ値が表示されるが、これがまさにレイヤ構造（レイヤ単位で処理している）
  The push refers to repository [123456789012.dkr.ecr.us-east-1.amazonaws.com/myapp]
  d4f4f6a4b8c2: Pushed 
  7a0437f04f83: Pushed 
  8c662931926f: Pushed 
  ...

各レイヤのコンテンツハッシュ(SHA256)らしい

具体的にはそのレイヤの差分をtarアーカイブをgzipなりで圧縮→圧縮されたバイナリファイルをSHA256ハッシュ計算している




整理すると、Dockerイメージはファイルシステムのスナップショットであり、それはレイヤー構造になっている

以下のDockerfileを例に考えると、
  FROM ubuntu:latest
  RUN apt-get update
  RUN apt-get install -y curl

各行がレイヤとなっていて、そのレイヤで変更があったファイル群を持っているイメージ


この上に、Dockerはコンテナ起動した時に、書き込みできるレイヤを作っている


イメージとコンテナの違い

イメージ: 読み込み専用の複数のレイヤを重ねたもの
コンテナ: イメージに読み書き可能なレイヤを追加して起動したもの


参考リンク

レイヤ — Docker-docs-ja 24.0 ドキュメント
Dockerのまとめ - コンテナとイメージ編 #Docker - Qiita



Dockerfile

COPY

2つの引数を設定する

1つ目はホスト側のディレクトリ、2つ目はDocker側のディレクトリ


ホスト側のディレクトリは docker build . で指定したディレクトリ

この場合 . を指定しており、カレントディレクトリが参照される


Docker側はデフォルトのパス、もしくは WORKDIR で定義されたディレクトリを参照する


EXPOSE

このポートを使いますよというドキュメント的な宣言


CMD

Dockerはここで設定したコマンドがフォアグラウンドで実行されている間が生存期間となる



RUN vs CMD

RUN:

イメージビルド時に実行される
レイヤとしてファイルシステムに反映されキャッシュが効く


CMD:

コンテナ起動時に実行される
イメージには反映せず、ただの実行時オプション



CMD vs ENTRYPOINT

CMDはデフォルト設定で、オーバーライド可能
一方、ENTRYPOINTは起動時に必ず実行される
テクニックとしてENTRYPOINTでコマンドを指定し、CMDで引数を指定するというのがある（引数だけ利用者側で指定可能となる）

基本的に CMD を使うのが良いでしょう。
ENTRYPOINT はDocker起動時のコマンドを強制します。
コマンドのラップをするDocker Image の場合は ENTRYPOINT のほうが好ましいですが、一般的なWebアプリケーションの場合は CMD を使用する方がユーザーにとって使いやすいDocker Image になります。
COPYは最後に実行するとキャッシュが効きやすい

Dockerfileの前段で、COPY . .を実行してしまうと、ローカル側のソースコードが1文字でも変わっていると、そのレイヤのキャッシュが効かなくなる
レイヤーのキャッシュは、親が変わると問答無用でキャッシュ無効化されるので、COPY . .以降は全てキャッシュが利用されなくなる（レイヤは差分を持っているようなものだから、親が変更があったら当然子にも影響あるよねということだと理解した）
なので、変更が頻繁にあるようなCOPY . .の処理は、Dockerfileの中で後ろの方に持っていくと良い
Nodeならpackage系だけを最初にコピーする→依存関係をインストール→ソースコードをコピーしてくるみたいな形で工夫できる

Container

イメージがスナップショットだとすると、そのスナップショットから起動したプロセスがコンテナ
コンテナは「1つのコマンド（プロセス）をフォアグラウンドで動かす」ように設計されている

コンテナは1つのコマンドを隔離された環境で実行し、そのコマンドの実行がフォアグラウンドで終了するまで生存する
ライフサイクル

Image &ndash; (docker run &lt;$IMAGE&gt;) &ndash;&gt; RUNNING &ndash; STOPPED &ndash; DELETED
正常終了 or 異常終了 or docker killするとSTOPPED
docker rmするとDELETED
pauseすると停止状態を表すPAUSEDにもなる




プロセスの隔離

コンテナ内のプロセスはホストマシンや他のコンテナと隔離されて実行される
CMDもしくはENTRYPOINTで定義されたプロセスはPID 1となる



Network

Dockerではネットワークの扱いが重要となる
1コンテナでは1プロセスを動かす設計となっている
nginxとphp-fpmのように複数プロセスを協調して動かす必要があるときはソケットではなく、ネットワークで通信を行うことが推奨されている
Dockerでのネットワークは特にKubernetes・ECS・docker-composeのような各種オーケストレーションツールを使用する際に意識する必要がある

Driverの種類

ネットワークドライバーはネットワークの振る舞いの定義で、デフォルトでは2種類ある
複数のコンテナ（プロセス）はネットワークを介して通信を行う

bridge

基本的にはこれ
コンテナごとに仮想IPが割り振られ、同じネットワークに属するコンテナ間で通信が可能
こうすることでコンテナ同士はコンテナ名で互いに名前解決して通信できる
少し深掘りすると..

何も指定せずにコンテナ起動すると、docker0という名前のbridgeネットワークに所属する

docker0というのははホストOS上に仮想ブリッジという仮想スイッチ
hostネットワーク &ndash; docker0（仮想ブリッジ） &ndash; コンテナA, B&hellip;という構成
この構成では、各コンテナに独立した仮想ネットワーク内のIPが与えられ、同じネットワークにいるコンテナ間はIPやホスト名で通信できる
コンテナに対し、外部からアクセスしたい場合はNAT変換によるポートフォワードが必要(ex: docker run -p 8080:80 nginx)


Linuxカーネルのbridgeネットワークを使用する



host

コンテナがホストのIPアドレスとポート空間（ネットワーク名前空間）をそのまま使う

仮想NICやブリッジを介さずに、直接ホストのIP・ポート空間にアクセスできる
例：コンテナが80番でListenすると、それはホスト側の80番ポートを使うことになる


オーバーヘッドが少ない分通信が速いが、ポートの競合に注意する必要がある
ホスト側のlocalhost:80等でそのままコンテナにアクセスできるような仕組み

none

コンテナにネットワークを割り当てない
セキュリティ上、外部から完全に切り離したい時に使う

Docker Composeにおけるネットワークの考え方

Docker Composeはマルチコンテナを簡単に定義・管理できるツール
内部ネットワークは自動で作成される
各サービスは、自動で同じカスタムネットワークに所属するので、互いにサービス名で名前解決が可能となる（内部DNSによって解決されている）

Volume

データを永続化するための機能
Dockerコンテナは基本的にはエフェメラル（短命）なもので、ライフサイクルの終了とともにコンテナ上で作成されたファイルは消失する
ボリュームタイプには以下の2種類がある

Data Volume

コンテナのライフサイクルの外で管理されるファイル/ディレクトリの設定
-v &lt;CONTAINER PATH&gt; or -v &lt;HOST PATH&gt;:&lt;CONTAINER PATH&gt;
コンテナの外側＝ホスト側にファイルが保管される

Data Volume Container

他のコンテナで指定されているボリュームを参照するための機能（コンテナ間でボリュームを共有する）
--volumes-fromでコンテナ名を指定することで、別のコンテナのボリュームを参照できる
今の時代では、Named Volume(-v mydata:data)や上記のData VolumeのBind Mount(-v &lt;HOST PATH&gt;:&lt;CONTAINER PATH&gt;)を使用するケースが多そう

Named Volumeの補足として、Linuxの場合は大抵/var/lib/docker/volumes/mydata/_data/に保存される



プロダクションでの活用Tips
セキュリティ

rootユーザーを使わない
野良のイメージをベースイメージにしない
ビルド時に機微情報を与えない

ビルド時にパスワードや秘密鍵のような機微情報を与え、最終イメージに残らないようにする
ビルド後に環境変数として渡すことがベストプラクティス
もし仮にプライベートリポジトリをクローンするなどをしたい場合、&ndash;secretや&ndash;sshオプションを使用する(シークレット情報を格納したファイルを渡すイメージ)ことで、ビルド時に一時的にファイルにアクセスし、最終的なイメージには残らないようにセキュアなビルドを行うようにする

この方法がなぜイメージに残らないのかというと、一時的なマウント(仮想的なtmpfs)としてビルド中のコンテナに提供されるだけであり、COPYやRUNコマンドで明示的に保存しない限り、イメージのレイヤーには一切含まれないため
逆に1行の中でRUN echo &ldquo;secret&rdquo; &gt; /tmp/hoge.txt &amp;&amp; rm -f /tmp/hoge.txtなどとまとめれば、レイヤーのスナップショットには残らない

これを2行に分けてしまうとRUN echo &ldquo;secret&rdquo; &gt; /tmp/hoge.txtのみキャッシュが効いてしまい、最終イメージにファイルがそのまま残ってしまう






.dockerignoreファイルでローカルの不要なパスを無視する

.envのようなDBへの接続情報が記載されているようなファイルをビルドに含めないように、.dockerignoreを管理する（そうすればビルド時に無視される）

具体的には、Dockerクライアントはdocker build実行時にビルドコンテキスト全体をDockerデーモンに送るが、.dockerignoreで指定されたものは転送対象から除外される（COPYコマンドでも同じ）


まぁそもそも.envに直接ベタでセキュアな情報を残すのも良くないとは思うが（ローカルでは必要ないはずだし、クラウド環境の秘匿情報はクラウド上の適した場所＝AWSならSecretsManager等に保存するべきはずだし..）


イメージを塩漬けにしない

ECRのイメージスキャンやDependabot Security Update等を活用したら良さそう
GitHub ActionsでDocker社公式のdocker/scout-actionというCVEベースの脆弱性検知を行ってくれるみたい
Dockerfileでマルチステージビルドを行い、Dockerfile内でセキュリティツールを実行する
Snykをサイドカーとして動かしてリアルタイムでの自動検知


ファイルのマウントが必要な場合は最小限にする

ホストのファイルをマウントする場合はRead-Onlyなど権限は必要最低限にする
特にdockerソケット(/var/run/docker.sock)の扱いは注意

dockerソケットとは、Dockerデーモンが提供するUNIXソケットファイル
このソケットを通じて、docker buildやrunなどのCLIコマンドはデーモンと通信している（つまりDocker APIの入口）

ホストファイルシステムの改ざん（削除して破壊等）やホストネットワークの操作・盗聴などなど


ただ、CIや監視などでdockerソケットのマウントを要求するツールはあるので、その場合はRead-Onlyでマウントするようにする





マルチステージビルド

イメージのサイズが大きいとPullに時間がかかってしまい、リードタイムが長くなる
リードタイムが長くなると、

デプロイ・ロールバックが遅くなる
スケールアウトが遅くなり、コンテナ起動が間に合わず、リクエストを捌けなくなる
レジストリの保存料が高くなる



イメージの仕組みと設計

DockerイメージはDockerfileによって作成されるスナップショットであり、そのDockerイメージをもとに起動するのがコンテナ
1コンテナ1プロセスの原則

なぜ1コンテナ1プロセスが良いか？

可観測性

プロセス単位でメトリクスやログ収集がしやすい


責務の明確化

まぁ責務は明確にして分離すべきという話


リソース制御

CPUやメモリの利用量をプロセス単位で制御できる


障害隔離性

複数のプロセスが同一コンテナにあると、一方のクラッシュがもう一方に影響しやすい




とは言っても、全てのケースで1コンテナ＝1プロセスといく訳ではないので、1つのコンテナにつき1つの責務を目安にすると良い


コンテナ設計の指針となるThe Twelve-Factor App

The Twelve-Factor App （日本語訳）


ファイルシステム

イメージはRead-Onlyで、その上にRead-Write可能なコンテナレイヤが立ち上がるのがイメージとコンテナの仕組み

下位コンポーネントがイメージ（Read-Only）、上位コンポーネントがコンテナ（Read-Write）




ステートレスなコンテナにする

コンテナは廃棄容易性に優れている反面、データの永続化を苦手としている
ステートを持たないことで特定の環境に依存せず、高い可搬性を実現できる


ログは標準出力に出す

ファイルに吐くとステートを持つことになる
標準出力に吐いて収集するようにする



Dockerfileのベストプラクティス

軽量なベースイメージを選択する

公式が提供するイメージは軽量なslimというタグがついたイメージが存在する
Google Cloudはdistrolessというシェルなどが入っていないシンプルで軽量なイメージを提供している
理想はdisrolessだが、シェルなどのツール群が入っていないのでまずはslimを使用するのがおすすめ
alpineイメージがおすすめできない理由

軽量ではあるが、alpineのベースOSの歴史的系異常扱いが非常に難しい
元々フロッピーディスクに入るような軽量なOSとして開発された軽量化に特化したもので、逆にそれ以外の非機能要件を満たせないことが多々ある
調べると色々出てくるけど、基本的には標準ライブラリが（一般的なLinuxディストリビューションと）異なるための互換性が弱いこととパフォーマンス面に懸念があることっぽい

参考: とりあえずでDockerイメージにAlpine Linuxを選択するのはやめましょうという話 - NIFTY engineering






.dockerignoreを使用する

Dockerビルド時に無視するファイル・ディレクトリを指定することができる
Dockerfile自体不要だし、node_modulesもイメージビルド時にインストールするから不要とかそんな感じ


ビルド時に複数のアーキテクチャに対応させる

Docker v19からbuildxというサブコマンドが増えた（ex: docker buildx build）
以下のようなコマンドで、複数アーキテクチャに対応可能
  $ docker buildx build \
  --load \
  --platform linux/amd64,linux/arm64 \
  -t multi-platform \
  .

本番とローカルでアーキテクチャが異なる場合に便利



自分で調べたこと
識別子
Dockerのイメージやコンテナを識別する時、結局何で識別するんだっけ？となりがちなのでまとめる。
ここでいう識別というのは「イメージを指定してコンテナ起動」とか「コンテナを指定して停止・削除する」とかその辺りを指してます。">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Docker",
      "item": "http://localhost:1313/posts/docker/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Docker",
  "name": "Docker",
  "description": "概要 なんとなく触っているDockerを以下を題材にきちんと学ぶ。\n入門 Docker\n基礎編 Dockerとは Dockerは任意のタイミングの状態（ランタイム・ライブラリ・コードのバージョン）を1つのスナップショットとして保存している 従来のVM型の仮想化は、物理レイヤの仮想化から行なっている つまりVMには、 一方DockerはLinuxカーネルの機能を用いて1プロセスとして隔離された環境を実現している なのでDockerの方が軽量でオーバーヘッドが少ない環境を実現できる DockerはImmutable InfrastructureをDockerfileとイメージという機能で実現 任意の時点で確実に動作するスナップショット（何か変更する場合は新しく構築する） かつてはサーバーへ変更を加えて実現するMutableなものだった また、イメージにはバージョン情報がつくので、それを指定することでロールバックが可能になり、可用性が向上する コンテナ自体は古くからある概念で、Dockerが流行ったのは「配布の容易性」がある（スナップショットを取得し配布を標準の機能として提供している） VMとDocker どちらも隔離された環境を提供する技術 VMはコンピュータ自体の抽象化（仮想化）するのに対し、Dockerはプロセス自体の抽象化（仮想化）を行う この2つは競合するのではなく、むしろ共存する VM ハードウェアから上、ハードウェア・カーネル（OS）、ユーザースペースの低レイヤから仮想化を行う 例えばmacOS上でWindowsを動かすことが可能だったりして、非常に自由度が高い 仮想化の対象となる領域が広いためオーバーヘッドが大きくなる Docker Linuxカーネルの機能を用いた技術で、cgroup・namespace・Capabilityのような機能を組み合わせて実現している\nVMとは異なり、ホストOSとリソースを共有し、効率的にホストOSのリソースを使うことができるので、高速化つ軽量な仮想化を実現している\nLinuxカーネルとは？\nOSの中核となる部分で、ハードウェアとアプリケーションの間を取り持つ橋渡し役 例えばファイルの読み書き・ネットワーク通信・メモリ管理・CPU割り当てなどの低レイヤ処理を全てカーネルが担っている UbuntuやCentOSなどのディストリビューションは全てLinuxカーネルをベースにしている カーネルが主に行なっているのは以下の4つ プロセス管理：プロセスに対してCPU割り当て（今どのプロセスにCPU時間を割り当てるかをスケジュール・切り替え＝コンテキストスイッチ） メモリ管理：アプリケーションへのメモリ割り当て（他のプロセスのメモリ領域を勝手にアクセスできないようにしたり、メモリ不足時はディスクにスワッピングしたり） ファイルシステム管理：ファイル操作を仲介（実際にディスクを触るのはカーネルが行なっている） ネットワーク管理：カーネルがパケット処理を行なっている でもDockerfileでFROM句にubuntu:latestみたいな記述をしているよね\u0026hellip;？\nホスト側のLinuxカーネルを使うのに、コンテナ側でOS指定が必要な理由は何？という話 結論、これはユーザースペースのOS環境を指定しているだけ ユーザースペースというのは、コマンドやライブラリ（bashとか） Distrolessとか軽量なOSイメージを指定すると、デフォルトのままではcurl等のコマンドがインストールされておらず使用できないのは、コンテナ側のユーザースペースを使っているため Docker Image イメージは、任意のタイミングのスナップショットとしての役割を持つ ファイルシステムのスナップショットである もっとシンプルに表現すると、OSの中身のフォルダ構造一式をZIP圧縮したようなもの 例えばubuntuイメージの中身は、ユーザースペース（ls /した時に見るような bin/,etc/,lib/等）のファイル・フォルダ一式が入っている（でもカーネル部分は含まない） てっきりイメージ＝プロセスのスナップショットと理解していたけどそれは間違っていて、イメージ＝実行前のファイル群が正しい表現 イメージを指定するときの命名は\u0026lt;イメージ名\u0026gt;:\u0026lt;タグ\u0026gt;であり、\u0026lt;タグ\u0026gt;を省略するとlatestタグが自動的に付与される レイヤー構造 Dockerイメージはレイヤーの積み重ね RUNやCOPY毎に新しいレイヤが作られる レイヤは読み取り専用で、キャッシュとして使い回せる レイヤー構造である理由 キャッシュ：同じベースイメージなら、そのレイヤはpull済み ストレージ節約：変更があった部分だけ新しいレイヤに保存 もし仮にレイヤ構造ではない場合はフルフルのものを保存しなければいけない 高速化：レイヤー単位でダウンロード・展開 docker pushすると以下のようなハッシュ値が表示されるが、これがまさにレイヤ構造（レイヤ単位で処理している） The push refers to repository [123456789012.dkr.ecr.us-east-1.amazonaws.com/myapp] d4f4f6a4b8c2: Pushed 7a0437f04f83: Pushed 8c662931926f: Pushed ... 各レイヤのコンテンツハッシュ(SHA256)らしい 具体的にはそのレイヤの差分をtarアーカイブをgzipなりで圧縮→圧縮されたバイナリファイルをSHA256ハッシュ計算している 整理すると、Dockerイメージはファイルシステムのスナップショットであり、それはレイヤー構造になっている 以下のDockerfileを例に考えると、 FROM ubuntu:latest RUN apt-get update RUN apt-get install -y curl 各行がレイヤとなっていて、そのレイヤで変更があったファイル群を持っているイメージ この上に、Dockerはコンテナ起動した時に、書き込みできるレイヤを作っている イメージとコンテナの違い イメージ: 読み込み専用の複数のレイヤを重ねたもの コンテナ: イメージに読み書き可能なレイヤを追加して起動したもの 参考リンク レイヤ — Docker-docs-ja 24.0 ドキュメント Dockerのまとめ - コンテナとイメージ編 #Docker - Qiita Dockerfile COPY 2つの引数を設定する 1つ目はホスト側のディレクトリ、2つ目はDocker側のディレクトリ ホスト側のディレクトリは docker build . で指定したディレクトリ この場合 . を指定しており、カレントディレクトリが参照される Docker側はデフォルトのパス、もしくは WORKDIR で定義されたディレクトリを参照する EXPOSE このポートを使いますよというドキュメント的な宣言 CMD Dockerはここで設定したコマンドがフォアグラウンドで実行されている間が生存期間となる RUN vs CMD RUN: イメージビルド時に実行される レイヤとしてファイルシステムに反映されキャッシュが効く CMD: コンテナ起動時に実行される イメージには反映せず、ただの実行時オプション CMD vs ENTRYPOINT CMDはデフォルト設定で、オーバーライド可能 一方、ENTRYPOINTは起動時に必ず実行される テクニックとしてENTRYPOINTでコマンドを指定し、CMDで引数を指定するというのがある（引数だけ利用者側で指定可能となる） 基本的に CMD を使うのが良いでしょう。 ENTRYPOINT はDocker起動時のコマンドを強制します。 コマンドのラップをするDocker Image の場合は ENTRYPOINT のほうが好ましいですが、一般的なWebアプリケーションの場合は CMD を使用する方がユーザーにとって使いやすいDocker Image になります。 COPYは最後に実行するとキャッシュが効きやすい Dockerfileの前段で、COPY . .を実行してしまうと、ローカル側のソースコードが1文字でも変わっていると、そのレイヤのキャッシュが効かなくなる レイヤーのキャッシュは、親が変わると問答無用でキャッシュ無効化されるので、COPY . .以降は全てキャッシュが利用されなくなる（レイヤは差分を持っているようなものだから、親が変更があったら当然子にも影響あるよねということだと理解した） なので、変更が頻繁にあるようなCOPY . .の処理は、Dockerfileの中で後ろの方に持っていくと良い Nodeならpackage系だけを最初にコピーする→依存関係をインストール→ソースコードをコピーしてくるみたいな形で工夫できる Container イメージがスナップショットだとすると、そのスナップショットから起動したプロセスがコンテナ コンテナは「1つのコマンド（プロセス）をフォアグラウンドで動かす」ように設計されている コンテナは1つのコマンドを隔離された環境で実行し、そのコマンドの実行がフォアグラウンドで終了するまで生存する ライフサイクル Image \u0026ndash; (docker run \u0026lt;$IMAGE\u0026gt;) \u0026ndash;\u0026gt; RUNNING \u0026ndash; STOPPED \u0026ndash; DELETED 正常終了 or 異常終了 or docker killするとSTOPPED docker rmするとDELETED pauseすると停止状態を表すPAUSEDにもなる プロセスの隔離 コンテナ内のプロセスはホストマシンや他のコンテナと隔離されて実行される CMDもしくはENTRYPOINTで定義されたプロセスはPID 1となる Network Dockerではネットワークの扱いが重要となる 1コンテナでは1プロセスを動かす設計となっている nginxとphp-fpmのように複数プロセスを協調して動かす必要があるときはソケットではなく、ネットワークで通信を行うことが推奨されている Dockerでのネットワークは特にKubernetes・ECS・docker-composeのような各種オーケストレーションツールを使用する際に意識する必要がある Driverの種類 ネットワークドライバーはネットワークの振る舞いの定義で、デフォルトでは2種類ある 複数のコンテナ（プロセス）はネットワークを介して通信を行う bridge 基本的にはこれ コンテナごとに仮想IPが割り振られ、同じネットワークに属するコンテナ間で通信が可能 こうすることでコンテナ同士はコンテナ名で互いに名前解決して通信できる 少し深掘りすると.. 何も指定せずにコンテナ起動すると、docker0という名前のbridgeネットワークに所属する docker0というのははホストOS上に仮想ブリッジという仮想スイッチ hostネットワーク \u0026ndash; docker0（仮想ブリッジ） \u0026ndash; コンテナA, B\u0026hellip;という構成 この構成では、各コンテナに独立した仮想ネットワーク内のIPが与えられ、同じネットワークにいるコンテナ間はIPやホスト名で通信できる コンテナに対し、外部からアクセスしたい場合はNAT変換によるポートフォワードが必要(ex: docker run -p 8080:80 nginx) Linuxカーネルのbridgeネットワークを使用する host コンテナがホストのIPアドレスとポート空間（ネットワーク名前空間）をそのまま使う 仮想NICやブリッジを介さずに、直接ホストのIP・ポート空間にアクセスできる 例：コンテナが80番でListenすると、それはホスト側の80番ポートを使うことになる オーバーヘッドが少ない分通信が速いが、ポートの競合に注意する必要がある ホスト側のlocalhost:80等でそのままコンテナにアクセスできるような仕組み none コンテナにネットワークを割り当てない セキュリティ上、外部から完全に切り離したい時に使う Docker Composeにおけるネットワークの考え方 Docker Composeはマルチコンテナを簡単に定義・管理できるツール 内部ネットワークは自動で作成される 各サービスは、自動で同じカスタムネットワークに所属するので、互いにサービス名で名前解決が可能となる（内部DNSによって解決されている） Volume データを永続化するための機能 Dockerコンテナは基本的にはエフェメラル（短命）なもので、ライフサイクルの終了とともにコンテナ上で作成されたファイルは消失する ボリュームタイプには以下の2種類がある Data Volume コンテナのライフサイクルの外で管理されるファイル/ディレクトリの設定 -v \u0026lt;CONTAINER PATH\u0026gt; or -v \u0026lt;HOST PATH\u0026gt;:\u0026lt;CONTAINER PATH\u0026gt; コンテナの外側＝ホスト側にファイルが保管される Data Volume Container 他のコンテナで指定されているボリュームを参照するための機能（コンテナ間でボリュームを共有する） --volumes-fromでコンテナ名を指定することで、別のコンテナのボリュームを参照できる 今の時代では、Named Volume(-v mydata:data)や上記のData VolumeのBind Mount(-v \u0026lt;HOST PATH\u0026gt;:\u0026lt;CONTAINER PATH\u0026gt;)を使用するケースが多そう Named Volumeの補足として、Linuxの場合は大抵/var/lib/docker/volumes/mydata/_data/に保存される プロダクションでの活用Tips セキュリティ rootユーザーを使わない 野良のイメージをベースイメージにしない ビルド時に機微情報を与えない ビルド時にパスワードや秘密鍵のような機微情報を与え、最終イメージに残らないようにする ビルド後に環境変数として渡すことがベストプラクティス もし仮にプライベートリポジトリをクローンするなどをしたい場合、\u0026ndash;secretや\u0026ndash;sshオプションを使用する(シークレット情報を格納したファイルを渡すイメージ)ことで、ビルド時に一時的にファイルにアクセスし、最終的なイメージには残らないようにセキュアなビルドを行うようにする この方法がなぜイメージに残らないのかというと、一時的なマウント(仮想的なtmpfs)としてビルド中のコンテナに提供されるだけであり、COPYやRUNコマンドで明示的に保存しない限り、イメージのレイヤーには一切含まれないため 逆に1行の中でRUN echo \u0026ldquo;secret\u0026rdquo; \u0026gt; /tmp/hoge.txt \u0026amp;\u0026amp; rm -f /tmp/hoge.txtなどとまとめれば、レイヤーのスナップショットには残らない これを2行に分けてしまうとRUN echo \u0026ldquo;secret\u0026rdquo; \u0026gt; /tmp/hoge.txtのみキャッシュが効いてしまい、最終イメージにファイルがそのまま残ってしまう .dockerignoreファイルでローカルの不要なパスを無視する .envのようなDBへの接続情報が記載されているようなファイルをビルドに含めないように、.dockerignoreを管理する（そうすればビルド時に無視される） 具体的には、Dockerクライアントはdocker build実行時にビルドコンテキスト全体をDockerデーモンに送るが、.dockerignoreで指定されたものは転送対象から除外される（COPYコマンドでも同じ） まぁそもそも.envに直接ベタでセキュアな情報を残すのも良くないとは思うが（ローカルでは必要ないはずだし、クラウド環境の秘匿情報はクラウド上の適した場所＝AWSならSecretsManager等に保存するべきはずだし..） イメージを塩漬けにしない ECRのイメージスキャンやDependabot Security Update等を活用したら良さそう GitHub ActionsでDocker社公式のdocker/scout-actionというCVEベースの脆弱性検知を行ってくれるみたい Dockerfileでマルチステージビルドを行い、Dockerfile内でセキュリティツールを実行する Snykをサイドカーとして動かしてリアルタイムでの自動検知 ファイルのマウントが必要な場合は最小限にする ホストのファイルをマウントする場合はRead-Onlyなど権限は必要最低限にする 特にdockerソケット(/var/run/docker.sock)の扱いは注意 dockerソケットとは、Dockerデーモンが提供するUNIXソケットファイル このソケットを通じて、docker buildやrunなどのCLIコマンドはデーモンと通信している（つまりDocker APIの入口） ホストファイルシステムの改ざん（削除して破壊等）やホストネットワークの操作・盗聴などなど ただ、CIや監視などでdockerソケットのマウントを要求するツールはあるので、その場合はRead-Onlyでマウントするようにする マルチステージビルド イメージのサイズが大きいとPullに時間がかかってしまい、リードタイムが長くなる リードタイムが長くなると、 デプロイ・ロールバックが遅くなる スケールアウトが遅くなり、コンテナ起動が間に合わず、リクエストを捌けなくなる レジストリの保存料が高くなる イメージの仕組みと設計 DockerイメージはDockerfileによって作成されるスナップショットであり、そのDockerイメージをもとに起動するのがコンテナ 1コンテナ1プロセスの原則 なぜ1コンテナ1プロセスが良いか？ 可観測性 プロセス単位でメトリクスやログ収集がしやすい 責務の明確化 まぁ責務は明確にして分離すべきという話 リソース制御 CPUやメモリの利用量をプロセス単位で制御できる 障害隔離性 複数のプロセスが同一コンテナにあると、一方のクラッシュがもう一方に影響しやすい とは言っても、全てのケースで1コンテナ＝1プロセスといく訳ではないので、1つのコンテナにつき1つの責務を目安にすると良い コンテナ設計の指針となるThe Twelve-Factor App The Twelve-Factor App （日本語訳） ファイルシステム イメージはRead-Onlyで、その上にRead-Write可能なコンテナレイヤが立ち上がるのがイメージとコンテナの仕組み 下位コンポーネントがイメージ（Read-Only）、上位コンポーネントがコンテナ（Read-Write） ステートレスなコンテナにする コンテナは廃棄容易性に優れている反面、データの永続化を苦手としている ステートを持たないことで特定の環境に依存せず、高い可搬性を実現できる ログは標準出力に出す ファイルに吐くとステートを持つことになる 標準出力に吐いて収集するようにする Dockerfileのベストプラクティス 軽量なベースイメージを選択する 公式が提供するイメージは軽量なslimというタグがついたイメージが存在する Google Cloudはdistrolessというシェルなどが入っていないシンプルで軽量なイメージを提供している 理想はdisrolessだが、シェルなどのツール群が入っていないのでまずはslimを使用するのがおすすめ alpineイメージがおすすめできない理由 軽量ではあるが、alpineのベースOSの歴史的系異常扱いが非常に難しい 元々フロッピーディスクに入るような軽量なOSとして開発された軽量化に特化したもので、逆にそれ以外の非機能要件を満たせないことが多々ある 調べると色々出てくるけど、基本的には標準ライブラリが（一般的なLinuxディストリビューションと）異なるための互換性が弱いこととパフォーマンス面に懸念があることっぽい 参考: とりあえずでDockerイメージにAlpine Linuxを選択するのはやめましょうという話 - NIFTY engineering .dockerignoreを使用する Dockerビルド時に無視するファイル・ディレクトリを指定することができる Dockerfile自体不要だし、node_modulesもイメージビルド時にインストールするから不要とかそんな感じ ビルド時に複数のアーキテクチャに対応させる Docker v19からbuildxというサブコマンドが増えた（ex: docker buildx build） 以下のようなコマンドで、複数アーキテクチャに対応可能 $ docker buildx build \\ --load \\ --platform linux/amd64,linux/arm64 \\ -t multi-platform \\ . 本番とローカルでアーキテクチャが異なる場合に便利 自分で調べたこと 識別子 Dockerのイメージやコンテナを識別する時、結局何で識別するんだっけ？となりがちなのでまとめる。 ここでいう識別というのは「イメージを指定してコンテナ起動」とか「コンテナを指定して停止・削除する」とかその辺りを指してます。\n",
  "keywords": [
    
  ],
  "articleBody": "概要 なんとなく触っているDockerを以下を題材にきちんと学ぶ。\n入門 Docker\n基礎編 Dockerとは Dockerは任意のタイミングの状態（ランタイム・ライブラリ・コードのバージョン）を1つのスナップショットとして保存している 従来のVM型の仮想化は、物理レイヤの仮想化から行なっている つまりVMには、 一方DockerはLinuxカーネルの機能を用いて1プロセスとして隔離された環境を実現している なのでDockerの方が軽量でオーバーヘッドが少ない環境を実現できる DockerはImmutable InfrastructureをDockerfileとイメージという機能で実現 任意の時点で確実に動作するスナップショット（何か変更する場合は新しく構築する） かつてはサーバーへ変更を加えて実現するMutableなものだった また、イメージにはバージョン情報がつくので、それを指定することでロールバックが可能になり、可用性が向上する コンテナ自体は古くからある概念で、Dockerが流行ったのは「配布の容易性」がある（スナップショットを取得し配布を標準の機能として提供している） VMとDocker どちらも隔離された環境を提供する技術 VMはコンピュータ自体の抽象化（仮想化）するのに対し、Dockerはプロセス自体の抽象化（仮想化）を行う この2つは競合するのではなく、むしろ共存する VM ハードウェアから上、ハードウェア・カーネル（OS）、ユーザースペースの低レイヤから仮想化を行う 例えばmacOS上でWindowsを動かすことが可能だったりして、非常に自由度が高い 仮想化の対象となる領域が広いためオーバーヘッドが大きくなる Docker Linuxカーネルの機能を用いた技術で、cgroup・namespace・Capabilityのような機能を組み合わせて実現している\nVMとは異なり、ホストOSとリソースを共有し、効率的にホストOSのリソースを使うことができるので、高速化つ軽量な仮想化を実現している\nLinuxカーネルとは？\nOSの中核となる部分で、ハードウェアとアプリケーションの間を取り持つ橋渡し役 例えばファイルの読み書き・ネットワーク通信・メモリ管理・CPU割り当てなどの低レイヤ処理を全てカーネルが担っている UbuntuやCentOSなどのディストリビューションは全てLinuxカーネルをベースにしている カーネルが主に行なっているのは以下の4つ プロセス管理：プロセスに対してCPU割り当て（今どのプロセスにCPU時間を割り当てるかをスケジュール・切り替え＝コンテキストスイッチ） メモリ管理：アプリケーションへのメモリ割り当て（他のプロセスのメモリ領域を勝手にアクセスできないようにしたり、メモリ不足時はディスクにスワッピングしたり） ファイルシステム管理：ファイル操作を仲介（実際にディスクを触るのはカーネルが行なっている） ネットワーク管理：カーネルがパケット処理を行なっている でもDockerfileでFROM句にubuntu:latestみたいな記述をしているよね…？\nホスト側のLinuxカーネルを使うのに、コンテナ側でOS指定が必要な理由は何？という話 結論、これはユーザースペースのOS環境を指定しているだけ ユーザースペースというのは、コマンドやライブラリ（bashとか） Distrolessとか軽量なOSイメージを指定すると、デフォルトのままではcurl等のコマンドがインストールされておらず使用できないのは、コンテナ側のユーザースペースを使っているため Docker Image イメージは、任意のタイミングのスナップショットとしての役割を持つ ファイルシステムのスナップショットである もっとシンプルに表現すると、OSの中身のフォルダ構造一式をZIP圧縮したようなもの 例えばubuntuイメージの中身は、ユーザースペース（ls /した時に見るような bin/,etc/,lib/等）のファイル・フォルダ一式が入っている（でもカーネル部分は含まない） てっきりイメージ＝プロセスのスナップショットと理解していたけどそれは間違っていて、イメージ＝実行前のファイル群が正しい表現 イメージを指定するときの命名は\u003cイメージ名\u003e:\u003cタグ\u003eであり、\u003cタグ\u003eを省略するとlatestタグが自動的に付与される レイヤー構造 Dockerイメージはレイヤーの積み重ね RUNやCOPY毎に新しいレイヤが作られる レイヤは読み取り専用で、キャッシュとして使い回せる レイヤー構造である理由 キャッシュ：同じベースイメージなら、そのレイヤはpull済み ストレージ節約：変更があった部分だけ新しいレイヤに保存 もし仮にレイヤ構造ではない場合はフルフルのものを保存しなければいけない 高速化：レイヤー単位でダウンロード・展開 docker pushすると以下のようなハッシュ値が表示されるが、これがまさにレイヤ構造（レイヤ単位で処理している） The push refers to repository [123456789012.dkr.ecr.us-east-1.amazonaws.com/myapp] d4f4f6a4b8c2: Pushed 7a0437f04f83: Pushed 8c662931926f: Pushed ... 各レイヤのコンテンツハッシュ(SHA256)らしい 具体的にはそのレイヤの差分をtarアーカイブをgzipなりで圧縮→圧縮されたバイナリファイルをSHA256ハッシュ計算している 整理すると、Dockerイメージはファイルシステムのスナップショットであり、それはレイヤー構造になっている 以下のDockerfileを例に考えると、 FROM ubuntu:latest RUN apt-get update RUN apt-get install -y curl 各行がレイヤとなっていて、そのレイヤで変更があったファイル群を持っているイメージ この上に、Dockerはコンテナ起動した時に、書き込みできるレイヤを作っている イメージとコンテナの違い イメージ: 読み込み専用の複数のレイヤを重ねたもの コンテナ: イメージに読み書き可能なレイヤを追加して起動したもの 参考リンク レイヤ — Docker-docs-ja 24.0 ドキュメント Dockerのまとめ - コンテナとイメージ編 #Docker - Qiita Dockerfile COPY 2つの引数を設定する 1つ目はホスト側のディレクトリ、2つ目はDocker側のディレクトリ ホスト側のディレクトリは docker build . で指定したディレクトリ この場合 . を指定しており、カレントディレクトリが参照される Docker側はデフォルトのパス、もしくは WORKDIR で定義されたディレクトリを参照する EXPOSE このポートを使いますよというドキュメント的な宣言 CMD Dockerはここで設定したコマンドがフォアグラウンドで実行されている間が生存期間となる RUN vs CMD RUN: イメージビルド時に実行される レイヤとしてファイルシステムに反映されキャッシュが効く CMD: コンテナ起動時に実行される イメージには反映せず、ただの実行時オプション CMD vs ENTRYPOINT CMDはデフォルト設定で、オーバーライド可能 一方、ENTRYPOINTは起動時に必ず実行される テクニックとしてENTRYPOINTでコマンドを指定し、CMDで引数を指定するというのがある（引数だけ利用者側で指定可能となる） 基本的に CMD を使うのが良いでしょう。 ENTRYPOINT はDocker起動時のコマンドを強制します。 コマンドのラップをするDocker Image の場合は ENTRYPOINT のほうが好ましいですが、一般的なWebアプリケーションの場合は CMD を使用する方がユーザーにとって使いやすいDocker Image になります。 COPYは最後に実行するとキャッシュが効きやすい Dockerfileの前段で、COPY . .を実行してしまうと、ローカル側のソースコードが1文字でも変わっていると、そのレイヤのキャッシュが効かなくなる レイヤーのキャッシュは、親が変わると問答無用でキャッシュ無効化されるので、COPY . .以降は全てキャッシュが利用されなくなる（レイヤは差分を持っているようなものだから、親が変更があったら当然子にも影響あるよねということだと理解した） なので、変更が頻繁にあるようなCOPY . .の処理は、Dockerfileの中で後ろの方に持っていくと良い Nodeならpackage系だけを最初にコピーする→依存関係をインストール→ソースコードをコピーしてくるみたいな形で工夫できる Container イメージがスナップショットだとすると、そのスナップショットから起動したプロセスがコンテナ コンテナは「1つのコマンド（プロセス）をフォアグラウンドで動かす」ように設計されている コンテナは1つのコマンドを隔離された環境で実行し、そのコマンドの実行がフォアグラウンドで終了するまで生存する ライフサイクル Image – (docker run \u003c$IMAGE\u003e) –\u003e RUNNING – STOPPED – DELETED 正常終了 or 異常終了 or docker killするとSTOPPED docker rmするとDELETED pauseすると停止状態を表すPAUSEDにもなる プロセスの隔離 コンテナ内のプロセスはホストマシンや他のコンテナと隔離されて実行される CMDもしくはENTRYPOINTで定義されたプロセスはPID 1となる Network Dockerではネットワークの扱いが重要となる 1コンテナでは1プロセスを動かす設計となっている nginxとphp-fpmのように複数プロセスを協調して動かす必要があるときはソケットではなく、ネットワークで通信を行うことが推奨されている Dockerでのネットワークは特にKubernetes・ECS・docker-composeのような各種オーケストレーションツールを使用する際に意識する必要がある Driverの種類 ネットワークドライバーはネットワークの振る舞いの定義で、デフォルトでは2種類ある 複数のコンテナ（プロセス）はネットワークを介して通信を行う bridge 基本的にはこれ コンテナごとに仮想IPが割り振られ、同じネットワークに属するコンテナ間で通信が可能 こうすることでコンテナ同士はコンテナ名で互いに名前解決して通信できる 少し深掘りすると.. 何も指定せずにコンテナ起動すると、docker0という名前のbridgeネットワークに所属する docker0というのははホストOS上に仮想ブリッジという仮想スイッチ hostネットワーク – docker0（仮想ブリッジ） – コンテナA, B…という構成 この構成では、各コンテナに独立した仮想ネットワーク内のIPが与えられ、同じネットワークにいるコンテナ間はIPやホスト名で通信できる コンテナに対し、外部からアクセスしたい場合はNAT変換によるポートフォワードが必要(ex: docker run -p 8080:80 nginx) Linuxカーネルのbridgeネットワークを使用する host コンテナがホストのIPアドレスとポート空間（ネットワーク名前空間）をそのまま使う 仮想NICやブリッジを介さずに、直接ホストのIP・ポート空間にアクセスできる 例：コンテナが80番でListenすると、それはホスト側の80番ポートを使うことになる オーバーヘッドが少ない分通信が速いが、ポートの競合に注意する必要がある ホスト側のlocalhost:80等でそのままコンテナにアクセスできるような仕組み none コンテナにネットワークを割り当てない セキュリティ上、外部から完全に切り離したい時に使う Docker Composeにおけるネットワークの考え方 Docker Composeはマルチコンテナを簡単に定義・管理できるツール 内部ネットワークは自動で作成される 各サービスは、自動で同じカスタムネットワークに所属するので、互いにサービス名で名前解決が可能となる（内部DNSによって解決されている） Volume データを永続化するための機能 Dockerコンテナは基本的にはエフェメラル（短命）なもので、ライフサイクルの終了とともにコンテナ上で作成されたファイルは消失する ボリュームタイプには以下の2種類がある Data Volume コンテナのライフサイクルの外で管理されるファイル/ディレクトリの設定 -v or -v : コンテナの外側＝ホスト側にファイルが保管される Data Volume Container 他のコンテナで指定されているボリュームを参照するための機能（コンテナ間でボリュームを共有する） --volumes-fromでコンテナ名を指定することで、別のコンテナのボリュームを参照できる 今の時代では、Named Volume(-v mydata:data)や上記のData VolumeのBind Mount(-v :)を使用するケースが多そう Named Volumeの補足として、Linuxの場合は大抵/var/lib/docker/volumes/mydata/_data/に保存される プロダクションでの活用Tips セキュリティ rootユーザーを使わない 野良のイメージをベースイメージにしない ビルド時に機微情報を与えない ビルド時にパスワードや秘密鍵のような機微情報を与え、最終イメージに残らないようにする ビルド後に環境変数として渡すことがベストプラクティス もし仮にプライベートリポジトリをクローンするなどをしたい場合、–secretや–sshオプションを使用する(シークレット情報を格納したファイルを渡すイメージ)ことで、ビルド時に一時的にファイルにアクセスし、最終的なイメージには残らないようにセキュアなビルドを行うようにする この方法がなぜイメージに残らないのかというと、一時的なマウント(仮想的なtmpfs)としてビルド中のコンテナに提供されるだけであり、COPYやRUNコマンドで明示的に保存しない限り、イメージのレイヤーには一切含まれないため 逆に1行の中でRUN echo “secret” \u003e /tmp/hoge.txt \u0026\u0026 rm -f /tmp/hoge.txtなどとまとめれば、レイヤーのスナップショットには残らない これを2行に分けてしまうとRUN echo “secret” \u003e /tmp/hoge.txtのみキャッシュが効いてしまい、最終イメージにファイルがそのまま残ってしまう .dockerignoreファイルでローカルの不要なパスを無視する .envのようなDBへの接続情報が記載されているようなファイルをビルドに含めないように、.dockerignoreを管理する（そうすればビルド時に無視される） 具体的には、Dockerクライアントはdocker build実行時にビルドコンテキスト全体をDockerデーモンに送るが、.dockerignoreで指定されたものは転送対象から除外される（COPYコマンドでも同じ） まぁそもそも.envに直接ベタでセキュアな情報を残すのも良くないとは思うが（ローカルでは必要ないはずだし、クラウド環境の秘匿情報はクラウド上の適した場所＝AWSならSecretsManager等に保存するべきはずだし..） イメージを塩漬けにしない ECRのイメージスキャンやDependabot Security Update等を活用したら良さそう GitHub ActionsでDocker社公式のdocker/scout-actionというCVEベースの脆弱性検知を行ってくれるみたい Dockerfileでマルチステージビルドを行い、Dockerfile内でセキュリティツールを実行する Snykをサイドカーとして動かしてリアルタイムでの自動検知 ファイルのマウントが必要な場合は最小限にする ホストのファイルをマウントする場合はRead-Onlyなど権限は必要最低限にする 特にdockerソケット(/var/run/docker.sock)の扱いは注意 dockerソケットとは、Dockerデーモンが提供するUNIXソケットファイル このソケットを通じて、docker buildやrunなどのCLIコマンドはデーモンと通信している（つまりDocker APIの入口） ホストファイルシステムの改ざん（削除して破壊等）やホストネットワークの操作・盗聴などなど ただ、CIや監視などでdockerソケットのマウントを要求するツールはあるので、その場合はRead-Onlyでマウントするようにする マルチステージビルド イメージのサイズが大きいとPullに時間がかかってしまい、リードタイムが長くなる リードタイムが長くなると、 デプロイ・ロールバックが遅くなる スケールアウトが遅くなり、コンテナ起動が間に合わず、リクエストを捌けなくなる レジストリの保存料が高くなる イメージの仕組みと設計 DockerイメージはDockerfileによって作成されるスナップショットであり、そのDockerイメージをもとに起動するのがコンテナ 1コンテナ1プロセスの原則 なぜ1コンテナ1プロセスが良いか？ 可観測性 プロセス単位でメトリクスやログ収集がしやすい 責務の明確化 まぁ責務は明確にして分離すべきという話 リソース制御 CPUやメモリの利用量をプロセス単位で制御できる 障害隔離性 複数のプロセスが同一コンテナにあると、一方のクラッシュがもう一方に影響しやすい とは言っても、全てのケースで1コンテナ＝1プロセスといく訳ではないので、1つのコンテナにつき1つの責務を目安にすると良い コンテナ設計の指針となるThe Twelve-Factor App The Twelve-Factor App （日本語訳） ファイルシステム イメージはRead-Onlyで、その上にRead-Write可能なコンテナレイヤが立ち上がるのがイメージとコンテナの仕組み 下位コンポーネントがイメージ（Read-Only）、上位コンポーネントがコンテナ（Read-Write） ステートレスなコンテナにする コンテナは廃棄容易性に優れている反面、データの永続化を苦手としている ステートを持たないことで特定の環境に依存せず、高い可搬性を実現できる ログは標準出力に出す ファイルに吐くとステートを持つことになる 標準出力に吐いて収集するようにする Dockerfileのベストプラクティス 軽量なベースイメージを選択する 公式が提供するイメージは軽量なslimというタグがついたイメージが存在する Google Cloudはdistrolessというシェルなどが入っていないシンプルで軽量なイメージを提供している 理想はdisrolessだが、シェルなどのツール群が入っていないのでまずはslimを使用するのがおすすめ alpineイメージがおすすめできない理由 軽量ではあるが、alpineのベースOSの歴史的系異常扱いが非常に難しい 元々フロッピーディスクに入るような軽量なOSとして開発された軽量化に特化したもので、逆にそれ以外の非機能要件を満たせないことが多々ある 調べると色々出てくるけど、基本的には標準ライブラリが（一般的なLinuxディストリビューションと）異なるための互換性が弱いこととパフォーマンス面に懸念があることっぽい 参考: とりあえずでDockerイメージにAlpine Linuxを選択するのはやめましょうという話 - NIFTY engineering .dockerignoreを使用する Dockerビルド時に無視するファイル・ディレクトリを指定することができる Dockerfile自体不要だし、node_modulesもイメージビルド時にインストールするから不要とかそんな感じ ビルド時に複数のアーキテクチャに対応させる Docker v19からbuildxというサブコマンドが増えた（ex: docker buildx build） 以下のようなコマンドで、複数アーキテクチャに対応可能 $ docker buildx build \\ --load \\ --platform linux/amd64,linux/arm64 \\ -t multi-platform \\ . 本番とローカルでアーキテクチャが異なる場合に便利 自分で調べたこと 識別子 Dockerのイメージやコンテナを識別する時、結局何で識別するんだっけ？となりがちなのでまとめる。 ここでいう識別というのは「イメージを指定してコンテナ起動」とか「コンテナを指定して停止・削除する」とかその辺りを指してます。\nイメージ イメージ名で識別する イメージ名は「リポジトリ名:タグ名」で構成される タグ名は省略可能で、省略した場合はlatestが付与される docker build -t repository-name:tag-name といった形で コンテナ コンテナ名 or コンテナID コンテナ名は、起動時に指定が可能 docker run --name mycontainer image-name コンテナIDは、起動時に自動付与される一意の識別子 通常64文字の英数字だが、先頭の12文字程度で識別可能 docker psで確認可能 ",
  "wordCount" : "420",
  "inLanguage": "en",
  "datePublished": "2025-06-18T11:40:43+09:00",
  "dateModified": "2025-06-18T11:40:43+09:00",
  "author":{
    "@type": "Person",
    "name": "nyuusen"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/docker/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "nyuusen blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="nyuusen blog (Alt + H)">nyuusen blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Docker
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2025-06-18 11:40:43 +0900 JST'>June 18, 2025</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;nyuusen

</div>
  </header> 
  <div class="post-content"><h2 id="概要">概要<a hidden class="anchor" aria-hidden="true" href="#概要">#</a></h2>
<p>なんとなく触っているDockerを以下を題材にきちんと学ぶ。</p>
<p><a href="https://y-ohgi.com/introduction-docker/">入門 Docker</a></p>
<h2 id="基礎編">基礎編<a hidden class="anchor" aria-hidden="true" href="#基礎編">#</a></h2>
<h3 id="dockerとは">Dockerとは<a hidden class="anchor" aria-hidden="true" href="#dockerとは">#</a></h3>
<ul>
<li>Dockerは任意のタイミングの状態（ランタイム・ライブラリ・コードのバージョン）を1つのスナップショットとして保存している</li>
<li>従来のVM型の仮想化は、物理レイヤの仮想化から行なっている
<ul>
<li>つまりVMには、</li>
</ul>
</li>
<li>一方DockerはLinuxカーネルの機能を用いて1プロセスとして隔離された環境を実現している</li>
<li>なのでDockerの方が軽量でオーバーヘッドが少ない環境を実現できる</li>
<li>DockerはImmutable InfrastructureをDockerfileとイメージという機能で実現
<ul>
<li>任意の時点で確実に動作するスナップショット（何か変更する場合は新しく構築する）</li>
<li>かつてはサーバーへ変更を加えて実現するMutableなものだった</li>
<li>また、イメージにはバージョン情報がつくので、それを指定することでロールバックが可能になり、可用性が向上する</li>
</ul>
</li>
<li>コンテナ自体は古くからある概念で、Dockerが流行ったのは「配布の容易性」がある（スナップショットを取得し配布を標準の機能として提供している）</li>
</ul>
<h3 id="vmとdocker">VMとDocker<a hidden class="anchor" aria-hidden="true" href="#vmとdocker">#</a></h3>
<ul>
<li>どちらも隔離された環境を提供する技術</li>
<li><strong>VMはコンピュータ自体の抽象化（仮想化）するのに対し、Dockerはプロセス自体の抽象化（仮想化）を行う</strong>
<ul>
<li>この2つは競合するのではなく、むしろ共存する</li>
</ul>
</li>
</ul>
<h4 id="vm">VM<a hidden class="anchor" aria-hidden="true" href="#vm">#</a></h4>
<ul>
<li>ハードウェアから上、ハードウェア・カーネル（OS）、ユーザースペースの低レイヤから仮想化を行う</li>
<li>例えばmacOS上でWindowsを動かすことが可能だったりして、非常に自由度が高い</li>
<li>仮想化の対象となる領域が広いためオーバーヘッドが大きくなる</li>
</ul>
<h4 id="docker">Docker<a hidden class="anchor" aria-hidden="true" href="#docker">#</a></h4>
<ul>
<li>
<p>Linuxカーネルの機能を用いた技術で、cgroup・namespace・Capabilityのような機能を組み合わせて実現している</p>
</li>
<li>
<p>VMとは異なり、ホストOSとリソースを共有し、効率的にホストOSのリソースを使うことができるので、高速化つ軽量な仮想化を実現している</p>
</li>
<li>
<p>Linuxカーネルとは？</p>
<ul>
<li>OSの中核となる部分で、ハードウェアとアプリケーションの間を取り持つ橋渡し役</li>
<li>例えばファイルの読み書き・ネットワーク通信・メモリ管理・CPU割り当てなどの低レイヤ処理を全てカーネルが担っている</li>
<li>UbuntuやCentOSなどのディストリビューションは全てLinuxカーネルをベースにしている</li>
<li>カーネルが主に行なっているのは以下の4つ
<ul>
<li>プロセス管理：プロセスに対してCPU割り当て（今どのプロセスにCPU時間を割り当てるかをスケジュール・切り替え＝コンテキストスイッチ）</li>
<li>メモリ管理：アプリケーションへのメモリ割り当て（他のプロセスのメモリ領域を勝手にアクセスできないようにしたり、メモリ不足時はディスクにスワッピングしたり）</li>
<li>ファイルシステム管理：ファイル操作を仲介（実際にディスクを触るのはカーネルが行なっている）</li>
<li>ネットワーク管理：カーネルがパケット処理を行なっている</li>
</ul>
</li>
</ul>
</li>
<li>
<p>でもDockerfileでFROM句にubuntu:latestみたいな記述をしているよね&hellip;？</p>
<ul>
<li>ホスト側のLinuxカーネルを使うのに、コンテナ側でOS指定が必要な理由は何？という話</li>
<li>結論、これはユーザースペースのOS環境を指定しているだけ</li>
<li>ユーザースペースというのは、コマンドやライブラリ（bashとか）
<ul>
<li>Distrolessとか軽量なOSイメージを指定すると、デフォルトのままではcurl等のコマンドがインストールされておらず使用できないのは、コンテナ側のユーザースペースを使っているため</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="docker-image">Docker Image<a hidden class="anchor" aria-hidden="true" href="#docker-image">#</a></h3>
<ul>
<li>イメージは、任意のタイミングのスナップショットとしての役割を持つ</li>
<li>ファイルシステムのスナップショットである
<ul>
<li>もっとシンプルに表現すると、OSの中身のフォルダ構造一式をZIP圧縮したようなもの</li>
<li>例えばubuntuイメージの中身は、ユーザースペース（<code>ls /</code>した時に見るような bin/,etc/,lib/等）のファイル・フォルダ一式が入っている（でもカーネル部分は含まない）</li>
</ul>
</li>
<li>てっきりイメージ＝プロセスのスナップショットと理解していたけどそれは間違っていて、<strong>イメージ＝実行前のファイル群</strong>が正しい表現</li>
<li>イメージを指定するときの命名は&lt;イメージ名&gt;:&lt;タグ&gt;であり、&lt;タグ&gt;を省略するとlatestタグが自動的に付与される</li>
</ul>
<h4 id="レイヤー構造">レイヤー構造<a hidden class="anchor" aria-hidden="true" href="#レイヤー構造">#</a></h4>
<ul>
<li>Dockerイメージはレイヤーの積み重ね</li>
<li>RUNやCOPY毎に新しいレイヤが作られる</li>
<li>レイヤは読み取り専用で、キャッシュとして使い回せる</li>
<li>レイヤー構造である理由
<ul>
<li>キャッシュ：同じベースイメージなら、そのレイヤはpull済み</li>
<li>ストレージ節約：変更があった部分だけ新しいレイヤに保存
<ul>
<li>もし仮にレイヤ構造ではない場合はフルフルのものを保存しなければいけない</li>
</ul>
</li>
<li>高速化：レイヤー単位でダウンロード・展開</li>
</ul>
</li>
<li>docker pushすると以下のようなハッシュ値が表示されるが、これがまさにレイヤ構造（レイヤ単位で処理している）
<pre tabindex="0"><code>  The push refers to repository [123456789012.dkr.ecr.us-east-1.amazonaws.com/myapp]
  d4f4f6a4b8c2: Pushed 
  7a0437f04f83: Pushed 
  8c662931926f: Pushed 
  ...
</code></pre><ul>
<li>各レイヤのコンテンツハッシュ(SHA256)らしい
<ul>
<li>具体的にはそのレイヤの差分をtarアーカイブをgzipなりで圧縮→圧縮されたバイナリファイルをSHA256ハッシュ計算している</li>
</ul>
</li>
</ul>
</li>
<li>整理すると、Dockerイメージはファイルシステムのスナップショットであり、それはレイヤー構造になっている
<ul>
<li>以下のDockerfileを例に考えると、
<pre tabindex="0"><code>  FROM ubuntu:latest
  RUN apt-get update
  RUN apt-get install -y curl
</code></pre><ul>
<li>各行がレイヤとなっていて、そのレイヤで変更があったファイル群を持っているイメージ</li>
</ul>
</li>
<li>この上に、Dockerはコンテナ起動した時に、書き込みできるレイヤを作っている</li>
</ul>
</li>
<li>イメージとコンテナの違い
<ul>
<li>イメージ: 読み込み専用の複数のレイヤを重ねたもの</li>
<li>コンテナ: イメージに読み書き可能なレイヤを追加して起動したもの</li>
</ul>
</li>
<li>参考リンク
<ul>
<li><a href="https://docs.docker.jp/build/guide/layers.html">レイヤ — Docker-docs-ja 24.0 ドキュメント</a></li>
<li><a href="https://qiita.com/kompiro/items/4153b4066a1837be7f98">Dockerのまとめ - コンテナとイメージ編 #Docker - Qiita</a></li>
</ul>
</li>
</ul>
<h2 id="dockerfile">Dockerfile<a hidden class="anchor" aria-hidden="true" href="#dockerfile">#</a></h2>
<ul>
<li>COPY
<ul>
<li>2つの引数を設定する
<ul>
<li>1つ目はホスト側のディレクトリ、2つ目はDocker側のディレクトリ</li>
</ul>
</li>
<li>ホスト側のディレクトリは <code>docker build .</code> で指定したディレクトリ
<ul>
<li>この場合 <code>.</code> を指定しており、カレントディレクトリが参照される</li>
</ul>
</li>
<li>Docker側はデフォルトのパス、もしくは <code>WORKDIR</code> で定義されたディレクトリを参照する</li>
</ul>
</li>
<li>EXPOSE
<ul>
<li>このポートを使いますよというドキュメント的な宣言</li>
</ul>
</li>
<li>CMD
<ul>
<li>Dockerはここで設定したコマンドがフォアグラウンドで実行されている間が生存期間となる</li>
</ul>
</li>
</ul>
<h4 id="run-vs-cmd">RUN vs CMD<a hidden class="anchor" aria-hidden="true" href="#run-vs-cmd">#</a></h4>
<ul>
<li>RUN:
<ul>
<li>イメージビルド時に実行される</li>
<li>レイヤとしてファイルシステムに反映されキャッシュが効く</li>
</ul>
</li>
<li>CMD:
<ul>
<li>コンテナ起動時に実行される</li>
<li>イメージには反映せず、ただの実行時オプション</li>
</ul>
</li>
</ul>
<h4 id="cmd-vs-entrypoint">CMD vs ENTRYPOINT<a hidden class="anchor" aria-hidden="true" href="#cmd-vs-entrypoint">#</a></h4>
<ul>
<li>CMDはデフォルト設定で、オーバーライド可能</li>
<li>一方、ENTRYPOINTは起動時に必ず実行される</li>
<li>テクニックとしてENTRYPOINTでコマンドを指定し、CMDで引数を指定するというのがある（引数だけ利用者側で指定可能となる）</li>
</ul>
<pre tabindex="0"><code>基本的に CMD を使うのが良いでしょう。
ENTRYPOINT はDocker起動時のコマンドを強制します。
コマンドのラップをするDocker Image の場合は ENTRYPOINT のほうが好ましいですが、一般的なWebアプリケーションの場合は CMD を使用する方がユーザーにとって使いやすいDocker Image になります。
</code></pre><h4 id="copyは最後に実行するとキャッシュが効きやすい">COPYは最後に実行するとキャッシュが効きやすい<a hidden class="anchor" aria-hidden="true" href="#copyは最後に実行するとキャッシュが効きやすい">#</a></h4>
<ul>
<li>Dockerfileの前段で、<code>COPY . .</code>を実行してしまうと、ローカル側のソースコードが1文字でも変わっていると、そのレイヤのキャッシュが効かなくなる</li>
<li>レイヤーのキャッシュは、親が変わると問答無用でキャッシュ無効化されるので、<code>COPY . .</code>以降は全てキャッシュが利用されなくなる（レイヤは差分を持っているようなものだから、親が変更があったら当然子にも影響あるよねということだと理解した）</li>
<li>なので、変更が頻繁にあるような<code>COPY . .</code>の処理は、Dockerfileの中で後ろの方に持っていくと良い</li>
<li>Nodeならpackage系だけを最初にコピーする→依存関係をインストール→ソースコードをコピーしてくるみたいな形で工夫できる</li>
</ul>
<h2 id="container">Container<a hidden class="anchor" aria-hidden="true" href="#container">#</a></h2>
<ul>
<li>イメージがスナップショットだとすると、そのスナップショットから起動したプロセスがコンテナ</li>
<li>コンテナは「1つのコマンド（プロセス）をフォアグラウンドで動かす」ように設計されている
<ul>
<li>コンテナは1つのコマンドを隔離された環境で実行し、そのコマンドの実行がフォアグラウンドで終了するまで生存する</li>
<li>ライフサイクル
<ul>
<li>Image &ndash; (docker run &lt;$IMAGE&gt;) &ndash;&gt; RUNNING &ndash; STOPPED &ndash; DELETED</li>
<li>正常終了 or 異常終了 or docker killするとSTOPPED</li>
<li>docker rmするとDELETED</li>
<li>pauseすると停止状態を表すPAUSEDにもなる</li>
</ul>
</li>
</ul>
</li>
<li>プロセスの隔離
<ul>
<li>コンテナ内のプロセスはホストマシンや他のコンテナと隔離されて実行される</li>
<li>CMDもしくはENTRYPOINTで定義されたプロセスはPID 1となる</li>
</ul>
</li>
</ul>
<h2 id="network">Network<a hidden class="anchor" aria-hidden="true" href="#network">#</a></h2>
<ul>
<li>Dockerではネットワークの扱いが重要となる</li>
<li>1コンテナでは1プロセスを動かす設計となっている</li>
<li>nginxとphp-fpmのように複数プロセスを協調して動かす必要があるときはソケットではなく、ネットワークで通信を行うことが推奨されている</li>
<li>Dockerでのネットワークは特にKubernetes・ECS・docker-composeのような各種オーケストレーションツールを使用する際に意識する必要がある</li>
</ul>
<h3 id="driverの種類">Driverの種類<a hidden class="anchor" aria-hidden="true" href="#driverの種類">#</a></h3>
<ul>
<li>ネットワークドライバーはネットワークの振る舞いの定義で、デフォルトでは2種類ある</li>
<li>複数のコンテナ（プロセス）はネットワークを介して通信を行う</li>
</ul>
<h4 id="bridge">bridge<a hidden class="anchor" aria-hidden="true" href="#bridge">#</a></h4>
<ul>
<li>基本的にはこれ</li>
<li>コンテナごとに仮想IPが割り振られ、同じネットワークに属するコンテナ間で通信が可能</li>
<li>こうすることでコンテナ同士はコンテナ名で互いに名前解決して通信できる</li>
<li>少し深掘りすると..
<ul>
<li>何も指定せずにコンテナ起動すると、docker0という名前のbridgeネットワークに所属する
<ul>
<li>docker0というのははホストOS上に仮想ブリッジという仮想スイッチ</li>
<li>hostネットワーク &ndash; docker0（仮想ブリッジ） &ndash; コンテナA, B&hellip;という構成</li>
<li>この構成では、各コンテナに独立した仮想ネットワーク内のIPが与えられ、同じネットワークにいるコンテナ間はIPやホスト名で通信できる</li>
<li>コンテナに対し、外部からアクセスしたい場合はNAT変換によるポートフォワードが必要(ex: <code>docker run -p 8080:80 nginx</code>)</li>
</ul>
</li>
<li>Linuxカーネルのbridgeネットワークを使用する</li>
</ul>
</li>
</ul>
<h4 id="host">host<a hidden class="anchor" aria-hidden="true" href="#host">#</a></h4>
<ul>
<li>コンテナがホストのIPアドレスとポート空間（ネットワーク名前空間）をそのまま使う
<ul>
<li>仮想NICやブリッジを介さずに、直接ホストのIP・ポート空間にアクセスできる</li>
<li>例：コンテナが80番でListenすると、それはホスト側の80番ポートを使うことになる</li>
</ul>
</li>
<li>オーバーヘッドが少ない分通信が速いが、ポートの競合に注意する必要がある</li>
<li>ホスト側のlocalhost:80等でそのままコンテナにアクセスできるような仕組み</li>
</ul>
<h4 id="none">none<a hidden class="anchor" aria-hidden="true" href="#none">#</a></h4>
<ul>
<li>コンテナにネットワークを割り当てない</li>
<li>セキュリティ上、外部から完全に切り離したい時に使う</li>
</ul>
<h4 id="docker-composeにおけるネットワークの考え方">Docker Composeにおけるネットワークの考え方<a hidden class="anchor" aria-hidden="true" href="#docker-composeにおけるネットワークの考え方">#</a></h4>
<ul>
<li>Docker Composeはマルチコンテナを簡単に定義・管理できるツール</li>
<li>内部ネットワークは自動で作成される</li>
<li>各サービスは、自動で同じカスタムネットワークに所属するので、互いにサービス名で名前解決が可能となる（内部DNSによって解決されている）</li>
</ul>
<h2 id="volume">Volume<a hidden class="anchor" aria-hidden="true" href="#volume">#</a></h2>
<ul>
<li>データを永続化するための機能</li>
<li>Dockerコンテナは基本的にはエフェメラル（短命）なもので、ライフサイクルの終了とともにコンテナ上で作成されたファイルは消失する</li>
<li>ボリュームタイプには以下の2種類がある</li>
</ul>
<h3 id="data-volume">Data Volume<a hidden class="anchor" aria-hidden="true" href="#data-volume">#</a></h3>
<ul>
<li>コンテナのライフサイクルの外で管理されるファイル/ディレクトリの設定</li>
<li><code>-v &lt;CONTAINER PATH&gt;</code> or <code>-v &lt;HOST PATH&gt;:&lt;CONTAINER PATH&gt;</code></li>
<li>コンテナの外側＝ホスト側にファイルが保管される</li>
</ul>
<h3 id="data-volume-container">Data Volume Container<a hidden class="anchor" aria-hidden="true" href="#data-volume-container">#</a></h3>
<ul>
<li>他のコンテナで指定されているボリュームを参照するための機能（コンテナ間でボリュームを共有する）</li>
<li><code>--volumes-from</code>でコンテナ名を指定することで、別のコンテナのボリュームを参照できる</li>
<li>今の時代では、Named Volume(<code>-v mydata:data</code>)や上記のData VolumeのBind Mount(<code>-v &lt;HOST PATH&gt;:&lt;CONTAINER PATH&gt;</code>)を使用するケースが多そう
<ul>
<li>Named Volumeの補足として、Linuxの場合は大抵<code>/var/lib/docker/volumes/mydata/_data/</code>に保存される</li>
</ul>
</li>
</ul>
<h2 id="プロダクションでの活用tips">プロダクションでの活用Tips<a hidden class="anchor" aria-hidden="true" href="#プロダクションでの活用tips">#</a></h2>
<h3 id="セキュリティ">セキュリティ<a hidden class="anchor" aria-hidden="true" href="#セキュリティ">#</a></h3>
<ul>
<li>rootユーザーを使わない</li>
<li>野良のイメージをベースイメージにしない</li>
<li>ビルド時に機微情報を与えない
<ul>
<li>ビルド時にパスワードや秘密鍵のような機微情報を与え、最終イメージに残らないようにする</li>
<li>ビルド後に環境変数として渡すことがベストプラクティス</li>
<li>もし仮にプライベートリポジトリをクローンするなどをしたい場合、&ndash;secretや&ndash;sshオプションを使用する(シークレット情報を格納したファイルを渡すイメージ)ことで、ビルド時に一時的にファイルにアクセスし、最終的なイメージには残らないようにセキュアなビルドを行うようにする
<ul>
<li>この方法がなぜイメージに残らないのかというと、一時的なマウント(仮想的なtmpfs)としてビルド中のコンテナに提供されるだけであり、COPYやRUNコマンドで明示的に保存しない限り、イメージのレイヤーには一切含まれないため</li>
<li>逆に1行の中でRUN echo &ldquo;secret&rdquo; &gt; /tmp/hoge.txt &amp;&amp; rm -f /tmp/hoge.txtなどとまとめれば、レイヤーのスナップショットには残らない
<ul>
<li>これを2行に分けてしまうとRUN echo &ldquo;secret&rdquo; &gt; /tmp/hoge.txtのみキャッシュが効いてしまい、最終イメージにファイルがそのまま残ってしまう</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>.dockerignoreファイルでローカルの不要なパスを無視する
<ul>
<li>.envのようなDBへの接続情報が記載されているようなファイルをビルドに含めないように、.dockerignoreを管理する（そうすればビルド時に無視される）
<ul>
<li>具体的には、Dockerクライアントはdocker build実行時にビルドコンテキスト全体をDockerデーモンに送るが、.dockerignoreで指定されたものは転送対象から除外される（COPYコマンドでも同じ）</li>
</ul>
</li>
<li>まぁそもそも.envに直接ベタでセキュアな情報を残すのも良くないとは思うが（ローカルでは必要ないはずだし、クラウド環境の秘匿情報はクラウド上の適した場所＝AWSならSecretsManager等に保存するべきはずだし..）</li>
</ul>
</li>
<li>イメージを塩漬けにしない
<ul>
<li>ECRのイメージスキャンやDependabot Security Update等を活用したら良さそう</li>
<li>GitHub ActionsでDocker社公式のdocker/scout-actionというCVEベースの脆弱性検知を行ってくれるみたい</li>
<li>Dockerfileでマルチステージビルドを行い、Dockerfile内でセキュリティツールを実行する</li>
<li>Snykをサイドカーとして動かしてリアルタイムでの自動検知</li>
</ul>
</li>
<li>ファイルのマウントが必要な場合は最小限にする
<ul>
<li>ホストのファイルをマウントする場合はRead-Onlyなど権限は必要最低限にする</li>
<li>特にdockerソケット(<code>/var/run/docker.sock</code>)の扱いは注意
<ul>
<li>dockerソケットとは、Dockerデーモンが提供するUNIXソケットファイル</li>
<li>このソケットを通じて、docker buildやrunなどのCLIコマンドはデーモンと通信している（つまりDocker APIの入口）
<ul>
<li>ホストファイルシステムの改ざん（削除して破壊等）やホストネットワークの操作・盗聴などなど</li>
</ul>
</li>
<li>ただ、CIや監視などでdockerソケットのマウントを要求するツールはあるので、その場合はRead-Onlyでマウントするようにする</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="マルチステージビルド">マルチステージビルド<a hidden class="anchor" aria-hidden="true" href="#マルチステージビルド">#</a></h3>
<ul>
<li>イメージのサイズが大きいとPullに時間がかかってしまい、リードタイムが長くなる</li>
<li>リードタイムが長くなると、
<ul>
<li>デプロイ・ロールバックが遅くなる</li>
<li>スケールアウトが遅くなり、コンテナ起動が間に合わず、リクエストを捌けなくなる</li>
<li>レジストリの保存料が高くなる</li>
</ul>
</li>
</ul>
<h3 id="イメージの仕組みと設計">イメージの仕組みと設計<a hidden class="anchor" aria-hidden="true" href="#イメージの仕組みと設計">#</a></h3>
<ul>
<li>DockerイメージはDockerfileによって作成されるスナップショットであり、そのDockerイメージをもとに起動するのがコンテナ</li>
<li>1コンテナ1プロセスの原則
<ul>
<li>なぜ1コンテナ1プロセスが良いか？
<ul>
<li>可観測性
<ul>
<li>プロセス単位でメトリクスやログ収集がしやすい</li>
</ul>
</li>
<li>責務の明確化
<ul>
<li>まぁ責務は明確にして分離すべきという話</li>
</ul>
</li>
<li>リソース制御
<ul>
<li>CPUやメモリの利用量をプロセス単位で制御できる</li>
</ul>
</li>
<li>障害隔離性
<ul>
<li>複数のプロセスが同一コンテナにあると、一方のクラッシュがもう一方に影響しやすい</li>
</ul>
</li>
</ul>
</li>
<li>とは言っても、全てのケースで1コンテナ＝1プロセスといく訳ではないので、1つのコンテナにつき1つの責務を目安にすると良い</li>
</ul>
</li>
<li>コンテナ設計の指針となるThe Twelve-Factor App
<ul>
<li><a href="https://12factor.net/ja/">The Twelve-Factor App （日本語訳）</a></li>
</ul>
</li>
<li>ファイルシステム
<ul>
<li>イメージはRead-Onlyで、その上にRead-Write可能なコンテナレイヤが立ち上がるのがイメージとコンテナの仕組み
<ul>
<li>下位コンポーネントがイメージ（Read-Only）、上位コンポーネントがコンテナ（Read-Write）</li>
</ul>
</li>
</ul>
</li>
<li>ステートレスなコンテナにする
<ul>
<li>コンテナは廃棄容易性に優れている反面、データの永続化を苦手としている</li>
<li>ステートを持たないことで特定の環境に依存せず、高い可搬性を実現できる</li>
</ul>
</li>
<li>ログは標準出力に出す
<ul>
<li>ファイルに吐くとステートを持つことになる</li>
<li>標準出力に吐いて収集するようにする</li>
</ul>
</li>
</ul>
<h3 id="dockerfileのベストプラクティス">Dockerfileのベストプラクティス<a hidden class="anchor" aria-hidden="true" href="#dockerfileのベストプラクティス">#</a></h3>
<ul>
<li>軽量なベースイメージを選択する
<ul>
<li>公式が提供するイメージは軽量なslimというタグがついたイメージが存在する</li>
<li>Google Cloudはdistrolessというシェルなどが入っていないシンプルで軽量なイメージを提供している</li>
<li>理想はdisrolessだが、シェルなどのツール群が入っていないのでまずはslimを使用するのがおすすめ</li>
<li>alpineイメージがおすすめできない理由
<ul>
<li>軽量ではあるが、alpineのベースOSの歴史的系異常扱いが非常に難しい</li>
<li>元々フロッピーディスクに入るような軽量なOSとして開発された軽量化に特化したもので、逆にそれ以外の非機能要件を満たせないことが多々ある</li>
<li>調べると色々出てくるけど、基本的には標準ライブラリが（一般的なLinuxディストリビューションと）異なるための互換性が弱いこととパフォーマンス面に懸念があることっぽい
<ul>
<li>参考: <a href="https://engineering.nifty.co.jp/blog/26586">とりあえずでDockerイメージにAlpine Linuxを選択するのはやめましょうという話 - NIFTY engineering</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>.dockerignoreを使用する
<ul>
<li>Dockerビルド時に無視するファイル・ディレクトリを指定することができる</li>
<li>Dockerfile自体不要だし、node_modulesもイメージビルド時にインストールするから不要とかそんな感じ</li>
</ul>
</li>
<li>ビルド時に複数のアーキテクチャに対応させる
<ul>
<li>Docker v19からbuildxというサブコマンドが増えた（ex: <code>docker buildx build</code>）</li>
<li>以下のようなコマンドで、複数アーキテクチャに対応可能
<pre tabindex="0"><code>  $ docker buildx build \
  --load \
  --platform linux/amd64,linux/arm64 \
  -t multi-platform \
  .
</code></pre></li>
<li>本番とローカルでアーキテクチャが異なる場合に便利</li>
</ul>
</li>
</ul>
<h2 id="自分で調べたこと">自分で調べたこと<a hidden class="anchor" aria-hidden="true" href="#自分で調べたこと">#</a></h2>
<h3 id="識別子">識別子<a hidden class="anchor" aria-hidden="true" href="#識別子">#</a></h3>
<p>Dockerのイメージやコンテナを識別する時、結局何で識別するんだっけ？となりがちなのでまとめる。
ここでいう識別というのは「イメージを指定してコンテナ起動」とか「コンテナを指定して停止・削除する」とかその辺りを指してます。</p>
<ul>
<li>イメージ
<ul>
<li>イメージ名で識別する</li>
<li>イメージ名は「リポジトリ名:タグ名」で構成される
<ul>
<li>タグ名は省略可能で、省略した場合はlatestが付与される</li>
</ul>
</li>
<li><code>docker build -t repository-name:tag-name</code> といった形で</li>
</ul>
</li>
<li>コンテナ
<ul>
<li>コンテナ名 or コンテナID</li>
<li>コンテナ名は、起動時に指定が可能
<ul>
<li><code>docker run --name mycontainer image-name</code></li>
</ul>
</li>
<li>コンテナIDは、起動時に自動付与される一意の識別子
<ul>
<li>通常64文字の英数字だが、先頭の12文字程度で識別可能</li>
<li><code>docker ps</code>で確認可能</li>
</ul>
</li>
</ul>
</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Docker on x"
            href="https://x.com/intent/tweet/?text=Docker&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocker%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Docker on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocker%2f&amp;title=Docker&amp;summary=Docker&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocker%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Docker on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocker%2f&title=Docker">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Docker on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocker%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Docker on whatsapp"
            href="https://api.whatsapp.com/send?text=Docker%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fdocker%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Docker on telegram"
            href="https://telegram.me/share/url?text=Docker&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocker%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Docker on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Docker&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fdocker%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">nyuusen blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
