<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/my-hugo-blog/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=my-hugo-blog/livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>GitHub CICD実践ガイド | nyuusen blog</title>
<meta name="keywords" content="">
<meta name="description" content="1章 ソフトウェア開発とGitHub

継続的インテグレーションとは？

コードの変更を頻繁にコードベースに統合し、正しく動作するかを繰り返し検証する
統合頻度が上がるとコンフリクトが減る
繰り返して検証を行うとバグを発見すれば素早く修正できる
ソフトウェアが安定して動けば、ユーザーの満足度も向上する


継続的デリバリーとは？

リリースしないとユーザーには価値を提供できない
いつでも安全にリリースできる状態を保ち、ソフトウェアを繰り返し改善する
CIとCDは同列の概念に見えるが、CIはCDに包含される



2章 GitHubActionsの基礎概念

実行時エラー

コマンドの終了ステータスが0ならば成功、0以外ならば失敗見なされる
なので、ワークフローでは終了ステータスを適切に返すことが大事


手動実行

on: workflow_dispatchで手動実行できる
inputとして、列挙型となるchoice型の指定が可能


定期実行

on: schedule: cron()で定期実行できる
時刻はUTCなので注意


実行環境

GitHub-Hosted Runners

GitHubが提供するマネージドな実行環境
LargerRunnersというマシンスペック向上したものも利用可能（有料）
サポートOSとしては、Linux(Ubuntu)/Windows/macOSがある
よく使用するDocker,Node.js,npmなどは既にインストールされている

ただし、バージョン固定はできないので、バージョン固定で使用したい場合は、ワークフローの中で自分でインストールする必要ある


エフェメラルという特性

ジョブ終了時に破棄されるので、毎回クリーンな環境でジョブを実行できる
この特性は一貫性向上に貢献している




Self-Hosted Runners

利用者が実行環境を用意する




MarketPlace

再利用できるワークフローが公開されている
著名な組織にはVerifiedCreatorsマークがついているので、そういうのを利用するとセキュリティ不安が低減する（100%安全とは言い切れないが）


料金

パブリックリポジトリなら無料
プライベートは使用時間とストレージ使用量で計算される
月毎に無料枠があり、それを超えると課金が発生するが、支払い設定をしていない場合は実行できなくなるだけ（なので安心できる）
使用時間は、実行時間×ランナーごとの料率で計算される

料率はubuntuが1,Windowsが2,macOSが10なので、なるべくUbuntuを利用するのがオススメ





3章 ワークフロー構文の基礎
環境変数

単一のワークフローで使用できる
envで定義する
ワークフロー・ジョブ・ステップで定義可能

定義した場所で、環境変数のスコープが異なる


中間環境変数

コンテキスト(github.base_refのように参照できるもの)は、各ジョブ(ステップ)の中で直接スクリプトに埋め込むのはNG

理由: スクリプトインジェクションにリスクがあるため


envの中で一度変数展開し、スクリプト内ではダブルクオテーションで囲むことが推奨される

変数展開することでメモリ上で保存されるので、スクリプト生成プロセスには生成プロセスには相互作用しないため


GHAに限らず、シェルスクリプト全体で言えること



Variables

複数のワークフローで使用できる
varsコンテキストでアクセスする
こちらも参照時は中間環境変数経由(envの中で環境変数に展開してから)が推奨

Secrets

以下の特徴がある

登録した値は暗号化され、GitHub内で安全に管理される
ログ出力時はマスクされる
登録後の値確認は不可となる


ログマスクのアルゴリズムは完全一致のみ、1文字スペースを加えたりするだけで出力されてしまうので、ログマスクは当てにしないようにする

そもそもsecretsの値はログ出力しないようにしましょう



expressions(式)

${ example }のような形で定義
リテラルや演算子などが使用可能
比較演算の際、GHAでは異なる型の値を比較すると、勝手に値が変換されるので注意
オブジェクトフィルター

配列やオブジェクトから指定したプロパティを抜き出し、配列を生成する
${{ github.event.*.html_url }}のような形で*を使用する



条件分岐(if)

ifの少し面白い使い方として、最初のジョブへ条件分岐を定義し、特定の条件でスキップするようにすると、ワークフロー自体の実行がスキップできる

使用時間もゼロになり、コスト削減につながる



ネーミング

実行ログが見やすくなるのでジョブ名やステップ名はきちんと書く
run-nameは、nameとは異なり、コンテキストが利用できる

run-name: Run by ${{ github.actor }}



ステップ間のデータ共有

2つのやり方がある

GITHUB_OUTPUT環境変数

定義: echo &ldquo;=&rdquo; &raquo; &ldquo;${GITHUB_OUTPUT}&rdquo;
参照: ${{ steps..outputs. }}
参照方法を見ると分かる通り、ステップ間の依存関係が明白


GITHUB_ENV環境変数

定義: echo &ldquo;=&rdquo; &raquo; &ldquo;${GITHUB_ENV}&rdquo;
参照: ${GITHUB_ENV}
ステップIDの指定が不要なので、どのステップで環境変数を設定したかを意識する必要ない
異なる複数のステップで、同じ値を参照する場合に使える（ただしステップ間の依存がわかりづらくなる）
これで定義したものは、事実上グローバル変数なので、ワークフローが大きくなるとバグの原因になるので注意が必要


特にこだわりなければ、GITHUB_OUTPUTを使用する



GitHub APIの実行

GitHubHostedRunnerの場合は、GitHub CLIがインストールされているのでそれを使うと良い
API(CLI)の実行にはトークンが必要

GHAには簡単に使えるクレデンシャルが利用できる
ワークフロー開始時に自動生成、終了すると自動的に破棄
有効期限は、ワークフロー実行中のみなので、万が一漏れても影響範囲は限定的
取得方法は、${{ secrets.GITHUB_TOKEN }} もしくは ${{ github.token }}

どちらでも良いので、どちらかに統一するのが良い


トークンの指定は、GITHUB_TOKENもしくはGH_TOKENという名前の環境変数をセットするだけで、自動で読み込んでくれる


パーミッション

ジョブレベルとワークフローレベルで指定可能
スコープ(contents, pull-requests等)とそれに対するアクション(read, write, none)を設定する
ただしワークフローを実行しているリポジトリ以外のアクセスは許可されない
パーミッションを明示的に定義していない場合、自動でソースコードの読み込み許可はされる

一方、明示的な定義をする場合は、この暗黙的な挙動は無視されるので注意




パーミッション周りのトラブルシューティング

ワークフロー実行ログのSet up jobの中に、GITHUB_TOKEN Permissionsがあるので、そこで実行時のパーミッションを確認できる



スターターワークフロー

GitHubリポジトリのActionsからNew Workflowを選択すると、ワークフローのコレクションが並んでいるので、参考にできそう

https://github.com/actions/starter-workflows?tab=readme-ov-file



4章 継続的インテグレーションの実践

大体以下の流れでワークフローを構成する

checkout
setup(ex: actions/setup-go)
リントやテストの実行


フィルター

pathsと他の条件を指定するとAND条件になる


静的解析

actionlintは、GHAワークフローの静的解析を行ってくれるので便利


使用時間の削減（どのワークフローでも有用な設定）

ジョブ・ステップレベルのタイムアウト設定

どのワークフローにも設定するようにする（GHAのデフォルト値は360分と大変長いため）


自動キャンセル（新しいコミットが追加されたら、古いコミットで動作しているワークフローを自動でキャンセルする）


シェル

ステップごとに起動シェルをshellキーで設定可能
Ubuntuの場合、省略時はbashだが、shellキーの指定有無で起動オプションが変更される
全ステップに書くのは面倒なので、ワークフローのトップレベルにデフォルト設定(defaults句)するのが良い
デフォルトシェルにはデメリットは存在しないので、全てのワークフローに機械的に入れるのがオススメ



Concurrency

ワークフローはイベント駆動なので、イベントが発生すると起動、さらにまたイベントが発生すると起動することになる
起動制御できる仕組みとして、Concurrencyがある
concurrency: &lt;group-name&gt;とすることで、同一グループの多重制御が設定できる

さらにcancel-in-progress: trueで自動キャンセルの設定も可能（プルリクエストで最新ではないコミットのCIとかに有効）



CIの黄金律

「クリーンに保つ」

全てのステータスチェックが成功した時だけマージできるようにする


「高速に実行する」

CIの実行が遅いと、待ち時間に他の作業→CIで失敗したらその対応する時にコンテキストスイッチが必要になる
時間の無駄だし、開発効率の低下につながる
CIのスピードは大切で、理想は5分以内、遅くとも10分以内に終わらせるように


「ノイズを減らす」

CIからのフィードバックで価値ある情報の「シグナル」とそうではない「ノイズ」
判断基準としては、その情報を受け取り、これは気にしなくて良いやと流したならそれがノイズ
ノイズがあると、シグナルもスルーされてしまうので、ノイズは意識的に減らす



テスト

単体テストの割合を増やす
フレーキーテストを放置しない（閾値を超えるとテスト全体が信頼されなくなる）

Googleソフトウェアエンジニアリングでは閾値は1％とされている


遅いテストは実行タイミングをPRマージの時に限定するなど工夫する
使用しているテストツールで以下のような機能を利用する

部分実行
並列実行
シャッフル実行（テスト間の隠れた依存関係も洗い出せる）
カテゴリ実行（スローテスト用のカテゴリを作ってそれだけ実行しないみたいな）



静的解析

不要な警告は無視するのではなく抑止する

ignoreやsuppressのキーワードで検索する
抑止理由はコメントやコミットメッセージに残しておく



第5章 運用しやすいワークフロー設計

長期運用で役立つプラクティスの紹介

ロギング

ワークフローの再実行時の「Enable debug logging」を有効にすると、デバッグログが確認できる
デバッグログには以下がある

ステップデバッグログ

ステップのログの詳細（ステップステータスや各種コンテキスト）をトレースできる
SecretsまたはVariablesに「ACTIONS_STEP_DEBUG」をtrueで登録しておくことで、これらの値も確認できる


他は内部実装者向けだったりするので、割愛


Bashのトレーシングオプション

デバッグログよりシンプルで、どんなコマンドが実行され、結果はなんだったのかを知りたいケースで使用する
Bashのトレーシングオプションは、set -xを実行するだけなので、手軽だが強力
全てのコマンドが実行前に表示されるようになり、どのコマンドがどのような引数で実行されているかを確認できる


ログのグルーピング、手動マスク等もある

レポーティング

アノテーション

echo &quot;::error::This is error&quot;みたいな形で書くとジョブページにみやすい形で表示


ジョブサマリー

シンプルなテキストならアノテーションで十分だが、複数行表示したい場合等はマークダウン形式で出力される${GITHUB_STEP_SUMMARY}が便利



複数ジョブの実行制御

デフォルトでは複数のジョブを実行すると並列実行される

並列実行は、全体の実行時間を短縮できる
もしジョブの実行時間の長さに問題がある場合は、ジョブを細かく分割し、並列実行させるというアプローチもある


逐次実行させたい場合は、needsを使用する
ジョブ間のデータ共有

$GITHUB_OUTPUT環境変数に出力し、stepsコンテキスト経由で受け渡す
受け取る側は、needsコンテキストを経由で受け取る



Environments

環境差分をパラメータ化でき、VariablesとSecretsがある
参照方法は、通常のVariablesとSecretsと同一(vars.xxx, secrets.xxx)
よくあるのはワークフローの入力値で環境名をもらい、それをenvironmentsにセットし、同じ変数名(環境ごとに値が異なる)を参照

キャッシュ

actions/cachedでGHA上にキャッシュとその利用が可能
実行時のパラメータとして

key: キャッシュキー。生成と保存に利用する。
path: キャッシュ対象となるディレクトリ/ファイルパス。
restore-keys: キャッシュミス時のリストアキーを複数指定する。


キャッシュ復元時に挙動

①keyキーに定義したキャッシュキーと厳密に一致するキャッシュを探す
②リストアキーの定義順に、プレフィックスが一致するキャッシュを探す
リストアキーは省力可能であり、これはパッケージマネージャーと併用するときに威力を発揮する

大半のパッケージマネージャーはキャッシュにないファイルだけダウンロードするように振る舞う




キャッシュは、7日以上アクセスされないと自動削除される

ブラウザからリポジトリ画面で手動削除も可能


合計サイズは、リポジトリで10GBまで

キャッシュキーの設計

プラットフォームごとに異なるキャッシュを利用するようにする

キャッシュは最低でもOSごとに分離する
他にもCPUアーキテクチャや言語バージョン、パッケージマネージャーもキャッシュキーの候補
例えば、OSとCPUアーキテクチャでキャッシュを分離するなら: key: example-${{ runner.os }}-${{ runner.arch }}


依存関係を更新した時だけキャッシュを変更するようにする

package-lock.jsonのようなロックファイルがある場合、そのファイルハッシュをハッシュキーに指定する

hashfiles(&#39;**/package-lock.json)


ロックファイルが更新されない限り、キャッシュが利用されるようになる



アーティファクト

ワークフロー内で生成したファイルをアーティファクトと呼ぶ
アーティファクトはGitHubストレージへ一時的に保存ができる

ビルドしたバイナリやメトリクスデータの保存に利用できる


アーティファクトの保存はデフォルト90日で、保存時にパラメータ(retention-days)で指定可能

プライベートリポジトリだとストレージ容量は課金対象のため、保存期間を短くすると節約できる



6章 アクションによるモジュール化

ここでいう「アクションによるモジュール化」とは、ワークフローにおける小さな部品（ステップやコマンドの小さな単位）をモジュール化すること
ランナーは、呼び出し元ワークフローに依存する
アクションの実装方式は以下の3つがある

Composite: YAMLで定義
JavaScript: JSで定義
Docker Container: Dockerで動かす(ビルド・起動するDockerfileを指定)

これらはrunsのusingキーで指定する(ex: using: composite)




アクションのロケーションは「ローカル」と「リモート」がある

リモート: uses: actions/checkout@v4

URLと連動する
@v4の部分はGitのタグ（ブランチやコミットハッシュも指定可能）


ローカル: uses: ./.github/actions/hello/

先頭部分が.であることが目印
ルートディレクトリを起点にパスを記述する





CompositeAction

メタデータファイル(action.yml)が必要
メタデータ構文のワークフロー構文との違いや注意点

シェル指定が必須
githubコンテキストのeventプロパティの使用は避ける

アクションはトリガー指定ができないので、呼び出し元のワークフローによりeventの中身がガラリと変わるため


variablesとsecretsは直接参照できない

inputとして渡す必要あり

secretsを渡したらログ出力時のマスクはしてくれる




環境変数のスコープはワークフローに準拠する

ワークフロー側で定義した環境変数は参照できるし、アクション側で書き出した環境変数はワークフロー側からも参照可能


パーミッション定義できない

ワークフロー側で制御するようにする
つまり呼び出し側ワークフローでパーミッション定義を忘れると実行エラーが発生するので、どのようなパーミッションが必要かはREADMEなどに残しておくのがオススメ





アクション設計プラクティス

認知負荷の低減

利用者はコードが読みたいのではなく、アクションを使いたいだけ
なのでアクションの名前と概要はきちんとわかりやすいように書く（input/outputも）


secrets.GITHUB_TOKENの取り方

アクションからsecretsは参照できないのでsecrets.GITHUB_TOKENは参照できないが、github.tokenで同じ値を参照できる


スクリプトの切り出し

内部ロジックが大きくなってきたらshファイルとして別で切り出すと良い
切り出したshファイルは、GITHUB_ACTION_PATH環境変数で実行する必要がある

run句に単純なshファイルへの相対パスを指定するだけでは実行できない




環境変数による暗黙的な依存の回避

ワークフローとアクションで相互に環境変数は参照できるが、必要な値はinputs/outputsで明示的に受け渡すようにするのが良い
コードが追いづらくなるのと、意図せず壊れてしまうリスクがある


ロググループ化の活用

まず大前提としてきちんとログを出力する（デバッグ効率が圧倒的に良くなるため）
CompositeActionのログはステップごとに分割されないのでログを追うのが難しくなる
なのでロググループ化を活用する



アクションとNodeバージョン

GitHubが提供する多くのアクションはJSで実装されている
Nodeバージョンが上がるとアクションのメジャーバージョンが上がることが多い
このバージョンアップ作業が地味に大変な作業&hellip;

7章 クリーンなリポジトリの維持
リポジトリルール

ブランチプロテクションルールを設定しよう
コードオーナーを設定して全てのコードにオーナーシップを維持しよう

自動でコードオーナーにレビュー依頼が飛ぶ


シークレットスキャンを導入して、秘匿情報混入を検出しよう

コードやIssueの本文やコメントなどもチェックしてくれる
GitHubが定期的にチェックする（つまり事後）
プッシュプロテクションをEnableにすると、プッシュするタイミングでチェックが走る



ドキュメント

READMEは読み手のことを考える
LICENSEは確認するようにする

MITは、責任とらないけど自由に使ってねくらいのニュアンス


コミュニティヘルスファイル

CONTRIBUTING.md: コントリビューション方法のガイド（PRやIssueの出し方、コーディング規約）
CODE_OF_CONDUCT.md: 行動規範
SECURITY.md: 脆弱性報告方法など



8章 Dependabotによる依存関係バージョンアップ

ソフトウェアは何もしないと壊れるので、変更し続ける必要がある

依存関係の管理には、検知・把握・実装・テストという活動が必要


Dependabotには以下3つの依存関係の管理をサポートする機能がある

Dependabot version updates: 最新バージョンへの自動アップデート
Dependabot security updates: 脆弱性を含むバージョンの自動アップデート
Dependabot alerts: 脆弱性が含まれるバージョンのアラート通知


ワークフローで実践

ブランチプロテクションルールを設定し、全てのステータスチェックを行ってからマージしたい場合

GitHub CLIのmergeコマンドに--autoをつけることで、全ワークフローの成功状態になった後に、自動でマージしてくれる




Dependabotが起動したワークフローは通常のsecretsへのアクセスができないので、Dependabot用のsecretsを登録する必要があるので注意

厄介なのが何もエラーが出ず、空文字で処理が進むので、頭の片隅に入れておくと良い


dependabot/fetch-metadataアクションを活用する

Dependabotが起動するワークフローで使用可能で、バージョンアップ・依存関係の種類、パッケージエコシステムを取得できる
有効活用の例

パッチバージョンの場合は自動マージ
開発環境向けの変更は自動マージ
GHA向けの変更は自動マージ
このように少しでも手動対応量を減らすことで、少しでも楽をする





9章 GitHub Releasesによるリリース自動化

バージョニング

いつどんな変更が行われたのかをバージョンを併記してユーザーに知らせることができる
トラブル時はバージョン情報をやり取りすることで関係者間の意思疎通が楽になる
開発者としてもどのバージョンで不具合が発生したかがわかれば、修正が楽になる


セマンティックバージョニング

メジャー.マイナー.パッチという構成のバージョニング方式
順序性だけでなく、後方互換性に関心を寄せているのが特徴
完璧ではない（後方互換性が個人の考え方やスキルに依存する点）が、有名であること視認性が高いことで、選択としては無難である


Gitタグの保護はやっておこう（ブランチ保護と同じような感じ）

ReleasesがGitタグに依存しており、そのGitタグが削除された場合、リリースノートは下書き状態となってしまうため



10章 GitHub Packagesによるパッケージ管理

パッケージエコシステム

npmやMavenなどの言語パッケージ、HomebrewなどのOSパッケージ、Dockerなどのコンテナイメージもパッケージの一種
ソフトウェアのインストール・管理（依存関係の把握、ライブラリが足りなければ自動でダウンロード、新しいバージョンの検知、最新版へのアップデート等）を容易にする
提供者はパッケージマネージャークライアントを通じてパッケージを作成・登録＆メタデータを提供し、利用者はパッケージマネージャークライアントを通じてパッケージを検索・取得・更新＆依存関係を解決する（そしてこの両者をつなぐのがパッケージレジストリ）


ContainerRegistryの話がメインで、使いそうもないのでスキップ

11章 OpenID Connectによるセキュアなクラウド連携
クラウドプロバイダのクレデンシャル

クラウドプロバイダは誰がアクセスしようとしているかを「認証」によって判断する
クレデンシャルは、その認証に利用するもので、ユーザーIDとパスワードもその一種
認証する側が、アクセスキーやAPIキーといった呼び名のランダム文字列を発行し、それをクレデンシャルとして利用する
プログラムがリクエスト時にそのクレデンシャルを一緒に送信することで、認証と認証情報が正しければ正常レスポンスを受け取れるという仕組み
静的クレデンシャル

長期にわたって変更しないパスワードのようなクレデンシャルを静的クレデンシャルという
静的クレデンシャルは長命という欠点があり、漏洩した場合の被害が拡大しやすい


一時クレデンシャル

こちらは必要なタイミングで都度払い出すので短命
ローテーション作業もないので運用も楽
OpenID Connectというプロトコルによって実現する


クラウド連携のアンチパターン

静的クレデンシャルは使用してはいけない
かつてはそれしか選択肢がなかったので、記事を探すときは要注意



OpenID Connect(OIDC)

これは複数の異なるドメインで認証結果を共有し、協調してサービスを提供するオープンなプロトコル（アイデンティ連携を実現する）
OAuth2.0を拡張する形で設計されている
利点として、GitHub上で静的クレデンシャルの管理が不要になる(一時クレデンシャルを取得するため)＋認証時にアクセス元を細かく制限できる（GHAの場合特定リポジトリのみに許可できる）

一時クレデンシャルの取得フロー

ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する


GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider)
OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ)
一時クレデンシャルで操作


大抵の処理は隠蔽されており、私たちは行う作業は以下の2つのみ（準備に若干手間はかかるがメリットが大きい）

クラウドプロバイダ側でOIDCに必要なコンポーネントを作成する
ワークフローへクラウドプロバイダの認証アクションを組み込む



OIDC TrustとCloud Roles

クラウドプロバイダで準備するコンポーネントは以下の2つ

OIDC Trust: クラウドプロバイダが信頼するOIDC Providerを設定(GitHub OIDC Provider)

OIDCトークンで一時クレデンシャルを取得できる理由は、クラウドプロバイダがOIDC Providerを信頼しているため（OIDC Trust）
OIDCトークンはJWT形式で、GitHub OIDC Providerの公開鍵を使って署名等の検証が行われる


Cloud Roles: 一時クレデンシャルのアクセス先とアクセス元を制御

一時クレデンシャルの「アクセス先」を管理する
AWSでいうIAMロールのこと





認証アクション

各クラウドプロバイダは公式で認証アクションを提供しているので、ワークフローからはそのアクションを呼び出すだけで、OIDCが扱える

検証作業のリスクヘッジ

プライベートリポジトリで試す
認証パラメータ(AWSアカウントIDやIAMロール名)はSecretsで管理する

これらクレデンシャルではないものの、ログ出力時にマスクされるので、謝ってパブリックリポジトリでワークフローを実行しても、第三者へ余計な情報が漏れない



AWSにおけるOIDC利用準備と連携

以下の2つを作成する

OIDC Provider

AWSがGitHub OIDC Providerを信頼するように設定


IAMロール

一時クレデンシャルのアクセス先とアクセス元を制御する




GHAワークフロー側での設定作業

Secrets登録

AWSアカウントID
IAMロール名




ワークフロー実装

permissions

id-token: writeの設定が必要

GitHub OIDC ProviderからOIDCトークン取得に必要




aws-actions/configure-aws-credentialsを利用

ロールARNとセッション名、デフォルトリージョンをパラメータとして指定する
セッション名は、トレーザビリティを目的に、AssumeRole APIに渡すパラメータ名であり、CloudTrailのセッション名として記録される

「誰が・いつ・どのジョブでこのセッションを作ったか分かる」ような情報を含めると便利
例：&quot;${{ github.workflow }}-${{ github.run_id }}-${{ github.actor }}&quot;






CloudRolesのセキュアな運用

他のリポジトリからアクセスできないことを確認しておく
CloudRolesは目的ごとに分離する（必要最小限の権限だけ）
クラウドプロバイダの設定作業にIaCを導入する



12章 コンテナオーケストレーションのデプロイメント

デプロイ自動化の流れ

コンテナビルドアクション：コンテナイメージのビルド＆プッシュ
コンテナデプロイアクション：タスク定義の書き換えとサービスの更新


本番環境へのデプロイはルールを制限したい

Deployment branches and tagsを設定する

Environmentsからブランチ名パターンを登録することでパターン外のブランチでワークフローを起動できなくなる


Required Reviewers

ワークフローの起動に承認を必須とする





デプロイメント設計

デプロイの設計では「ユーザー影響」と「ロールバック」の観点に着目する
ローリングアップデート

ECSのデプロイ方式
新しいバージョンへ少しずつ置き換える
無停止


ロールバック

ローリングアップデートの場合は特別な仕組みはないので、リバートコミットを追加し、再デプロイする（あまり速くない）
人間が切り戻しを検知・判断するので、別途監視の仕組みが必要となる



第14章 GitHub Actionsの高度な使い方
Reusable Workflows

アクションは比較的小さな処理をカプセル化するのに対し、Reusable Workflowsはワークフロー全体を丸ごとカプセル化する
パーミッション

パーミッション定義を省略した場合は呼び出し側ワークフローのパーミッションを暗黙的に継承する
呼び出し側より厳しくできるが、緩めることはできない

なので、呼び出し側ではジョブレベルでパーミッションを定義すると良い（Reusable Workflowsの権限が最小限になるため＋ドキュメンテーションとなり可読性が向上する）




コンテキスト

呼び出し側ワークフローのコンテキストを直接参照できる
ただしReusable Workflowsが制御できないgithub.eventプロパティを参照すると再利用性は低下するので注意が必要


Secrets

呼び出し側ワークフローのコンテキストを直接参照できない
入力パラメータ経由で渡す or 呼び出し側でsecrets: inheritを指定するとまとめて継承可能

暗黙的な継承となりコードが追いづらくなるので個別で入力パラメータとして渡すのが良い




環境変数

こちらも参照できないので入力パラメータ経由で渡す



fromJSON関数

動的なワークフロー定義

事前にマトリクスを生成できない場合、fromJSON()をmatrixに指定することで動的にマトリクスを生成できる


文字列の型変換

ワークフロー構文の環境変数はstring型として扱われてしまう
その際string型の文字列をnumber型やboolean型に変換できる



エラーハンドリング

Continue on Error

デフォルトではエラーが発生するとその時点でワークフローが停止する
continue-on-error: trueを指定すると、エラーを握りつぶし、次の処理に進む
これを指定すると、途中でエラーが発生しても、ワークフロー自体は正常終了扱いされる
ログを見ない限りエラーには気づけないので、リカバリー不要な場合のみ使用する


マトリックスのフェイルファスト

マトリックスを使うと複数のジョブが並列に起動する
途中でエラーが発生した場合、他のジョブが止まる
fail-fast: falseを指定することで他のジョブを継続可能とできる



コンテキストによるフロー制御

終了状態を取得できるコンテキスト

stepsコンテキスト：ステップの終了状態を保持

outcomeプロパティはContinue on Error適用前の終了状態（つまり生情報）
conclusionプロパティはContinue on Error適用後の終了状態


needsコンテキスト：（依存している）ジョブの終了状態を保持

resultプロパティのみ




コンテキストとステータスチェック関数の併用

「前のステップが失敗したら」という条件式を書きたい場合

if: ${{ failure() &amp;&amp; steps.stepName.outcome == &#39;failure&#39; }}とする必要がある
このようにステータスチェック関数とコンテキスト参照を併用する必要がある理由として、failure()が記述されていない場合、暗黙的にsuccess()関数が存在すると解釈されるため





15章 GitHub Actionsのセキュリティ

この章では「ソフトウェアサプライチェーン」に着目する

ソフトウェアサプライチェーンとは、コード書いてから実行環境へリリースまでに含まれる一連のアクティビティを意味する


GHAはさまざまなシステムと連携するため、強力な権限が集中するため、悪意ある人にとってはとても魅力な攻撃対象になる

セキュリティのCIA

CIAとは、機密性・完全性・可用性のこと
CIAの観点から、守るべき資産はコード・クレデンシャル・アーティファクトとなる
闇雲に対策するのではなく、利便性とのトレードオフとなる

セキュリティの設計原則

脅威を完全に排除することは難しいので、脅威の軽減を目標とする
アタックサーフェス＝攻撃される恐れのある場所を小さくする

シンプルな設計を意識する（複雑な設計では意図しないこれ↑を生みやすいので）


複数のセキュリティレイヤを用意して、多層防御にする
最小権限

攻撃されても被害を小さくできる
一時クレデンシャルのような権限の行使に時間の制約があるようなものも有効だと思われる



Githubのサービス特性

上記の設計原則を踏まえて考えていく
GitHubはデフォルトの設定は利便性重視なので注意する
コードをプッシュできる人はワークフローの実行ができるという仕様を理解する
悪意ある人もコントリビューション可能であることを認識する

サードパーティアクション

サードパーティのアクションがリポジトリのコードを参照できるかはパーミションによるが、ほとんどのワークフローではコードにチェックアウトするので、大半のアクションはコードを参照できる
サードパーティアクション導入時は、そのサードパーティを信頼するかを意識的に決断するようにする

本当に信頼して良いかを考えるクセをつけるのが重要


リポジトリ設定で利用制限も可能
呼び出し時にコミットハッシュによる固定を行えば、アクションを不変リソースとして扱える

ハッシュ指定だけでは分かりづらいので、コメントでバージョン情報を併記しておくと分かりやすい


筆者の考えとしては「ある程度の車輪の再発明は仕方ない」それくらいサードパーティアクションの使用は慎重になるべき

スクリプトインジェクション

外からやってくるデータ（例：PRのタイトル）に悪意あるスクリプトが仕込まれていた場合、それがワークフローの中で読み込まれてスクリプトとして実行されてしまうリスクがある
対策として、

中間環境変数による無害化

env: PR_TITLE: ${{ github.event.pull_request.title }}というような形でスクリプトインジェクションを防げる
どのプロパティが危険かを正確に判断するのは困難なので、コンテキストは常に中間環境変数で参照するようにするのが確実で楽


ShellCheckによる静的解析

Github-Hosted Runnerには最初からインストールされている
actionlintは内部的にShellCheckを実行していて、yamlに直接書いたスクリプトもチェックしてくれる





最小権限のパーミッション

パーミッションはpermissionキーで設定可能
省略可能で、省略した場合はコード参照が許可される
明示的な記述を習慣化することで、自然とパーミッションを意識するようになる

具体的には、

ワークフローレベルでのパーミッション無効化(permissions: {})の設定を入れることで、コード参照すら明示的な許可が必要になる
各ジョブへ都度、必要なパーミッションを定義する


面倒に見えるが、やってみると慣れるのは早い



ジョブ分割によるパーミッションの分離

パーミッションのスコープはいくつかあるが、特に注意すべきなのが以下の4つ

contents: 改竄されたコードをプッシュされるリスク
packages: 悪意あるパッケージをパブリッシュされるリスク
actions: 別のワークフローを意図せず起動されるリスク
id-token: OIDCでクラウドプロバイダにアクセスされるリスク


これらのパーミッションを複数扱う場合はジョブの分割を検討すると良い

パーミッションをジョブ単位で記述すれば、ジョブがセキュリティ境界となる



シークレットマネジメント

まずはクレデンシャルの把握をすべき
最小権限・一時クレデンシャルを優先・定期的なローテーション

OpenID Connectハードニング

OpenID Connectを深掘りするパート
(再掲)一時クレデンシャルの取得フロー

ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する

GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider)
OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ)
一時クレデンシャルで操作


IDトークン

上記の1のOIDCトークンと呼んでいるものはOIDCの世界ではIDトークンと呼ぶ
これには主体に認証情報を含んでおり、リポジトリやワークフローの情報が含まれている
これらの属性情報を受け取ったクラウドプロバイダ側で検証し、アクセス可否を判断している
IDトークンの実体は、JWTである

ヘッダ・ペイロード・署名をピリオド区切りでBase64URLエンコードしたもの
ペイロードのデータ構造は決まっており、JSONの各フィールドはクレームと呼ぶ
IDトークンにはいくつかの必須クレームがあり、この必須クレームがセキュリティ上重要となる


IDトークンの検証フロー

ワークフローはGitHub OIDC Providerから取得したIDトークンをクラウドプロバイダに渡す
クラウドプロバイダはIDトークンの署名を検証し、JWTクレームを検証する
この検証に成功したら、一時クレデンシャルをワークフローに返送する


IDトークンの署名検証

本当にGitHub OIDC Providerが発行したIDトークンなのか確認する
署名の検証には、GitHub OIDC Providerの公開鍵を探し出す必要がある
どこを探すかというと、OIDC Trust(AWSの場合はOpenID Connect Provider)にGitHub OIDC ProviderのURLを設定していて、このURLが公開鍵の検索に使用される（https://token.actions.githubusercontent.com）
注意点として、上記のURLは全アカウントで共通のため、アカウントやリポジトリの識別ができない（GitHubが生成したという内容しか検証できない）

そこでJWTクレーム検証でその部分を補う形で検証する




IDトークンのJWTクレーム検証

IDトークンの署名だけではGitHub利用者が誰でもアクセスできてしまうため、JWTクレームでも検証を行う
JWTクレーム検証はクラウドプロバイダによって異なるが、AWSではAssumeRoleポリシーのCondition定義に基づいて検証を行う
subクレーム

もっとも重要な検証対象となる
認証された主体の識別子が格納される（一般的にはユーザーIDなど）
GitHub Actionsでは少し毛色が異なり、ワークフローの属性情報を連結した値が入る（アカウント名やリポジトリ名など）

ワークフローの実行方法によって値が異なるが、repo:/:のような文字列はどの方法でも含まれる
なのでアカウント名やリポジトリ名が正しいかの判断は可能




GitHubのカスタムクレーム

IDトークンは拡張が認めらていて、任意のカスタムクレームを追加可能
クラウドプロバイダによってサポート状況が異なっているので注意（AWSはサポートしていない）


クラウドプロバイダのJWTクレーム検証設定

AssumeRoleポリシーのConditionに以下のように記述する

&quot;token.actions.githubusercontent.com:sub&quot;: &quot;repo:&lt;OWNER&gt;/&lt;REPO&gt;:*&quot;


左辺のキーはsubクレームを指している
他の値もsubクレームで検証するとセキュリティがより強固になる


Environmentsの検証

subクレームに含まれるEnvironmentsの値を検証することで、商用環境にアクセスできるのはレビュー済みのワークフローのみとしたいといった制御が可能


JWTクレームの検証はOpenID Connectのキモであり、特にsubクレームは重要となる







16章 セキュリティのシフトレフト

セキュリティは後回しにしがちだが早めに取り組むのが良い戦略

これがシフトレフトという考え方（痛い目に遭うくらいなら早めに対処しよう）


依存関係の脆弱性スキャン

最新に保ち続けられるならそれで十分だけど現実はそうもいかない
そこで活用したいのが依存関係の脆弱性を検出するサービス

Dependabot Alerts

依存関係の脆弱性を発見するとアラートを送信する
「新たなコードのプッシュでDependency Graphが更新された時（例えばpackage.jsonなどのファイルが更新された時と同意かな？）」と「脆弱性データベースであるGitHub Advisory Databaseに脆弱性が登録された時」のタイミングでリポジトリをチェックしてくれる


Dependabot security updates

Alertsは情報提供で、これはプルリクエスト作成まで行ってくれるサービス
「security updates」は脆弱性のパッチを当てたバージョンへあげるもの（「version updates」の方は常に最新バージョンにあげるという違いがある）


設定ファイルについて

.github/dependabot.ymlは、security updatesとversion updatesで共有される

共有されるということは除外ルールを書いたらどちらでも検知されない


なので防御策として、Alertsを合わせて有効化しておくと良い（Alertsは設定ファイルに依存しない）そうすれば検出漏れを最小限にできる






シークレットスキャン

GitHubのシークレットスキャン機能は経済的理由で導入が困難な場合もある
SecretlintというDockerで動かせるAWSやGitHubなどの主要サービスのクレデンシャルを検出できる

これをGitHubActionsで動かすと尚良い
その際、検出された情報がログ出力されないように注意（--maskSecretsオプションで設定可能）


途中からシークレットスキャンを導入する場合は全ヒストリーをスキャンするGitleaksというツールがある

これもDockerで動かせる


git push前にスキャンするのがベター

.git/hooks/pre-commitファイルへシークレットスキャンコマンドを組み込むとコミット時にスキャンが実行あsれる
個々人で設定可能が必要であり、ストレスに感じる人もいるため、実際にやるかどうかは個人の判断に委ねると良い




アプリケーションスキャン

Static Application Security Testing(SAST)

コードスキャンしてセキュリティ問題を検出する（静的解析）
Goだとsecurego/gosec: Go security checkerがそれみたい


コンテナイメージの脆弱性スキャン

Trivyというツール
他にはコンテナレジストリでスキャン実施できる




Infrastructure as Codeセキュリティ

IaCで作業ミスは抑制できるが、セキュリティミスは防げない
そしてパッと見で正しく動作しているように見えるので意外と発見が難しい
セキュリティ設定ミスの防止

ここでもTrivyが活躍する
万事解決とまでいかないが、優れた出発点となる


Policy as Code

Conftestというツールが使える
ポリシールールを設定ファイルに記述し、それを検証してくれる
これもDockerで動かせるのでワークフローに簡単に実行できる
選択肢の1つとして持っておくと良い




継続的なセキュリティの改善

誤検出と検出漏れはどうしても発生する（バランス・トレードオフ）
誤検出は想像異常にストレスが大きい
またツールを導入しすぎるたりして検出される問題が多すぎるとアラート疲れも発生する
時々立ち返って運用を見返すのが良い



18章 継続的デリバリーの実践

組織パフォーマンスを研究しているGoogleのDORAというチーム曰く「ソフトウェアデリバリーパフォーマンスは組織パフォーマンスと高い相関がある」と学術的な方法で示したこと
DORAの研究では「スピードが速い組織ほど品質も高い」を提唱している
加えて、個人の幸福や組織文化にも寄与すると考えられている
この章では「継続的デリバリー」うまく実践するために、何ができるかを紹介していく

バージョン管理戦略

継続的デリバリーは適切なバージョン管理から始まる
大原則は「ソフトウェアの実行に必要なあらゆるものをバージョン管理する」

ソースコードだけではなく、テスト・ビルド・デプロイ・データベースマイグレーション・運用などのスクリプト・インフラ設定もバージョン管理の対象（つまりクレデンシャル以外）


1日に1回はデフォルトブランチにマージする短命なブランチ運用＝トランクベース開発をすることで、コード変更量が小さいのでレビューしやすかったりコンフリクトが発生しづらかったりする

実装途中の機能を一時的に無効化したい場合は「フィーチャートグル」を使えば良い
詳細: 機能トグル（別名機能フラグ）



テスト戦略

CDの品質改善では、4章で説明した自動テストが重要な役割を担う
それ以外の異なる観点を提供するものとして、以下の2つがある

探索的テスト

自動化できないテストのこと
テストの目的は「調査」と「検証」がある
自動テストは記事の問題を「検証「することで、探索的テストは人間が手動で未知の問題を「調査」すること（目的が異なる）

Testing in Production

リリース後も本番環境でテストする
A/Bテストやシンセティックテストなど

リリース戦略

恐怖の克服

いくら自動化しても経験しないと恐怖は薄れない
自分の手でリリースすることが大切


ロールバック

ロールバックも全員が慣れておく
頻度が少ないためにやり方を知らない人がいるので手順を周知し、平時にロールバックの練習をしておく


デプロイとリリースの分離

分離していない場合にデプロイに問題があった時は全ユーザーに影響がある
分離する方法として、デプロイ後にユーザートラフィックを少しずつ新しい環境に流す「カナリアリリース」がある



データベースの変更管理

手作業でデータベースコマンドを実行してはダメ
マイグレーションスクリプト経由で実行すると、ヒューマンエラーも発生しない

ロールバック用のスクリプトも用意するようにする



IaCの変更管理

IaCはソフトウェアとライフサイクルが異なるため、固有の考慮点が存在する
ツールにドライ欄があるならそれを使用する

毎回手動実行は大変なので、プルリクエスト作成時に自動で実行し、それをコメントに貼り付ける


「本番環境への適用はデフォルトブランチにマージした時のみ」という規律を設けるべき
IaCはローカルからの変更は事故が起きやすいので止める
実行環境は強力な権限が必要なので、絶対消されてはいけないDB等のリソース削除を禁止したり、権限昇格なIAM操作を禁止すべき
構成ドリフト（実態とコードの差分がある状態）は定期的にドライランを実行して通知させよう

疎結合なアーキテクチャ

疎結合はCDがとても実践しやすい
テストやデプロイの容易性
">
<meta name="author" content="nyuusen">
<link rel="canonical" href="http://localhost:1313/my-hugo-blog/posts/010_github_cicd%E5%AE%9F%E8%B7%B5%E3%82%AC%E3%82%A4%E3%83%89/">
<link crossorigin="anonymous" href="/my-hugo-blog/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:1313/my-hugo-blog/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/my-hugo-blog/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/my-hugo-blog/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/my-hugo-blog/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/my-hugo-blog/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:1313/my-hugo-blog/posts/010_github_cicd%E5%AE%9F%E8%B7%B5%E3%82%AC%E3%82%A4%E3%83%89/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="http://localhost:1313/my-hugo-blog/posts/010_github_cicd%E5%AE%9F%E8%B7%B5%E3%82%AC%E3%82%A4%E3%83%89/">
  <meta property="og:site_name" content="nyuusen blog">
  <meta property="og:title" content="GitHub CICD実践ガイド">
  <meta property="og:description" content="1章 ソフトウェア開発とGitHub 継続的インテグレーションとは？ コードの変更を頻繁にコードベースに統合し、正しく動作するかを繰り返し検証する 統合頻度が上がるとコンフリクトが減る 繰り返して検証を行うとバグを発見すれば素早く修正できる ソフトウェアが安定して動けば、ユーザーの満足度も向上する 継続的デリバリーとは？ リリースしないとユーザーには価値を提供できない いつでも安全にリリースできる状態を保ち、ソフトウェアを繰り返し改善する CIとCDは同列の概念に見えるが、CIはCDに包含される 2章 GitHubActionsの基礎概念 実行時エラー コマンドの終了ステータスが0ならば成功、0以外ならば失敗見なされる なので、ワークフローでは終了ステータスを適切に返すことが大事 手動実行 on: workflow_dispatchで手動実行できる inputとして、列挙型となるchoice型の指定が可能 定期実行 on: schedule: cron()で定期実行できる 時刻はUTCなので注意 実行環境 GitHub-Hosted Runners GitHubが提供するマネージドな実行環境 LargerRunnersというマシンスペック向上したものも利用可能（有料） サポートOSとしては、Linux(Ubuntu)/Windows/macOSがある よく使用するDocker,Node.js,npmなどは既にインストールされている ただし、バージョン固定はできないので、バージョン固定で使用したい場合は、ワークフローの中で自分でインストールする必要ある エフェメラルという特性 ジョブ終了時に破棄されるので、毎回クリーンな環境でジョブを実行できる この特性は一貫性向上に貢献している Self-Hosted Runners 利用者が実行環境を用意する MarketPlace 再利用できるワークフローが公開されている 著名な組織にはVerifiedCreatorsマークがついているので、そういうのを利用するとセキュリティ不安が低減する（100%安全とは言い切れないが） 料金 パブリックリポジトリなら無料 プライベートは使用時間とストレージ使用量で計算される 月毎に無料枠があり、それを超えると課金が発生するが、支払い設定をしていない場合は実行できなくなるだけ（なので安心できる） 使用時間は、実行時間×ランナーごとの料率で計算される 料率はubuntuが1,Windowsが2,macOSが10なので、なるべくUbuntuを利用するのがオススメ 3章 ワークフロー構文の基礎 環境変数 単一のワークフローで使用できる envで定義する ワークフロー・ジョブ・ステップで定義可能 定義した場所で、環境変数のスコープが異なる 中間環境変数 コンテキスト(github.base_refのように参照できるもの)は、各ジョブ(ステップ)の中で直接スクリプトに埋め込むのはNG 理由: スクリプトインジェクションにリスクがあるため envの中で一度変数展開し、スクリプト内ではダブルクオテーションで囲むことが推奨される 変数展開することでメモリ上で保存されるので、スクリプト生成プロセスには生成プロセスには相互作用しないため GHAに限らず、シェルスクリプト全体で言えること Variables 複数のワークフローで使用できる varsコンテキストでアクセスする こちらも参照時は中間環境変数経由(envの中で環境変数に展開してから)が推奨 Secrets 以下の特徴がある 登録した値は暗号化され、GitHub内で安全に管理される ログ出力時はマスクされる 登録後の値確認は不可となる ログマスクのアルゴリズムは完全一致のみ、1文字スペースを加えたりするだけで出力されてしまうので、ログマスクは当てにしないようにする そもそもsecretsの値はログ出力しないようにしましょう expressions(式) ${ example }のような形で定義 リテラルや演算子などが使用可能 比較演算の際、GHAでは異なる型の値を比較すると、勝手に値が変換されるので注意 オブジェクトフィルター 配列やオブジェクトから指定したプロパティを抜き出し、配列を生成する ${{ github.event.*.html_url }}のような形で*を使用する 条件分岐(if) ifの少し面白い使い方として、最初のジョブへ条件分岐を定義し、特定の条件でスキップするようにすると、ワークフロー自体の実行がスキップできる 使用時間もゼロになり、コスト削減につながる ネーミング 実行ログが見やすくなるのでジョブ名やステップ名はきちんと書く run-nameは、nameとは異なり、コンテキストが利用できる run-name: Run by ${{ github.actor }} ステップ間のデータ共有 2つのやり方がある GITHUB_OUTPUT環境変数 定義: echo “=” » “${GITHUB_OUTPUT}” 参照: ${{ steps..outputs. }} 参照方法を見ると分かる通り、ステップ間の依存関係が明白 GITHUB_ENV環境変数 定義: echo “=” » “${GITHUB_ENV}” 参照: ${GITHUB_ENV} ステップIDの指定が不要なので、どのステップで環境変数を設定したかを意識する必要ない 異なる複数のステップで、同じ値を参照する場合に使える（ただしステップ間の依存がわかりづらくなる） これで定義したものは、事実上グローバル変数なので、ワークフローが大きくなるとバグの原因になるので注意が必要 特にこだわりなければ、GITHUB_OUTPUTを使用する GitHub APIの実行 GitHubHostedRunnerの場合は、GitHub CLIがインストールされているのでそれを使うと良い API(CLI)の実行にはトークンが必要 GHAには簡単に使えるクレデンシャルが利用できる ワークフロー開始時に自動生成、終了すると自動的に破棄 有効期限は、ワークフロー実行中のみなので、万が一漏れても影響範囲は限定的 取得方法は、${{ secrets.GITHUB_TOKEN }} もしくは ${{ github.token }} どちらでも良いので、どちらかに統一するのが良い トークンの指定は、GITHUB_TOKENもしくはGH_TOKENという名前の環境変数をセットするだけで、自動で読み込んでくれる パーミッション ジョブレベルとワークフローレベルで指定可能 スコープ(contents, pull-requests等)とそれに対するアクション(read, write, none)を設定する ただしワークフローを実行しているリポジトリ以外のアクセスは許可されない パーミッションを明示的に定義していない場合、自動でソースコードの読み込み許可はされる 一方、明示的な定義をする場合は、この暗黙的な挙動は無視されるので注意 パーミッション周りのトラブルシューティング ワークフロー実行ログのSet up jobの中に、GITHUB_TOKEN Permissionsがあるので、そこで実行時のパーミッションを確認できる スターターワークフロー GitHubリポジトリのActionsからNew Workflowを選択すると、ワークフローのコレクションが並んでいるので、参考にできそう https://github.com/actions/starter-workflows?tab=readme-ov-file 4章 継続的インテグレーションの実践 大体以下の流れでワークフローを構成する checkout setup(ex: actions/setup-go) リントやテストの実行 フィルター pathsと他の条件を指定するとAND条件になる 静的解析 actionlintは、GHAワークフローの静的解析を行ってくれるので便利 使用時間の削減（どのワークフローでも有用な設定） ジョブ・ステップレベルのタイムアウト設定 どのワークフローにも設定するようにする（GHAのデフォルト値は360分と大変長いため） 自動キャンセル（新しいコミットが追加されたら、古いコミットで動作しているワークフローを自動でキャンセルする） シェル ステップごとに起動シェルをshellキーで設定可能 Ubuntuの場合、省略時はbashだが、shellキーの指定有無で起動オプションが変更される 全ステップに書くのは面倒なので、ワークフローのトップレベルにデフォルト設定(defaults句)するのが良い デフォルトシェルにはデメリットは存在しないので、全てのワークフローに機械的に入れるのがオススメ Concurrency ワークフローはイベント駆動なので、イベントが発生すると起動、さらにまたイベントが発生すると起動することになる 起動制御できる仕組みとして、Concurrencyがある concurrency: &lt;group-name&gt;とすることで、同一グループの多重制御が設定できる さらにcancel-in-progress: trueで自動キャンセルの設定も可能（プルリクエストで最新ではないコミットのCIとかに有効） CIの黄金律 「クリーンに保つ」 全てのステータスチェックが成功した時だけマージできるようにする 「高速に実行する」 CIの実行が遅いと、待ち時間に他の作業→CIで失敗したらその対応する時にコンテキストスイッチが必要になる 時間の無駄だし、開発効率の低下につながる CIのスピードは大切で、理想は5分以内、遅くとも10分以内に終わらせるように 「ノイズを減らす」 CIからのフィードバックで価値ある情報の「シグナル」とそうではない「ノイズ」 判断基準としては、その情報を受け取り、これは気にしなくて良いやと流したならそれがノイズ ノイズがあると、シグナルもスルーされてしまうので、ノイズは意識的に減らす テスト 単体テストの割合を増やす フレーキーテストを放置しない（閾値を超えるとテスト全体が信頼されなくなる） Googleソフトウェアエンジニアリングでは閾値は1％とされている 遅いテストは実行タイミングをPRマージの時に限定するなど工夫する 使用しているテストツールで以下のような機能を利用する 部分実行 並列実行 シャッフル実行（テスト間の隠れた依存関係も洗い出せる） カテゴリ実行（スローテスト用のカテゴリを作ってそれだけ実行しないみたいな） 静的解析 不要な警告は無視するのではなく抑止する ignoreやsuppressのキーワードで検索する 抑止理由はコメントやコミットメッセージに残しておく 第5章 運用しやすいワークフロー設計 長期運用で役立つプラクティスの紹介 ロギング ワークフローの再実行時の「Enable debug logging」を有効にすると、デバッグログが確認できる デバッグログには以下がある ステップデバッグログ ステップのログの詳細（ステップステータスや各種コンテキスト）をトレースできる SecretsまたはVariablesに「ACTIONS_STEP_DEBUG」をtrueで登録しておくことで、これらの値も確認できる 他は内部実装者向けだったりするので、割愛 Bashのトレーシングオプション デバッグログよりシンプルで、どんなコマンドが実行され、結果はなんだったのかを知りたいケースで使用する Bashのトレーシングオプションは、set -xを実行するだけなので、手軽だが強力 全てのコマンドが実行前に表示されるようになり、どのコマンドがどのような引数で実行されているかを確認できる ログのグルーピング、手動マスク等もある レポーティング アノテーション echo &#34;::error::This is error&#34;みたいな形で書くとジョブページにみやすい形で表示 ジョブサマリー シンプルなテキストならアノテーションで十分だが、複数行表示したい場合等はマークダウン形式で出力される${GITHUB_STEP_SUMMARY}が便利 複数ジョブの実行制御 デフォルトでは複数のジョブを実行すると並列実行される 並列実行は、全体の実行時間を短縮できる もしジョブの実行時間の長さに問題がある場合は、ジョブを細かく分割し、並列実行させるというアプローチもある 逐次実行させたい場合は、needsを使用する ジョブ間のデータ共有 $GITHUB_OUTPUT環境変数に出力し、stepsコンテキスト経由で受け渡す 受け取る側は、needsコンテキストを経由で受け取る Environments 環境差分をパラメータ化でき、VariablesとSecretsがある 参照方法は、通常のVariablesとSecretsと同一(vars.xxx, secrets.xxx) よくあるのはワークフローの入力値で環境名をもらい、それをenvironmentsにセットし、同じ変数名(環境ごとに値が異なる)を参照 キャッシュ actions/cachedでGHA上にキャッシュとその利用が可能 実行時のパラメータとして key: キャッシュキー。生成と保存に利用する。 path: キャッシュ対象となるディレクトリ/ファイルパス。 restore-keys: キャッシュミス時のリストアキーを複数指定する。 キャッシュ復元時に挙動 ①keyキーに定義したキャッシュキーと厳密に一致するキャッシュを探す ②リストアキーの定義順に、プレフィックスが一致するキャッシュを探す リストアキーは省力可能であり、これはパッケージマネージャーと併用するときに威力を発揮する 大半のパッケージマネージャーはキャッシュにないファイルだけダウンロードするように振る舞う キャッシュは、7日以上アクセスされないと自動削除される ブラウザからリポジトリ画面で手動削除も可能 合計サイズは、リポジトリで10GBまで キャッシュキーの設計 プラットフォームごとに異なるキャッシュを利用するようにする キャッシュは最低でもOSごとに分離する 他にもCPUアーキテクチャや言語バージョン、パッケージマネージャーもキャッシュキーの候補 例えば、OSとCPUアーキテクチャでキャッシュを分離するなら: key: example-${{ runner.os }}-${{ runner.arch }} 依存関係を更新した時だけキャッシュを変更するようにする package-lock.jsonのようなロックファイルがある場合、そのファイルハッシュをハッシュキーに指定する hashfiles(&#39;**/package-lock.json) ロックファイルが更新されない限り、キャッシュが利用されるようになる アーティファクト ワークフロー内で生成したファイルをアーティファクトと呼ぶ アーティファクトはGitHubストレージへ一時的に保存ができる ビルドしたバイナリやメトリクスデータの保存に利用できる アーティファクトの保存はデフォルト90日で、保存時にパラメータ(retention-days)で指定可能 プライベートリポジトリだとストレージ容量は課金対象のため、保存期間を短くすると節約できる 6章 アクションによるモジュール化 ここでいう「アクションによるモジュール化」とは、ワークフローにおける小さな部品（ステップやコマンドの小さな単位）をモジュール化すること ランナーは、呼び出し元ワークフローに依存する アクションの実装方式は以下の3つがある Composite: YAMLで定義 JavaScript: JSで定義 Docker Container: Dockerで動かす(ビルド・起動するDockerfileを指定) これらはrunsのusingキーで指定する(ex: using: composite) アクションのロケーションは「ローカル」と「リモート」がある リモート: uses: actions/checkout@v4 URLと連動する @v4の部分はGitのタグ（ブランチやコミットハッシュも指定可能） ローカル: uses: ./.github/actions/hello/ 先頭部分が.であることが目印 ルートディレクトリを起点にパスを記述する CompositeAction メタデータファイル(action.yml)が必要 メタデータ構文のワークフロー構文との違いや注意点 シェル指定が必須 githubコンテキストのeventプロパティの使用は避ける アクションはトリガー指定ができないので、呼び出し元のワークフローによりeventの中身がガラリと変わるため variablesとsecretsは直接参照できない inputとして渡す必要あり secretsを渡したらログ出力時のマスクはしてくれる 環境変数のスコープはワークフローに準拠する ワークフロー側で定義した環境変数は参照できるし、アクション側で書き出した環境変数はワークフロー側からも参照可能 パーミッション定義できない ワークフロー側で制御するようにする つまり呼び出し側ワークフローでパーミッション定義を忘れると実行エラーが発生するので、どのようなパーミッションが必要かはREADMEなどに残しておくのがオススメ アクション設計プラクティス 認知負荷の低減 利用者はコードが読みたいのではなく、アクションを使いたいだけ なのでアクションの名前と概要はきちんとわかりやすいように書く（input/outputも） secrets.GITHUB_TOKENの取り方 アクションからsecretsは参照できないのでsecrets.GITHUB_TOKENは参照できないが、github.tokenで同じ値を参照できる スクリプトの切り出し 内部ロジックが大きくなってきたらshファイルとして別で切り出すと良い 切り出したshファイルは、GITHUB_ACTION_PATH環境変数で実行する必要がある run句に単純なshファイルへの相対パスを指定するだけでは実行できない 環境変数による暗黙的な依存の回避 ワークフローとアクションで相互に環境変数は参照できるが、必要な値はinputs/outputsで明示的に受け渡すようにするのが良い コードが追いづらくなるのと、意図せず壊れてしまうリスクがある ロググループ化の活用 まず大前提としてきちんとログを出力する（デバッグ効率が圧倒的に良くなるため） CompositeActionのログはステップごとに分割されないのでログを追うのが難しくなる なのでロググループ化を活用する アクションとNodeバージョン GitHubが提供する多くのアクションはJSで実装されている Nodeバージョンが上がるとアクションのメジャーバージョンが上がることが多い このバージョンアップ作業が地味に大変な作業… 7章 クリーンなリポジトリの維持 リポジトリルール ブランチプロテクションルールを設定しよう コードオーナーを設定して全てのコードにオーナーシップを維持しよう 自動でコードオーナーにレビュー依頼が飛ぶ シークレットスキャンを導入して、秘匿情報混入を検出しよう コードやIssueの本文やコメントなどもチェックしてくれる GitHubが定期的にチェックする（つまり事後） プッシュプロテクションをEnableにすると、プッシュするタイミングでチェックが走る ドキュメント READMEは読み手のことを考える LICENSEは確認するようにする MITは、責任とらないけど自由に使ってねくらいのニュアンス コミュニティヘルスファイル CONTRIBUTING.md: コントリビューション方法のガイド（PRやIssueの出し方、コーディング規約） CODE_OF_CONDUCT.md: 行動規範 SECURITY.md: 脆弱性報告方法など 8章 Dependabotによる依存関係バージョンアップ ソフトウェアは何もしないと壊れるので、変更し続ける必要がある 依存関係の管理には、検知・把握・実装・テストという活動が必要 Dependabotには以下3つの依存関係の管理をサポートする機能がある Dependabot version updates: 最新バージョンへの自動アップデート Dependabot security updates: 脆弱性を含むバージョンの自動アップデート Dependabot alerts: 脆弱性が含まれるバージョンのアラート通知 ワークフローで実践 ブランチプロテクションルールを設定し、全てのステータスチェックを行ってからマージしたい場合 GitHub CLIのmergeコマンドに--autoをつけることで、全ワークフローの成功状態になった後に、自動でマージしてくれる Dependabotが起動したワークフローは通常のsecretsへのアクセスができないので、Dependabot用のsecretsを登録する必要があるので注意 厄介なのが何もエラーが出ず、空文字で処理が進むので、頭の片隅に入れておくと良い dependabot/fetch-metadataアクションを活用する Dependabotが起動するワークフローで使用可能で、バージョンアップ・依存関係の種類、パッケージエコシステムを取得できる 有効活用の例 パッチバージョンの場合は自動マージ 開発環境向けの変更は自動マージ GHA向けの変更は自動マージ このように少しでも手動対応量を減らすことで、少しでも楽をする 9章 GitHub Releasesによるリリース自動化 バージョニング いつどんな変更が行われたのかをバージョンを併記してユーザーに知らせることができる トラブル時はバージョン情報をやり取りすることで関係者間の意思疎通が楽になる 開発者としてもどのバージョンで不具合が発生したかがわかれば、修正が楽になる セマンティックバージョニング メジャー.マイナー.パッチという構成のバージョニング方式 順序性だけでなく、後方互換性に関心を寄せているのが特徴 完璧ではない（後方互換性が個人の考え方やスキルに依存する点）が、有名であること視認性が高いことで、選択としては無難である Gitタグの保護はやっておこう（ブランチ保護と同じような感じ） ReleasesがGitタグに依存しており、そのGitタグが削除された場合、リリースノートは下書き状態となってしまうため 10章 GitHub Packagesによるパッケージ管理 パッケージエコシステム npmやMavenなどの言語パッケージ、HomebrewなどのOSパッケージ、Dockerなどのコンテナイメージもパッケージの一種 ソフトウェアのインストール・管理（依存関係の把握、ライブラリが足りなければ自動でダウンロード、新しいバージョンの検知、最新版へのアップデート等）を容易にする 提供者はパッケージマネージャークライアントを通じてパッケージを作成・登録＆メタデータを提供し、利用者はパッケージマネージャークライアントを通じてパッケージを検索・取得・更新＆依存関係を解決する（そしてこの両者をつなぐのがパッケージレジストリ） ContainerRegistryの話がメインで、使いそうもないのでスキップ 11章 OpenID Connectによるセキュアなクラウド連携 クラウドプロバイダのクレデンシャル クラウドプロバイダは誰がアクセスしようとしているかを「認証」によって判断する クレデンシャルは、その認証に利用するもので、ユーザーIDとパスワードもその一種 認証する側が、アクセスキーやAPIキーといった呼び名のランダム文字列を発行し、それをクレデンシャルとして利用する プログラムがリクエスト時にそのクレデンシャルを一緒に送信することで、認証と認証情報が正しければ正常レスポンスを受け取れるという仕組み 静的クレデンシャル 長期にわたって変更しないパスワードのようなクレデンシャルを静的クレデンシャルという 静的クレデンシャルは長命という欠点があり、漏洩した場合の被害が拡大しやすい 一時クレデンシャル こちらは必要なタイミングで都度払い出すので短命 ローテーション作業もないので運用も楽 OpenID Connectというプロトコルによって実現する クラウド連携のアンチパターン 静的クレデンシャルは使用してはいけない かつてはそれしか選択肢がなかったので、記事を探すときは要注意 OpenID Connect(OIDC) これは複数の異なるドメインで認証結果を共有し、協調してサービスを提供するオープンなプロトコル（アイデンティ連携を実現する） OAuth2.0を拡張する形で設計されている 利点として、GitHub上で静的クレデンシャルの管理が不要になる(一時クレデンシャルを取得するため)＋認証時にアクセス元を細かく制限できる（GHAの場合特定リポジトリのみに許可できる） 一時クレデンシャルの取得フロー ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider) OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ) 一時クレデンシャルで操作 大抵の処理は隠蔽されており、私たちは行う作業は以下の2つのみ（準備に若干手間はかかるがメリットが大きい） クラウドプロバイダ側でOIDCに必要なコンポーネントを作成する ワークフローへクラウドプロバイダの認証アクションを組み込む OIDC TrustとCloud Roles クラウドプロバイダで準備するコンポーネントは以下の2つ OIDC Trust: クラウドプロバイダが信頼するOIDC Providerを設定(GitHub OIDC Provider) OIDCトークンで一時クレデンシャルを取得できる理由は、クラウドプロバイダがOIDC Providerを信頼しているため（OIDC Trust） OIDCトークンはJWT形式で、GitHub OIDC Providerの公開鍵を使って署名等の検証が行われる Cloud Roles: 一時クレデンシャルのアクセス先とアクセス元を制御 一時クレデンシャルの「アクセス先」を管理する AWSでいうIAMロールのこと 認証アクション 各クラウドプロバイダは公式で認証アクションを提供しているので、ワークフローからはそのアクションを呼び出すだけで、OIDCが扱える 検証作業のリスクヘッジ プライベートリポジトリで試す 認証パラメータ(AWSアカウントIDやIAMロール名)はSecretsで管理する これらクレデンシャルではないものの、ログ出力時にマスクされるので、謝ってパブリックリポジトリでワークフローを実行しても、第三者へ余計な情報が漏れない AWSにおけるOIDC利用準備と連携 以下の2つを作成する OIDC Provider AWSがGitHub OIDC Providerを信頼するように設定 IAMロール 一時クレデンシャルのアクセス先とアクセス元を制御する GHAワークフロー側での設定作業 Secrets登録 AWSアカウントID IAMロール名 ワークフロー実装 permissions id-token: writeの設定が必要 GitHub OIDC ProviderからOIDCトークン取得に必要 aws-actions/configure-aws-credentialsを利用 ロールARNとセッション名、デフォルトリージョンをパラメータとして指定する セッション名は、トレーザビリティを目的に、AssumeRole APIに渡すパラメータ名であり、CloudTrailのセッション名として記録される 「誰が・いつ・どのジョブでこのセッションを作ったか分かる」ような情報を含めると便利 例：&#34;${{ github.workflow }}-${{ github.run_id }}-${{ github.actor }}&#34; CloudRolesのセキュアな運用 他のリポジトリからアクセスできないことを確認しておく CloudRolesは目的ごとに分離する（必要最小限の権限だけ） クラウドプロバイダの設定作業にIaCを導入する 12章 コンテナオーケストレーションのデプロイメント デプロイ自動化の流れ コンテナビルドアクション：コンテナイメージのビルド＆プッシュ コンテナデプロイアクション：タスク定義の書き換えとサービスの更新 本番環境へのデプロイはルールを制限したい Deployment branches and tagsを設定する Environmentsからブランチ名パターンを登録することでパターン外のブランチでワークフローを起動できなくなる Required Reviewers ワークフローの起動に承認を必須とする デプロイメント設計 デプロイの設計では「ユーザー影響」と「ロールバック」の観点に着目する ローリングアップデート ECSのデプロイ方式 新しいバージョンへ少しずつ置き換える 無停止 ロールバック ローリングアップデートの場合は特別な仕組みはないので、リバートコミットを追加し、再デプロイする（あまり速くない） 人間が切り戻しを検知・判断するので、別途監視の仕組みが必要となる 第14章 GitHub Actionsの高度な使い方 Reusable Workflows アクションは比較的小さな処理をカプセル化するのに対し、Reusable Workflowsはワークフロー全体を丸ごとカプセル化する パーミッション パーミッション定義を省略した場合は呼び出し側ワークフローのパーミッションを暗黙的に継承する 呼び出し側より厳しくできるが、緩めることはできない なので、呼び出し側ではジョブレベルでパーミッションを定義すると良い（Reusable Workflowsの権限が最小限になるため＋ドキュメンテーションとなり可読性が向上する） コンテキスト 呼び出し側ワークフローのコンテキストを直接参照できる ただしReusable Workflowsが制御できないgithub.eventプロパティを参照すると再利用性は低下するので注意が必要 Secrets 呼び出し側ワークフローのコンテキストを直接参照できない 入力パラメータ経由で渡す or 呼び出し側でsecrets: inheritを指定するとまとめて継承可能 暗黙的な継承となりコードが追いづらくなるので個別で入力パラメータとして渡すのが良い 環境変数 こちらも参照できないので入力パラメータ経由で渡す fromJSON関数 動的なワークフロー定義 事前にマトリクスを生成できない場合、fromJSON()をmatrixに指定することで動的にマトリクスを生成できる 文字列の型変換 ワークフロー構文の環境変数はstring型として扱われてしまう その際string型の文字列をnumber型やboolean型に変換できる エラーハンドリング Continue on Error デフォルトではエラーが発生するとその時点でワークフローが停止する continue-on-error: trueを指定すると、エラーを握りつぶし、次の処理に進む これを指定すると、途中でエラーが発生しても、ワークフロー自体は正常終了扱いされる ログを見ない限りエラーには気づけないので、リカバリー不要な場合のみ使用する マトリックスのフェイルファスト マトリックスを使うと複数のジョブが並列に起動する 途中でエラーが発生した場合、他のジョブが止まる fail-fast: falseを指定することで他のジョブを継続可能とできる コンテキストによるフロー制御 終了状態を取得できるコンテキスト stepsコンテキスト：ステップの終了状態を保持 outcomeプロパティはContinue on Error適用前の終了状態（つまり生情報） conclusionプロパティはContinue on Error適用後の終了状態 needsコンテキスト：（依存している）ジョブの終了状態を保持 resultプロパティのみ コンテキストとステータスチェック関数の併用 「前のステップが失敗したら」という条件式を書きたい場合 if: ${{ failure() &amp;&amp; steps.stepName.outcome == &#39;failure&#39; }}とする必要がある このようにステータスチェック関数とコンテキスト参照を併用する必要がある理由として、failure()が記述されていない場合、暗黙的にsuccess()関数が存在すると解釈されるため 15章 GitHub Actionsのセキュリティ この章では「ソフトウェアサプライチェーン」に着目する ソフトウェアサプライチェーンとは、コード書いてから実行環境へリリースまでに含まれる一連のアクティビティを意味する GHAはさまざまなシステムと連携するため、強力な権限が集中するため、悪意ある人にとってはとても魅力な攻撃対象になる セキュリティのCIA CIAとは、機密性・完全性・可用性のこと CIAの観点から、守るべき資産はコード・クレデンシャル・アーティファクトとなる 闇雲に対策するのではなく、利便性とのトレードオフとなる セキュリティの設計原則 脅威を完全に排除することは難しいので、脅威の軽減を目標とする アタックサーフェス＝攻撃される恐れのある場所を小さくする シンプルな設計を意識する（複雑な設計では意図しないこれ↑を生みやすいので） 複数のセキュリティレイヤを用意して、多層防御にする 最小権限 攻撃されても被害を小さくできる 一時クレデンシャルのような権限の行使に時間の制約があるようなものも有効だと思われる Githubのサービス特性 上記の設計原則を踏まえて考えていく GitHubはデフォルトの設定は利便性重視なので注意する コードをプッシュできる人はワークフローの実行ができるという仕様を理解する 悪意ある人もコントリビューション可能であることを認識する サードパーティアクション サードパーティのアクションがリポジトリのコードを参照できるかはパーミションによるが、ほとんどのワークフローではコードにチェックアウトするので、大半のアクションはコードを参照できる サードパーティアクション導入時は、そのサードパーティを信頼するかを意識的に決断するようにする 本当に信頼して良いかを考えるクセをつけるのが重要 リポジトリ設定で利用制限も可能 呼び出し時にコミットハッシュによる固定を行えば、アクションを不変リソースとして扱える ハッシュ指定だけでは分かりづらいので、コメントでバージョン情報を併記しておくと分かりやすい 筆者の考えとしては「ある程度の車輪の再発明は仕方ない」それくらいサードパーティアクションの使用は慎重になるべき スクリプトインジェクション 外からやってくるデータ（例：PRのタイトル）に悪意あるスクリプトが仕込まれていた場合、それがワークフローの中で読み込まれてスクリプトとして実行されてしまうリスクがある 対策として、 中間環境変数による無害化 env: PR_TITLE: ${{ github.event.pull_request.title }}というような形でスクリプトインジェクションを防げる どのプロパティが危険かを正確に判断するのは困難なので、コンテキストは常に中間環境変数で参照するようにするのが確実で楽 ShellCheckによる静的解析 Github-Hosted Runnerには最初からインストールされている actionlintは内部的にShellCheckを実行していて、yamlに直接書いたスクリプトもチェックしてくれる 最小権限のパーミッション パーミッションはpermissionキーで設定可能 省略可能で、省略した場合はコード参照が許可される 明示的な記述を習慣化することで、自然とパーミッションを意識するようになる 具体的には、 ワークフローレベルでのパーミッション無効化(permissions: {})の設定を入れることで、コード参照すら明示的な許可が必要になる 各ジョブへ都度、必要なパーミッションを定義する 面倒に見えるが、やってみると慣れるのは早い ジョブ分割によるパーミッションの分離 パーミッションのスコープはいくつかあるが、特に注意すべきなのが以下の4つ contents: 改竄されたコードをプッシュされるリスク packages: 悪意あるパッケージをパブリッシュされるリスク actions: 別のワークフローを意図せず起動されるリスク id-token: OIDCでクラウドプロバイダにアクセスされるリスク これらのパーミッションを複数扱う場合はジョブの分割を検討すると良い パーミッションをジョブ単位で記述すれば、ジョブがセキュリティ境界となる シークレットマネジメント まずはクレデンシャルの把握をすべき 最小権限・一時クレデンシャルを優先・定期的なローテーション OpenID Connectハードニング OpenID Connectを深掘りするパート (再掲)一時クレデンシャルの取得フロー ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider) OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ) 一時クレデンシャルで操作 IDトークン 上記の1のOIDCトークンと呼んでいるものはOIDCの世界ではIDトークンと呼ぶ これには主体に認証情報を含んでおり、リポジトリやワークフローの情報が含まれている これらの属性情報を受け取ったクラウドプロバイダ側で検証し、アクセス可否を判断している IDトークンの実体は、JWTである ヘッダ・ペイロード・署名をピリオド区切りでBase64URLエンコードしたもの ペイロードのデータ構造は決まっており、JSONの各フィールドはクレームと呼ぶ IDトークンにはいくつかの必須クレームがあり、この必須クレームがセキュリティ上重要となる IDトークンの検証フロー ワークフローはGitHub OIDC Providerから取得したIDトークンをクラウドプロバイダに渡す クラウドプロバイダはIDトークンの署名を検証し、JWTクレームを検証する この検証に成功したら、一時クレデンシャルをワークフローに返送する IDトークンの署名検証 本当にGitHub OIDC Providerが発行したIDトークンなのか確認する 署名の検証には、GitHub OIDC Providerの公開鍵を探し出す必要がある どこを探すかというと、OIDC Trust(AWSの場合はOpenID Connect Provider)にGitHub OIDC ProviderのURLを設定していて、このURLが公開鍵の検索に使用される（https://token.actions.githubusercontent.com） 注意点として、上記のURLは全アカウントで共通のため、アカウントやリポジトリの識別ができない（GitHubが生成したという内容しか検証できない） そこでJWTクレーム検証でその部分を補う形で検証する IDトークンのJWTクレーム検証 IDトークンの署名だけではGitHub利用者が誰でもアクセスできてしまうため、JWTクレームでも検証を行う JWTクレーム検証はクラウドプロバイダによって異なるが、AWSではAssumeRoleポリシーのCondition定義に基づいて検証を行う subクレーム もっとも重要な検証対象となる 認証された主体の識別子が格納される（一般的にはユーザーIDなど） GitHub Actionsでは少し毛色が異なり、ワークフローの属性情報を連結した値が入る（アカウント名やリポジトリ名など） ワークフローの実行方法によって値が異なるが、repo:/:のような文字列はどの方法でも含まれる なのでアカウント名やリポジトリ名が正しいかの判断は可能 GitHubのカスタムクレーム IDトークンは拡張が認めらていて、任意のカスタムクレームを追加可能 クラウドプロバイダによってサポート状況が異なっているので注意（AWSはサポートしていない） クラウドプロバイダのJWTクレーム検証設定 AssumeRoleポリシーのConditionに以下のように記述する &#34;token.actions.githubusercontent.com:sub&#34;: &#34;repo:&lt;OWNER&gt;/&lt;REPO&gt;:*&#34; 左辺のキーはsubクレームを指している 他の値もsubクレームで検証するとセキュリティがより強固になる Environmentsの検証 subクレームに含まれるEnvironmentsの値を検証することで、商用環境にアクセスできるのはレビュー済みのワークフローのみとしたいといった制御が可能 JWTクレームの検証はOpenID Connectのキモであり、特にsubクレームは重要となる 16章 セキュリティのシフトレフト セキュリティは後回しにしがちだが早めに取り組むのが良い戦略 これがシフトレフトという考え方（痛い目に遭うくらいなら早めに対処しよう） 依存関係の脆弱性スキャン 最新に保ち続けられるならそれで十分だけど現実はそうもいかない そこで活用したいのが依存関係の脆弱性を検出するサービス Dependabot Alerts 依存関係の脆弱性を発見するとアラートを送信する 「新たなコードのプッシュでDependency Graphが更新された時（例えばpackage.jsonなどのファイルが更新された時と同意かな？）」と「脆弱性データベースであるGitHub Advisory Databaseに脆弱性が登録された時」のタイミングでリポジトリをチェックしてくれる Dependabot security updates Alertsは情報提供で、これはプルリクエスト作成まで行ってくれるサービス 「security updates」は脆弱性のパッチを当てたバージョンへあげるもの（「version updates」の方は常に最新バージョンにあげるという違いがある） 設定ファイルについて .github/dependabot.ymlは、security updatesとversion updatesで共有される 共有されるということは除外ルールを書いたらどちらでも検知されない なので防御策として、Alertsを合わせて有効化しておくと良い（Alertsは設定ファイルに依存しない）そうすれば検出漏れを最小限にできる シークレットスキャン GitHubのシークレットスキャン機能は経済的理由で導入が困難な場合もある SecretlintというDockerで動かせるAWSやGitHubなどの主要サービスのクレデンシャルを検出できる これをGitHubActionsで動かすと尚良い その際、検出された情報がログ出力されないように注意（--maskSecretsオプションで設定可能） 途中からシークレットスキャンを導入する場合は全ヒストリーをスキャンするGitleaksというツールがある これもDockerで動かせる git push前にスキャンするのがベター .git/hooks/pre-commitファイルへシークレットスキャンコマンドを組み込むとコミット時にスキャンが実行あsれる 個々人で設定可能が必要であり、ストレスに感じる人もいるため、実際にやるかどうかは個人の判断に委ねると良い アプリケーションスキャン Static Application Security Testing(SAST) コードスキャンしてセキュリティ問題を検出する（静的解析） Goだとsecurego/gosec: Go security checkerがそれみたい コンテナイメージの脆弱性スキャン Trivyというツール 他にはコンテナレジストリでスキャン実施できる Infrastructure as Codeセキュリティ IaCで作業ミスは抑制できるが、セキュリティミスは防げない そしてパッと見で正しく動作しているように見えるので意外と発見が難しい セキュリティ設定ミスの防止 ここでもTrivyが活躍する 万事解決とまでいかないが、優れた出発点となる Policy as Code Conftestというツールが使える ポリシールールを設定ファイルに記述し、それを検証してくれる これもDockerで動かせるのでワークフローに簡単に実行できる 選択肢の1つとして持っておくと良い 継続的なセキュリティの改善 誤検出と検出漏れはどうしても発生する（バランス・トレードオフ） 誤検出は想像異常にストレスが大きい またツールを導入しすぎるたりして検出される問題が多すぎるとアラート疲れも発生する 時々立ち返って運用を見返すのが良い 18章 継続的デリバリーの実践 組織パフォーマンスを研究しているGoogleのDORAというチーム曰く「ソフトウェアデリバリーパフォーマンスは組織パフォーマンスと高い相関がある」と学術的な方法で示したこと DORAの研究では「スピードが速い組織ほど品質も高い」を提唱している 加えて、個人の幸福や組織文化にも寄与すると考えられている この章では「継続的デリバリー」うまく実践するために、何ができるかを紹介していく バージョン管理戦略 継続的デリバリーは適切なバージョン管理から始まる 大原則は「ソフトウェアの実行に必要なあらゆるものをバージョン管理する」 ソースコードだけではなく、テスト・ビルド・デプロイ・データベースマイグレーション・運用などのスクリプト・インフラ設定もバージョン管理の対象（つまりクレデンシャル以外） 1日に1回はデフォルトブランチにマージする短命なブランチ運用＝トランクベース開発をすることで、コード変更量が小さいのでレビューしやすかったりコンフリクトが発生しづらかったりする 実装途中の機能を一時的に無効化したい場合は「フィーチャートグル」を使えば良い 詳細: 機能トグル（別名機能フラグ） テスト戦略 CDの品質改善では、4章で説明した自動テストが重要な役割を担う それ以外の異なる観点を提供するものとして、以下の2つがある 探索的テスト 自動化できないテストのこと テストの目的は「調査」と「検証」がある 自動テストは記事の問題を「検証「することで、探索的テストは人間が手動で未知の問題を「調査」すること（目的が異なる） Testing in Production リリース後も本番環境でテストする A/Bテストやシンセティックテストなど リリース戦略 恐怖の克服 いくら自動化しても経験しないと恐怖は薄れない 自分の手でリリースすることが大切 ロールバック ロールバックも全員が慣れておく 頻度が少ないためにやり方を知らない人がいるので手順を周知し、平時にロールバックの練習をしておく デプロイとリリースの分離 分離していない場合にデプロイに問題があった時は全ユーザーに影響がある 分離する方法として、デプロイ後にユーザートラフィックを少しずつ新しい環境に流す「カナリアリリース」がある データベースの変更管理 手作業でデータベースコマンドを実行してはダメ マイグレーションスクリプト経由で実行すると、ヒューマンエラーも発生しない ロールバック用のスクリプトも用意するようにする IaCの変更管理 IaCはソフトウェアとライフサイクルが異なるため、固有の考慮点が存在する ツールにドライ欄があるならそれを使用する 毎回手動実行は大変なので、プルリクエスト作成時に自動で実行し、それをコメントに貼り付ける 「本番環境への適用はデフォルトブランチにマージした時のみ」という規律を設けるべき IaCはローカルからの変更は事故が起きやすいので止める 実行環境は強力な権限が必要なので、絶対消されてはいけないDB等のリソース削除を禁止したり、権限昇格なIAM操作を禁止すべき 構成ドリフト（実態とコードの差分がある状態）は定期的にドライランを実行して通知させよう 疎結合なアーキテクチャ 疎結合はCDがとても実践しやすい テストやデプロイの容易性 ">
  <meta property="og:locale" content="ja">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-05-27T21:25:40+09:00">
    <meta property="article:modified_time" content="2025-05-27T21:25:40+09:00">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="GitHub CICD実践ガイド">
<meta name="twitter:description" content="1章 ソフトウェア開発とGitHub

継続的インテグレーションとは？

コードの変更を頻繁にコードベースに統合し、正しく動作するかを繰り返し検証する
統合頻度が上がるとコンフリクトが減る
繰り返して検証を行うとバグを発見すれば素早く修正できる
ソフトウェアが安定して動けば、ユーザーの満足度も向上する


継続的デリバリーとは？

リリースしないとユーザーには価値を提供できない
いつでも安全にリリースできる状態を保ち、ソフトウェアを繰り返し改善する
CIとCDは同列の概念に見えるが、CIはCDに包含される



2章 GitHubActionsの基礎概念

実行時エラー

コマンドの終了ステータスが0ならば成功、0以外ならば失敗見なされる
なので、ワークフローでは終了ステータスを適切に返すことが大事


手動実行

on: workflow_dispatchで手動実行できる
inputとして、列挙型となるchoice型の指定が可能


定期実行

on: schedule: cron()で定期実行できる
時刻はUTCなので注意


実行環境

GitHub-Hosted Runners

GitHubが提供するマネージドな実行環境
LargerRunnersというマシンスペック向上したものも利用可能（有料）
サポートOSとしては、Linux(Ubuntu)/Windows/macOSがある
よく使用するDocker,Node.js,npmなどは既にインストールされている

ただし、バージョン固定はできないので、バージョン固定で使用したい場合は、ワークフローの中で自分でインストールする必要ある


エフェメラルという特性

ジョブ終了時に破棄されるので、毎回クリーンな環境でジョブを実行できる
この特性は一貫性向上に貢献している




Self-Hosted Runners

利用者が実行環境を用意する




MarketPlace

再利用できるワークフローが公開されている
著名な組織にはVerifiedCreatorsマークがついているので、そういうのを利用するとセキュリティ不安が低減する（100%安全とは言い切れないが）


料金

パブリックリポジトリなら無料
プライベートは使用時間とストレージ使用量で計算される
月毎に無料枠があり、それを超えると課金が発生するが、支払い設定をしていない場合は実行できなくなるだけ（なので安心できる）
使用時間は、実行時間×ランナーごとの料率で計算される

料率はubuntuが1,Windowsが2,macOSが10なので、なるべくUbuntuを利用するのがオススメ





3章 ワークフロー構文の基礎
環境変数

単一のワークフローで使用できる
envで定義する
ワークフロー・ジョブ・ステップで定義可能

定義した場所で、環境変数のスコープが異なる


中間環境変数

コンテキスト(github.base_refのように参照できるもの)は、各ジョブ(ステップ)の中で直接スクリプトに埋め込むのはNG

理由: スクリプトインジェクションにリスクがあるため


envの中で一度変数展開し、スクリプト内ではダブルクオテーションで囲むことが推奨される

変数展開することでメモリ上で保存されるので、スクリプト生成プロセスには生成プロセスには相互作用しないため


GHAに限らず、シェルスクリプト全体で言えること



Variables

複数のワークフローで使用できる
varsコンテキストでアクセスする
こちらも参照時は中間環境変数経由(envの中で環境変数に展開してから)が推奨

Secrets

以下の特徴がある

登録した値は暗号化され、GitHub内で安全に管理される
ログ出力時はマスクされる
登録後の値確認は不可となる


ログマスクのアルゴリズムは完全一致のみ、1文字スペースを加えたりするだけで出力されてしまうので、ログマスクは当てにしないようにする

そもそもsecretsの値はログ出力しないようにしましょう



expressions(式)

${ example }のような形で定義
リテラルや演算子などが使用可能
比較演算の際、GHAでは異なる型の値を比較すると、勝手に値が変換されるので注意
オブジェクトフィルター

配列やオブジェクトから指定したプロパティを抜き出し、配列を生成する
${{ github.event.*.html_url }}のような形で*を使用する



条件分岐(if)

ifの少し面白い使い方として、最初のジョブへ条件分岐を定義し、特定の条件でスキップするようにすると、ワークフロー自体の実行がスキップできる

使用時間もゼロになり、コスト削減につながる



ネーミング

実行ログが見やすくなるのでジョブ名やステップ名はきちんと書く
run-nameは、nameとは異なり、コンテキストが利用できる

run-name: Run by ${{ github.actor }}



ステップ間のデータ共有

2つのやり方がある

GITHUB_OUTPUT環境変数

定義: echo &ldquo;=&rdquo; &raquo; &ldquo;${GITHUB_OUTPUT}&rdquo;
参照: ${{ steps..outputs. }}
参照方法を見ると分かる通り、ステップ間の依存関係が明白


GITHUB_ENV環境変数

定義: echo &ldquo;=&rdquo; &raquo; &ldquo;${GITHUB_ENV}&rdquo;
参照: ${GITHUB_ENV}
ステップIDの指定が不要なので、どのステップで環境変数を設定したかを意識する必要ない
異なる複数のステップで、同じ値を参照する場合に使える（ただしステップ間の依存がわかりづらくなる）
これで定義したものは、事実上グローバル変数なので、ワークフローが大きくなるとバグの原因になるので注意が必要


特にこだわりなければ、GITHUB_OUTPUTを使用する



GitHub APIの実行

GitHubHostedRunnerの場合は、GitHub CLIがインストールされているのでそれを使うと良い
API(CLI)の実行にはトークンが必要

GHAには簡単に使えるクレデンシャルが利用できる
ワークフロー開始時に自動生成、終了すると自動的に破棄
有効期限は、ワークフロー実行中のみなので、万が一漏れても影響範囲は限定的
取得方法は、${{ secrets.GITHUB_TOKEN }} もしくは ${{ github.token }}

どちらでも良いので、どちらかに統一するのが良い


トークンの指定は、GITHUB_TOKENもしくはGH_TOKENという名前の環境変数をセットするだけで、自動で読み込んでくれる


パーミッション

ジョブレベルとワークフローレベルで指定可能
スコープ(contents, pull-requests等)とそれに対するアクション(read, write, none)を設定する
ただしワークフローを実行しているリポジトリ以外のアクセスは許可されない
パーミッションを明示的に定義していない場合、自動でソースコードの読み込み許可はされる

一方、明示的な定義をする場合は、この暗黙的な挙動は無視されるので注意




パーミッション周りのトラブルシューティング

ワークフロー実行ログのSet up jobの中に、GITHUB_TOKEN Permissionsがあるので、そこで実行時のパーミッションを確認できる



スターターワークフロー

GitHubリポジトリのActionsからNew Workflowを選択すると、ワークフローのコレクションが並んでいるので、参考にできそう

https://github.com/actions/starter-workflows?tab=readme-ov-file



4章 継続的インテグレーションの実践

大体以下の流れでワークフローを構成する

checkout
setup(ex: actions/setup-go)
リントやテストの実行


フィルター

pathsと他の条件を指定するとAND条件になる


静的解析

actionlintは、GHAワークフローの静的解析を行ってくれるので便利


使用時間の削減（どのワークフローでも有用な設定）

ジョブ・ステップレベルのタイムアウト設定

どのワークフローにも設定するようにする（GHAのデフォルト値は360分と大変長いため）


自動キャンセル（新しいコミットが追加されたら、古いコミットで動作しているワークフローを自動でキャンセルする）


シェル

ステップごとに起動シェルをshellキーで設定可能
Ubuntuの場合、省略時はbashだが、shellキーの指定有無で起動オプションが変更される
全ステップに書くのは面倒なので、ワークフローのトップレベルにデフォルト設定(defaults句)するのが良い
デフォルトシェルにはデメリットは存在しないので、全てのワークフローに機械的に入れるのがオススメ



Concurrency

ワークフローはイベント駆動なので、イベントが発生すると起動、さらにまたイベントが発生すると起動することになる
起動制御できる仕組みとして、Concurrencyがある
concurrency: &lt;group-name&gt;とすることで、同一グループの多重制御が設定できる

さらにcancel-in-progress: trueで自動キャンセルの設定も可能（プルリクエストで最新ではないコミットのCIとかに有効）



CIの黄金律

「クリーンに保つ」

全てのステータスチェックが成功した時だけマージできるようにする


「高速に実行する」

CIの実行が遅いと、待ち時間に他の作業→CIで失敗したらその対応する時にコンテキストスイッチが必要になる
時間の無駄だし、開発効率の低下につながる
CIのスピードは大切で、理想は5分以内、遅くとも10分以内に終わらせるように


「ノイズを減らす」

CIからのフィードバックで価値ある情報の「シグナル」とそうではない「ノイズ」
判断基準としては、その情報を受け取り、これは気にしなくて良いやと流したならそれがノイズ
ノイズがあると、シグナルもスルーされてしまうので、ノイズは意識的に減らす



テスト

単体テストの割合を増やす
フレーキーテストを放置しない（閾値を超えるとテスト全体が信頼されなくなる）

Googleソフトウェアエンジニアリングでは閾値は1％とされている


遅いテストは実行タイミングをPRマージの時に限定するなど工夫する
使用しているテストツールで以下のような機能を利用する

部分実行
並列実行
シャッフル実行（テスト間の隠れた依存関係も洗い出せる）
カテゴリ実行（スローテスト用のカテゴリを作ってそれだけ実行しないみたいな）



静的解析

不要な警告は無視するのではなく抑止する

ignoreやsuppressのキーワードで検索する
抑止理由はコメントやコミットメッセージに残しておく



第5章 運用しやすいワークフロー設計

長期運用で役立つプラクティスの紹介

ロギング

ワークフローの再実行時の「Enable debug logging」を有効にすると、デバッグログが確認できる
デバッグログには以下がある

ステップデバッグログ

ステップのログの詳細（ステップステータスや各種コンテキスト）をトレースできる
SecretsまたはVariablesに「ACTIONS_STEP_DEBUG」をtrueで登録しておくことで、これらの値も確認できる


他は内部実装者向けだったりするので、割愛


Bashのトレーシングオプション

デバッグログよりシンプルで、どんなコマンドが実行され、結果はなんだったのかを知りたいケースで使用する
Bashのトレーシングオプションは、set -xを実行するだけなので、手軽だが強力
全てのコマンドが実行前に表示されるようになり、どのコマンドがどのような引数で実行されているかを確認できる


ログのグルーピング、手動マスク等もある

レポーティング

アノテーション

echo &quot;::error::This is error&quot;みたいな形で書くとジョブページにみやすい形で表示


ジョブサマリー

シンプルなテキストならアノテーションで十分だが、複数行表示したい場合等はマークダウン形式で出力される${GITHUB_STEP_SUMMARY}が便利



複数ジョブの実行制御

デフォルトでは複数のジョブを実行すると並列実行される

並列実行は、全体の実行時間を短縮できる
もしジョブの実行時間の長さに問題がある場合は、ジョブを細かく分割し、並列実行させるというアプローチもある


逐次実行させたい場合は、needsを使用する
ジョブ間のデータ共有

$GITHUB_OUTPUT環境変数に出力し、stepsコンテキスト経由で受け渡す
受け取る側は、needsコンテキストを経由で受け取る



Environments

環境差分をパラメータ化でき、VariablesとSecretsがある
参照方法は、通常のVariablesとSecretsと同一(vars.xxx, secrets.xxx)
よくあるのはワークフローの入力値で環境名をもらい、それをenvironmentsにセットし、同じ変数名(環境ごとに値が異なる)を参照

キャッシュ

actions/cachedでGHA上にキャッシュとその利用が可能
実行時のパラメータとして

key: キャッシュキー。生成と保存に利用する。
path: キャッシュ対象となるディレクトリ/ファイルパス。
restore-keys: キャッシュミス時のリストアキーを複数指定する。


キャッシュ復元時に挙動

①keyキーに定義したキャッシュキーと厳密に一致するキャッシュを探す
②リストアキーの定義順に、プレフィックスが一致するキャッシュを探す
リストアキーは省力可能であり、これはパッケージマネージャーと併用するときに威力を発揮する

大半のパッケージマネージャーはキャッシュにないファイルだけダウンロードするように振る舞う




キャッシュは、7日以上アクセスされないと自動削除される

ブラウザからリポジトリ画面で手動削除も可能


合計サイズは、リポジトリで10GBまで

キャッシュキーの設計

プラットフォームごとに異なるキャッシュを利用するようにする

キャッシュは最低でもOSごとに分離する
他にもCPUアーキテクチャや言語バージョン、パッケージマネージャーもキャッシュキーの候補
例えば、OSとCPUアーキテクチャでキャッシュを分離するなら: key: example-${{ runner.os }}-${{ runner.arch }}


依存関係を更新した時だけキャッシュを変更するようにする

package-lock.jsonのようなロックファイルがある場合、そのファイルハッシュをハッシュキーに指定する

hashfiles(&#39;**/package-lock.json)


ロックファイルが更新されない限り、キャッシュが利用されるようになる



アーティファクト

ワークフロー内で生成したファイルをアーティファクトと呼ぶ
アーティファクトはGitHubストレージへ一時的に保存ができる

ビルドしたバイナリやメトリクスデータの保存に利用できる


アーティファクトの保存はデフォルト90日で、保存時にパラメータ(retention-days)で指定可能

プライベートリポジトリだとストレージ容量は課金対象のため、保存期間を短くすると節約できる



6章 アクションによるモジュール化

ここでいう「アクションによるモジュール化」とは、ワークフローにおける小さな部品（ステップやコマンドの小さな単位）をモジュール化すること
ランナーは、呼び出し元ワークフローに依存する
アクションの実装方式は以下の3つがある

Composite: YAMLで定義
JavaScript: JSで定義
Docker Container: Dockerで動かす(ビルド・起動するDockerfileを指定)

これらはrunsのusingキーで指定する(ex: using: composite)




アクションのロケーションは「ローカル」と「リモート」がある

リモート: uses: actions/checkout@v4

URLと連動する
@v4の部分はGitのタグ（ブランチやコミットハッシュも指定可能）


ローカル: uses: ./.github/actions/hello/

先頭部分が.であることが目印
ルートディレクトリを起点にパスを記述する





CompositeAction

メタデータファイル(action.yml)が必要
メタデータ構文のワークフロー構文との違いや注意点

シェル指定が必須
githubコンテキストのeventプロパティの使用は避ける

アクションはトリガー指定ができないので、呼び出し元のワークフローによりeventの中身がガラリと変わるため


variablesとsecretsは直接参照できない

inputとして渡す必要あり

secretsを渡したらログ出力時のマスクはしてくれる




環境変数のスコープはワークフローに準拠する

ワークフロー側で定義した環境変数は参照できるし、アクション側で書き出した環境変数はワークフロー側からも参照可能


パーミッション定義できない

ワークフロー側で制御するようにする
つまり呼び出し側ワークフローでパーミッション定義を忘れると実行エラーが発生するので、どのようなパーミッションが必要かはREADMEなどに残しておくのがオススメ





アクション設計プラクティス

認知負荷の低減

利用者はコードが読みたいのではなく、アクションを使いたいだけ
なのでアクションの名前と概要はきちんとわかりやすいように書く（input/outputも）


secrets.GITHUB_TOKENの取り方

アクションからsecretsは参照できないのでsecrets.GITHUB_TOKENは参照できないが、github.tokenで同じ値を参照できる


スクリプトの切り出し

内部ロジックが大きくなってきたらshファイルとして別で切り出すと良い
切り出したshファイルは、GITHUB_ACTION_PATH環境変数で実行する必要がある

run句に単純なshファイルへの相対パスを指定するだけでは実行できない




環境変数による暗黙的な依存の回避

ワークフローとアクションで相互に環境変数は参照できるが、必要な値はinputs/outputsで明示的に受け渡すようにするのが良い
コードが追いづらくなるのと、意図せず壊れてしまうリスクがある


ロググループ化の活用

まず大前提としてきちんとログを出力する（デバッグ効率が圧倒的に良くなるため）
CompositeActionのログはステップごとに分割されないのでログを追うのが難しくなる
なのでロググループ化を活用する



アクションとNodeバージョン

GitHubが提供する多くのアクションはJSで実装されている
Nodeバージョンが上がるとアクションのメジャーバージョンが上がることが多い
このバージョンアップ作業が地味に大変な作業&hellip;

7章 クリーンなリポジトリの維持
リポジトリルール

ブランチプロテクションルールを設定しよう
コードオーナーを設定して全てのコードにオーナーシップを維持しよう

自動でコードオーナーにレビュー依頼が飛ぶ


シークレットスキャンを導入して、秘匿情報混入を検出しよう

コードやIssueの本文やコメントなどもチェックしてくれる
GitHubが定期的にチェックする（つまり事後）
プッシュプロテクションをEnableにすると、プッシュするタイミングでチェックが走る



ドキュメント

READMEは読み手のことを考える
LICENSEは確認するようにする

MITは、責任とらないけど自由に使ってねくらいのニュアンス


コミュニティヘルスファイル

CONTRIBUTING.md: コントリビューション方法のガイド（PRやIssueの出し方、コーディング規約）
CODE_OF_CONDUCT.md: 行動規範
SECURITY.md: 脆弱性報告方法など



8章 Dependabotによる依存関係バージョンアップ

ソフトウェアは何もしないと壊れるので、変更し続ける必要がある

依存関係の管理には、検知・把握・実装・テストという活動が必要


Dependabotには以下3つの依存関係の管理をサポートする機能がある

Dependabot version updates: 最新バージョンへの自動アップデート
Dependabot security updates: 脆弱性を含むバージョンの自動アップデート
Dependabot alerts: 脆弱性が含まれるバージョンのアラート通知


ワークフローで実践

ブランチプロテクションルールを設定し、全てのステータスチェックを行ってからマージしたい場合

GitHub CLIのmergeコマンドに--autoをつけることで、全ワークフローの成功状態になった後に、自動でマージしてくれる




Dependabotが起動したワークフローは通常のsecretsへのアクセスができないので、Dependabot用のsecretsを登録する必要があるので注意

厄介なのが何もエラーが出ず、空文字で処理が進むので、頭の片隅に入れておくと良い


dependabot/fetch-metadataアクションを活用する

Dependabotが起動するワークフローで使用可能で、バージョンアップ・依存関係の種類、パッケージエコシステムを取得できる
有効活用の例

パッチバージョンの場合は自動マージ
開発環境向けの変更は自動マージ
GHA向けの変更は自動マージ
このように少しでも手動対応量を減らすことで、少しでも楽をする





9章 GitHub Releasesによるリリース自動化

バージョニング

いつどんな変更が行われたのかをバージョンを併記してユーザーに知らせることができる
トラブル時はバージョン情報をやり取りすることで関係者間の意思疎通が楽になる
開発者としてもどのバージョンで不具合が発生したかがわかれば、修正が楽になる


セマンティックバージョニング

メジャー.マイナー.パッチという構成のバージョニング方式
順序性だけでなく、後方互換性に関心を寄せているのが特徴
完璧ではない（後方互換性が個人の考え方やスキルに依存する点）が、有名であること視認性が高いことで、選択としては無難である


Gitタグの保護はやっておこう（ブランチ保護と同じような感じ）

ReleasesがGitタグに依存しており、そのGitタグが削除された場合、リリースノートは下書き状態となってしまうため



10章 GitHub Packagesによるパッケージ管理

パッケージエコシステム

npmやMavenなどの言語パッケージ、HomebrewなどのOSパッケージ、Dockerなどのコンテナイメージもパッケージの一種
ソフトウェアのインストール・管理（依存関係の把握、ライブラリが足りなければ自動でダウンロード、新しいバージョンの検知、最新版へのアップデート等）を容易にする
提供者はパッケージマネージャークライアントを通じてパッケージを作成・登録＆メタデータを提供し、利用者はパッケージマネージャークライアントを通じてパッケージを検索・取得・更新＆依存関係を解決する（そしてこの両者をつなぐのがパッケージレジストリ）


ContainerRegistryの話がメインで、使いそうもないのでスキップ

11章 OpenID Connectによるセキュアなクラウド連携
クラウドプロバイダのクレデンシャル

クラウドプロバイダは誰がアクセスしようとしているかを「認証」によって判断する
クレデンシャルは、その認証に利用するもので、ユーザーIDとパスワードもその一種
認証する側が、アクセスキーやAPIキーといった呼び名のランダム文字列を発行し、それをクレデンシャルとして利用する
プログラムがリクエスト時にそのクレデンシャルを一緒に送信することで、認証と認証情報が正しければ正常レスポンスを受け取れるという仕組み
静的クレデンシャル

長期にわたって変更しないパスワードのようなクレデンシャルを静的クレデンシャルという
静的クレデンシャルは長命という欠点があり、漏洩した場合の被害が拡大しやすい


一時クレデンシャル

こちらは必要なタイミングで都度払い出すので短命
ローテーション作業もないので運用も楽
OpenID Connectというプロトコルによって実現する


クラウド連携のアンチパターン

静的クレデンシャルは使用してはいけない
かつてはそれしか選択肢がなかったので、記事を探すときは要注意



OpenID Connect(OIDC)

これは複数の異なるドメインで認証結果を共有し、協調してサービスを提供するオープンなプロトコル（アイデンティ連携を実現する）
OAuth2.0を拡張する形で設計されている
利点として、GitHub上で静的クレデンシャルの管理が不要になる(一時クレデンシャルを取得するため)＋認証時にアクセス元を細かく制限できる（GHAの場合特定リポジトリのみに許可できる）

一時クレデンシャルの取得フロー

ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する


GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider)
OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ)
一時クレデンシャルで操作


大抵の処理は隠蔽されており、私たちは行う作業は以下の2つのみ（準備に若干手間はかかるがメリットが大きい）

クラウドプロバイダ側でOIDCに必要なコンポーネントを作成する
ワークフローへクラウドプロバイダの認証アクションを組み込む



OIDC TrustとCloud Roles

クラウドプロバイダで準備するコンポーネントは以下の2つ

OIDC Trust: クラウドプロバイダが信頼するOIDC Providerを設定(GitHub OIDC Provider)

OIDCトークンで一時クレデンシャルを取得できる理由は、クラウドプロバイダがOIDC Providerを信頼しているため（OIDC Trust）
OIDCトークンはJWT形式で、GitHub OIDC Providerの公開鍵を使って署名等の検証が行われる


Cloud Roles: 一時クレデンシャルのアクセス先とアクセス元を制御

一時クレデンシャルの「アクセス先」を管理する
AWSでいうIAMロールのこと





認証アクション

各クラウドプロバイダは公式で認証アクションを提供しているので、ワークフローからはそのアクションを呼び出すだけで、OIDCが扱える

検証作業のリスクヘッジ

プライベートリポジトリで試す
認証パラメータ(AWSアカウントIDやIAMロール名)はSecretsで管理する

これらクレデンシャルではないものの、ログ出力時にマスクされるので、謝ってパブリックリポジトリでワークフローを実行しても、第三者へ余計な情報が漏れない



AWSにおけるOIDC利用準備と連携

以下の2つを作成する

OIDC Provider

AWSがGitHub OIDC Providerを信頼するように設定


IAMロール

一時クレデンシャルのアクセス先とアクセス元を制御する




GHAワークフロー側での設定作業

Secrets登録

AWSアカウントID
IAMロール名




ワークフロー実装

permissions

id-token: writeの設定が必要

GitHub OIDC ProviderからOIDCトークン取得に必要




aws-actions/configure-aws-credentialsを利用

ロールARNとセッション名、デフォルトリージョンをパラメータとして指定する
セッション名は、トレーザビリティを目的に、AssumeRole APIに渡すパラメータ名であり、CloudTrailのセッション名として記録される

「誰が・いつ・どのジョブでこのセッションを作ったか分かる」ような情報を含めると便利
例：&quot;${{ github.workflow }}-${{ github.run_id }}-${{ github.actor }}&quot;






CloudRolesのセキュアな運用

他のリポジトリからアクセスできないことを確認しておく
CloudRolesは目的ごとに分離する（必要最小限の権限だけ）
クラウドプロバイダの設定作業にIaCを導入する



12章 コンテナオーケストレーションのデプロイメント

デプロイ自動化の流れ

コンテナビルドアクション：コンテナイメージのビルド＆プッシュ
コンテナデプロイアクション：タスク定義の書き換えとサービスの更新


本番環境へのデプロイはルールを制限したい

Deployment branches and tagsを設定する

Environmentsからブランチ名パターンを登録することでパターン外のブランチでワークフローを起動できなくなる


Required Reviewers

ワークフローの起動に承認を必須とする





デプロイメント設計

デプロイの設計では「ユーザー影響」と「ロールバック」の観点に着目する
ローリングアップデート

ECSのデプロイ方式
新しいバージョンへ少しずつ置き換える
無停止


ロールバック

ローリングアップデートの場合は特別な仕組みはないので、リバートコミットを追加し、再デプロイする（あまり速くない）
人間が切り戻しを検知・判断するので、別途監視の仕組みが必要となる



第14章 GitHub Actionsの高度な使い方
Reusable Workflows

アクションは比較的小さな処理をカプセル化するのに対し、Reusable Workflowsはワークフロー全体を丸ごとカプセル化する
パーミッション

パーミッション定義を省略した場合は呼び出し側ワークフローのパーミッションを暗黙的に継承する
呼び出し側より厳しくできるが、緩めることはできない

なので、呼び出し側ではジョブレベルでパーミッションを定義すると良い（Reusable Workflowsの権限が最小限になるため＋ドキュメンテーションとなり可読性が向上する）




コンテキスト

呼び出し側ワークフローのコンテキストを直接参照できる
ただしReusable Workflowsが制御できないgithub.eventプロパティを参照すると再利用性は低下するので注意が必要


Secrets

呼び出し側ワークフローのコンテキストを直接参照できない
入力パラメータ経由で渡す or 呼び出し側でsecrets: inheritを指定するとまとめて継承可能

暗黙的な継承となりコードが追いづらくなるので個別で入力パラメータとして渡すのが良い




環境変数

こちらも参照できないので入力パラメータ経由で渡す



fromJSON関数

動的なワークフロー定義

事前にマトリクスを生成できない場合、fromJSON()をmatrixに指定することで動的にマトリクスを生成できる


文字列の型変換

ワークフロー構文の環境変数はstring型として扱われてしまう
その際string型の文字列をnumber型やboolean型に変換できる



エラーハンドリング

Continue on Error

デフォルトではエラーが発生するとその時点でワークフローが停止する
continue-on-error: trueを指定すると、エラーを握りつぶし、次の処理に進む
これを指定すると、途中でエラーが発生しても、ワークフロー自体は正常終了扱いされる
ログを見ない限りエラーには気づけないので、リカバリー不要な場合のみ使用する


マトリックスのフェイルファスト

マトリックスを使うと複数のジョブが並列に起動する
途中でエラーが発生した場合、他のジョブが止まる
fail-fast: falseを指定することで他のジョブを継続可能とできる



コンテキストによるフロー制御

終了状態を取得できるコンテキスト

stepsコンテキスト：ステップの終了状態を保持

outcomeプロパティはContinue on Error適用前の終了状態（つまり生情報）
conclusionプロパティはContinue on Error適用後の終了状態


needsコンテキスト：（依存している）ジョブの終了状態を保持

resultプロパティのみ




コンテキストとステータスチェック関数の併用

「前のステップが失敗したら」という条件式を書きたい場合

if: ${{ failure() &amp;&amp; steps.stepName.outcome == &#39;failure&#39; }}とする必要がある
このようにステータスチェック関数とコンテキスト参照を併用する必要がある理由として、failure()が記述されていない場合、暗黙的にsuccess()関数が存在すると解釈されるため





15章 GitHub Actionsのセキュリティ

この章では「ソフトウェアサプライチェーン」に着目する

ソフトウェアサプライチェーンとは、コード書いてから実行環境へリリースまでに含まれる一連のアクティビティを意味する


GHAはさまざまなシステムと連携するため、強力な権限が集中するため、悪意ある人にとってはとても魅力な攻撃対象になる

セキュリティのCIA

CIAとは、機密性・完全性・可用性のこと
CIAの観点から、守るべき資産はコード・クレデンシャル・アーティファクトとなる
闇雲に対策するのではなく、利便性とのトレードオフとなる

セキュリティの設計原則

脅威を完全に排除することは難しいので、脅威の軽減を目標とする
アタックサーフェス＝攻撃される恐れのある場所を小さくする

シンプルな設計を意識する（複雑な設計では意図しないこれ↑を生みやすいので）


複数のセキュリティレイヤを用意して、多層防御にする
最小権限

攻撃されても被害を小さくできる
一時クレデンシャルのような権限の行使に時間の制約があるようなものも有効だと思われる



Githubのサービス特性

上記の設計原則を踏まえて考えていく
GitHubはデフォルトの設定は利便性重視なので注意する
コードをプッシュできる人はワークフローの実行ができるという仕様を理解する
悪意ある人もコントリビューション可能であることを認識する

サードパーティアクション

サードパーティのアクションがリポジトリのコードを参照できるかはパーミションによるが、ほとんどのワークフローではコードにチェックアウトするので、大半のアクションはコードを参照できる
サードパーティアクション導入時は、そのサードパーティを信頼するかを意識的に決断するようにする

本当に信頼して良いかを考えるクセをつけるのが重要


リポジトリ設定で利用制限も可能
呼び出し時にコミットハッシュによる固定を行えば、アクションを不変リソースとして扱える

ハッシュ指定だけでは分かりづらいので、コメントでバージョン情報を併記しておくと分かりやすい


筆者の考えとしては「ある程度の車輪の再発明は仕方ない」それくらいサードパーティアクションの使用は慎重になるべき

スクリプトインジェクション

外からやってくるデータ（例：PRのタイトル）に悪意あるスクリプトが仕込まれていた場合、それがワークフローの中で読み込まれてスクリプトとして実行されてしまうリスクがある
対策として、

中間環境変数による無害化

env: PR_TITLE: ${{ github.event.pull_request.title }}というような形でスクリプトインジェクションを防げる
どのプロパティが危険かを正確に判断するのは困難なので、コンテキストは常に中間環境変数で参照するようにするのが確実で楽


ShellCheckによる静的解析

Github-Hosted Runnerには最初からインストールされている
actionlintは内部的にShellCheckを実行していて、yamlに直接書いたスクリプトもチェックしてくれる





最小権限のパーミッション

パーミッションはpermissionキーで設定可能
省略可能で、省略した場合はコード参照が許可される
明示的な記述を習慣化することで、自然とパーミッションを意識するようになる

具体的には、

ワークフローレベルでのパーミッション無効化(permissions: {})の設定を入れることで、コード参照すら明示的な許可が必要になる
各ジョブへ都度、必要なパーミッションを定義する


面倒に見えるが、やってみると慣れるのは早い



ジョブ分割によるパーミッションの分離

パーミッションのスコープはいくつかあるが、特に注意すべきなのが以下の4つ

contents: 改竄されたコードをプッシュされるリスク
packages: 悪意あるパッケージをパブリッシュされるリスク
actions: 別のワークフローを意図せず起動されるリスク
id-token: OIDCでクラウドプロバイダにアクセスされるリスク


これらのパーミッションを複数扱う場合はジョブの分割を検討すると良い

パーミッションをジョブ単位で記述すれば、ジョブがセキュリティ境界となる



シークレットマネジメント

まずはクレデンシャルの把握をすべき
最小権限・一時クレデンシャルを優先・定期的なローテーション

OpenID Connectハードニング

OpenID Connectを深掘りするパート
(再掲)一時クレデンシャルの取得フロー

ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する

GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider)
OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ)
一時クレデンシャルで操作


IDトークン

上記の1のOIDCトークンと呼んでいるものはOIDCの世界ではIDトークンと呼ぶ
これには主体に認証情報を含んでおり、リポジトリやワークフローの情報が含まれている
これらの属性情報を受け取ったクラウドプロバイダ側で検証し、アクセス可否を判断している
IDトークンの実体は、JWTである

ヘッダ・ペイロード・署名をピリオド区切りでBase64URLエンコードしたもの
ペイロードのデータ構造は決まっており、JSONの各フィールドはクレームと呼ぶ
IDトークンにはいくつかの必須クレームがあり、この必須クレームがセキュリティ上重要となる


IDトークンの検証フロー

ワークフローはGitHub OIDC Providerから取得したIDトークンをクラウドプロバイダに渡す
クラウドプロバイダはIDトークンの署名を検証し、JWTクレームを検証する
この検証に成功したら、一時クレデンシャルをワークフローに返送する


IDトークンの署名検証

本当にGitHub OIDC Providerが発行したIDトークンなのか確認する
署名の検証には、GitHub OIDC Providerの公開鍵を探し出す必要がある
どこを探すかというと、OIDC Trust(AWSの場合はOpenID Connect Provider)にGitHub OIDC ProviderのURLを設定していて、このURLが公開鍵の検索に使用される（https://token.actions.githubusercontent.com）
注意点として、上記のURLは全アカウントで共通のため、アカウントやリポジトリの識別ができない（GitHubが生成したという内容しか検証できない）

そこでJWTクレーム検証でその部分を補う形で検証する




IDトークンのJWTクレーム検証

IDトークンの署名だけではGitHub利用者が誰でもアクセスできてしまうため、JWTクレームでも検証を行う
JWTクレーム検証はクラウドプロバイダによって異なるが、AWSではAssumeRoleポリシーのCondition定義に基づいて検証を行う
subクレーム

もっとも重要な検証対象となる
認証された主体の識別子が格納される（一般的にはユーザーIDなど）
GitHub Actionsでは少し毛色が異なり、ワークフローの属性情報を連結した値が入る（アカウント名やリポジトリ名など）

ワークフローの実行方法によって値が異なるが、repo:/:のような文字列はどの方法でも含まれる
なのでアカウント名やリポジトリ名が正しいかの判断は可能




GitHubのカスタムクレーム

IDトークンは拡張が認めらていて、任意のカスタムクレームを追加可能
クラウドプロバイダによってサポート状況が異なっているので注意（AWSはサポートしていない）


クラウドプロバイダのJWTクレーム検証設定

AssumeRoleポリシーのConditionに以下のように記述する

&quot;token.actions.githubusercontent.com:sub&quot;: &quot;repo:&lt;OWNER&gt;/&lt;REPO&gt;:*&quot;


左辺のキーはsubクレームを指している
他の値もsubクレームで検証するとセキュリティがより強固になる


Environmentsの検証

subクレームに含まれるEnvironmentsの値を検証することで、商用環境にアクセスできるのはレビュー済みのワークフローのみとしたいといった制御が可能


JWTクレームの検証はOpenID Connectのキモであり、特にsubクレームは重要となる







16章 セキュリティのシフトレフト

セキュリティは後回しにしがちだが早めに取り組むのが良い戦略

これがシフトレフトという考え方（痛い目に遭うくらいなら早めに対処しよう）


依存関係の脆弱性スキャン

最新に保ち続けられるならそれで十分だけど現実はそうもいかない
そこで活用したいのが依存関係の脆弱性を検出するサービス

Dependabot Alerts

依存関係の脆弱性を発見するとアラートを送信する
「新たなコードのプッシュでDependency Graphが更新された時（例えばpackage.jsonなどのファイルが更新された時と同意かな？）」と「脆弱性データベースであるGitHub Advisory Databaseに脆弱性が登録された時」のタイミングでリポジトリをチェックしてくれる


Dependabot security updates

Alertsは情報提供で、これはプルリクエスト作成まで行ってくれるサービス
「security updates」は脆弱性のパッチを当てたバージョンへあげるもの（「version updates」の方は常に最新バージョンにあげるという違いがある）


設定ファイルについて

.github/dependabot.ymlは、security updatesとversion updatesで共有される

共有されるということは除外ルールを書いたらどちらでも検知されない


なので防御策として、Alertsを合わせて有効化しておくと良い（Alertsは設定ファイルに依存しない）そうすれば検出漏れを最小限にできる






シークレットスキャン

GitHubのシークレットスキャン機能は経済的理由で導入が困難な場合もある
SecretlintというDockerで動かせるAWSやGitHubなどの主要サービスのクレデンシャルを検出できる

これをGitHubActionsで動かすと尚良い
その際、検出された情報がログ出力されないように注意（--maskSecretsオプションで設定可能）


途中からシークレットスキャンを導入する場合は全ヒストリーをスキャンするGitleaksというツールがある

これもDockerで動かせる


git push前にスキャンするのがベター

.git/hooks/pre-commitファイルへシークレットスキャンコマンドを組み込むとコミット時にスキャンが実行あsれる
個々人で設定可能が必要であり、ストレスに感じる人もいるため、実際にやるかどうかは個人の判断に委ねると良い




アプリケーションスキャン

Static Application Security Testing(SAST)

コードスキャンしてセキュリティ問題を検出する（静的解析）
Goだとsecurego/gosec: Go security checkerがそれみたい


コンテナイメージの脆弱性スキャン

Trivyというツール
他にはコンテナレジストリでスキャン実施できる




Infrastructure as Codeセキュリティ

IaCで作業ミスは抑制できるが、セキュリティミスは防げない
そしてパッと見で正しく動作しているように見えるので意外と発見が難しい
セキュリティ設定ミスの防止

ここでもTrivyが活躍する
万事解決とまでいかないが、優れた出発点となる


Policy as Code

Conftestというツールが使える
ポリシールールを設定ファイルに記述し、それを検証してくれる
これもDockerで動かせるのでワークフローに簡単に実行できる
選択肢の1つとして持っておくと良い




継続的なセキュリティの改善

誤検出と検出漏れはどうしても発生する（バランス・トレードオフ）
誤検出は想像異常にストレスが大きい
またツールを導入しすぎるたりして検出される問題が多すぎるとアラート疲れも発生する
時々立ち返って運用を見返すのが良い



18章 継続的デリバリーの実践

組織パフォーマンスを研究しているGoogleのDORAというチーム曰く「ソフトウェアデリバリーパフォーマンスは組織パフォーマンスと高い相関がある」と学術的な方法で示したこと
DORAの研究では「スピードが速い組織ほど品質も高い」を提唱している
加えて、個人の幸福や組織文化にも寄与すると考えられている
この章では「継続的デリバリー」うまく実践するために、何ができるかを紹介していく

バージョン管理戦略

継続的デリバリーは適切なバージョン管理から始まる
大原則は「ソフトウェアの実行に必要なあらゆるものをバージョン管理する」

ソースコードだけではなく、テスト・ビルド・デプロイ・データベースマイグレーション・運用などのスクリプト・インフラ設定もバージョン管理の対象（つまりクレデンシャル以外）


1日に1回はデフォルトブランチにマージする短命なブランチ運用＝トランクベース開発をすることで、コード変更量が小さいのでレビューしやすかったりコンフリクトが発生しづらかったりする

実装途中の機能を一時的に無効化したい場合は「フィーチャートグル」を使えば良い
詳細: 機能トグル（別名機能フラグ）



テスト戦略

CDの品質改善では、4章で説明した自動テストが重要な役割を担う
それ以外の異なる観点を提供するものとして、以下の2つがある

探索的テスト

自動化できないテストのこと
テストの目的は「調査」と「検証」がある
自動テストは記事の問題を「検証「することで、探索的テストは人間が手動で未知の問題を「調査」すること（目的が異なる）

Testing in Production

リリース後も本番環境でテストする
A/Bテストやシンセティックテストなど

リリース戦略

恐怖の克服

いくら自動化しても経験しないと恐怖は薄れない
自分の手でリリースすることが大切


ロールバック

ロールバックも全員が慣れておく
頻度が少ないためにやり方を知らない人がいるので手順を周知し、平時にロールバックの練習をしておく


デプロイとリリースの分離

分離していない場合にデプロイに問題があった時は全ユーザーに影響がある
分離する方法として、デプロイ後にユーザートラフィックを少しずつ新しい環境に流す「カナリアリリース」がある



データベースの変更管理

手作業でデータベースコマンドを実行してはダメ
マイグレーションスクリプト経由で実行すると、ヒューマンエラーも発生しない

ロールバック用のスクリプトも用意するようにする



IaCの変更管理

IaCはソフトウェアとライフサイクルが異なるため、固有の考慮点が存在する
ツールにドライ欄があるならそれを使用する

毎回手動実行は大変なので、プルリクエスト作成時に自動で実行し、それをコメントに貼り付ける


「本番環境への適用はデフォルトブランチにマージした時のみ」という規律を設けるべき
IaCはローカルからの変更は事故が起きやすいので止める
実行環境は強力な権限が必要なので、絶対消されてはいけないDB等のリソース削除を禁止したり、権限昇格なIAM操作を禁止すべき
構成ドリフト（実態とコードの差分がある状態）は定期的にドライランを実行して通知させよう

疎結合なアーキテクチャ

疎結合はCDがとても実践しやすい
テストやデプロイの容易性
">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/my-hugo-blog/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "GitHub CICD実践ガイド",
      "item": "http://localhost:1313/my-hugo-blog/posts/010_github_cicd%E5%AE%9F%E8%B7%B5%E3%82%AC%E3%82%A4%E3%83%89/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "GitHub CICD実践ガイド",
  "name": "GitHub CICD実践ガイド",
  "description": "1章 ソフトウェア開発とGitHub 継続的インテグレーションとは？ コードの変更を頻繁にコードベースに統合し、正しく動作するかを繰り返し検証する 統合頻度が上がるとコンフリクトが減る 繰り返して検証を行うとバグを発見すれば素早く修正できる ソフトウェアが安定して動けば、ユーザーの満足度も向上する 継続的デリバリーとは？ リリースしないとユーザーには価値を提供できない いつでも安全にリリースできる状態を保ち、ソフトウェアを繰り返し改善する CIとCDは同列の概念に見えるが、CIはCDに包含される 2章 GitHubActionsの基礎概念 実行時エラー コマンドの終了ステータスが0ならば成功、0以外ならば失敗見なされる なので、ワークフローでは終了ステータスを適切に返すことが大事 手動実行 on: workflow_dispatchで手動実行できる inputとして、列挙型となるchoice型の指定が可能 定期実行 on: schedule: cron()で定期実行できる 時刻はUTCなので注意 実行環境 GitHub-Hosted Runners GitHubが提供するマネージドな実行環境 LargerRunnersというマシンスペック向上したものも利用可能（有料） サポートOSとしては、Linux(Ubuntu)/Windows/macOSがある よく使用するDocker,Node.js,npmなどは既にインストールされている ただし、バージョン固定はできないので、バージョン固定で使用したい場合は、ワークフローの中で自分でインストールする必要ある エフェメラルという特性 ジョブ終了時に破棄されるので、毎回クリーンな環境でジョブを実行できる この特性は一貫性向上に貢献している Self-Hosted Runners 利用者が実行環境を用意する MarketPlace 再利用できるワークフローが公開されている 著名な組織にはVerifiedCreatorsマークがついているので、そういうのを利用するとセキュリティ不安が低減する（100%安全とは言い切れないが） 料金 パブリックリポジトリなら無料 プライベートは使用時間とストレージ使用量で計算される 月毎に無料枠があり、それを超えると課金が発生するが、支払い設定をしていない場合は実行できなくなるだけ（なので安心できる） 使用時間は、実行時間×ランナーごとの料率で計算される 料率はubuntuが1,Windowsが2,macOSが10なので、なるべくUbuntuを利用するのがオススメ 3章 ワークフロー構文の基礎 環境変数 単一のワークフローで使用できる envで定義する ワークフロー・ジョブ・ステップで定義可能 定義した場所で、環境変数のスコープが異なる 中間環境変数 コンテキスト(github.base_refのように参照できるもの)は、各ジョブ(ステップ)の中で直接スクリプトに埋め込むのはNG 理由: スクリプトインジェクションにリスクがあるため envの中で一度変数展開し、スクリプト内ではダブルクオテーションで囲むことが推奨される 変数展開することでメモリ上で保存されるので、スクリプト生成プロセスには生成プロセスには相互作用しないため GHAに限らず、シェルスクリプト全体で言えること Variables 複数のワークフローで使用できる varsコンテキストでアクセスする こちらも参照時は中間環境変数経由(envの中で環境変数に展開してから)が推奨 Secrets 以下の特徴がある 登録した値は暗号化され、GitHub内で安全に管理される ログ出力時はマスクされる 登録後の値確認は不可となる ログマスクのアルゴリズムは完全一致のみ、1文字スペースを加えたりするだけで出力されてしまうので、ログマスクは当てにしないようにする そもそもsecretsの値はログ出力しないようにしましょう expressions(式) ${ example }のような形で定義 リテラルや演算子などが使用可能 比較演算の際、GHAでは異なる型の値を比較すると、勝手に値が変換されるので注意 オブジェクトフィルター 配列やオブジェクトから指定したプロパティを抜き出し、配列を生成する ${{ github.event.*.html_url }}のような形で*を使用する 条件分岐(if) ifの少し面白い使い方として、最初のジョブへ条件分岐を定義し、特定の条件でスキップするようにすると、ワークフロー自体の実行がスキップできる 使用時間もゼロになり、コスト削減につながる ネーミング 実行ログが見やすくなるのでジョブ名やステップ名はきちんと書く run-nameは、nameとは異なり、コンテキストが利用できる run-name: Run by ${{ github.actor }} ステップ間のデータ共有 2つのやり方がある GITHUB_OUTPUT環境変数 定義: echo \u0026ldquo;=\u0026rdquo; \u0026raquo; \u0026ldquo;${GITHUB_OUTPUT}\u0026rdquo; 参照: ${{ steps..outputs. }} 参照方法を見ると分かる通り、ステップ間の依存関係が明白 GITHUB_ENV環境変数 定義: echo \u0026ldquo;=\u0026rdquo; \u0026raquo; \u0026ldquo;${GITHUB_ENV}\u0026rdquo; 参照: ${GITHUB_ENV} ステップIDの指定が不要なので、どのステップで環境変数を設定したかを意識する必要ない 異なる複数のステップで、同じ値を参照する場合に使える（ただしステップ間の依存がわかりづらくなる） これで定義したものは、事実上グローバル変数なので、ワークフローが大きくなるとバグの原因になるので注意が必要 特にこだわりなければ、GITHUB_OUTPUTを使用する GitHub APIの実行 GitHubHostedRunnerの場合は、GitHub CLIがインストールされているのでそれを使うと良い API(CLI)の実行にはトークンが必要 GHAには簡単に使えるクレデンシャルが利用できる ワークフロー開始時に自動生成、終了すると自動的に破棄 有効期限は、ワークフロー実行中のみなので、万が一漏れても影響範囲は限定的 取得方法は、${{ secrets.GITHUB_TOKEN }} もしくは ${{ github.token }} どちらでも良いので、どちらかに統一するのが良い トークンの指定は、GITHUB_TOKENもしくはGH_TOKENという名前の環境変数をセットするだけで、自動で読み込んでくれる パーミッション ジョブレベルとワークフローレベルで指定可能 スコープ(contents, pull-requests等)とそれに対するアクション(read, write, none)を設定する ただしワークフローを実行しているリポジトリ以外のアクセスは許可されない パーミッションを明示的に定義していない場合、自動でソースコードの読み込み許可はされる 一方、明示的な定義をする場合は、この暗黙的な挙動は無視されるので注意 パーミッション周りのトラブルシューティング ワークフロー実行ログのSet up jobの中に、GITHUB_TOKEN Permissionsがあるので、そこで実行時のパーミッションを確認できる スターターワークフロー GitHubリポジトリのActionsからNew Workflowを選択すると、ワークフローのコレクションが並んでいるので、参考にできそう https://github.com/actions/starter-workflows?tab=readme-ov-file 4章 継続的インテグレーションの実践 大体以下の流れでワークフローを構成する checkout setup(ex: actions/setup-go) リントやテストの実行 フィルター pathsと他の条件を指定するとAND条件になる 静的解析 actionlintは、GHAワークフローの静的解析を行ってくれるので便利 使用時間の削減（どのワークフローでも有用な設定） ジョブ・ステップレベルのタイムアウト設定 どのワークフローにも設定するようにする（GHAのデフォルト値は360分と大変長いため） 自動キャンセル（新しいコミットが追加されたら、古いコミットで動作しているワークフローを自動でキャンセルする） シェル ステップごとに起動シェルをshellキーで設定可能 Ubuntuの場合、省略時はbashだが、shellキーの指定有無で起動オプションが変更される 全ステップに書くのは面倒なので、ワークフローのトップレベルにデフォルト設定(defaults句)するのが良い デフォルトシェルにはデメリットは存在しないので、全てのワークフローに機械的に入れるのがオススメ Concurrency ワークフローはイベント駆動なので、イベントが発生すると起動、さらにまたイベントが発生すると起動することになる 起動制御できる仕組みとして、Concurrencyがある concurrency: \u0026lt;group-name\u0026gt;とすることで、同一グループの多重制御が設定できる さらにcancel-in-progress: trueで自動キャンセルの設定も可能（プルリクエストで最新ではないコミットのCIとかに有効） CIの黄金律 「クリーンに保つ」 全てのステータスチェックが成功した時だけマージできるようにする 「高速に実行する」 CIの実行が遅いと、待ち時間に他の作業→CIで失敗したらその対応する時にコンテキストスイッチが必要になる 時間の無駄だし、開発効率の低下につながる CIのスピードは大切で、理想は5分以内、遅くとも10分以内に終わらせるように 「ノイズを減らす」 CIからのフィードバックで価値ある情報の「シグナル」とそうではない「ノイズ」 判断基準としては、その情報を受け取り、これは気にしなくて良いやと流したならそれがノイズ ノイズがあると、シグナルもスルーされてしまうので、ノイズは意識的に減らす テスト 単体テストの割合を増やす フレーキーテストを放置しない（閾値を超えるとテスト全体が信頼されなくなる） Googleソフトウェアエンジニアリングでは閾値は1％とされている 遅いテストは実行タイミングをPRマージの時に限定するなど工夫する 使用しているテストツールで以下のような機能を利用する 部分実行 並列実行 シャッフル実行（テスト間の隠れた依存関係も洗い出せる） カテゴリ実行（スローテスト用のカテゴリを作ってそれだけ実行しないみたいな） 静的解析 不要な警告は無視するのではなく抑止する ignoreやsuppressのキーワードで検索する 抑止理由はコメントやコミットメッセージに残しておく 第5章 運用しやすいワークフロー設計 長期運用で役立つプラクティスの紹介 ロギング ワークフローの再実行時の「Enable debug logging」を有効にすると、デバッグログが確認できる デバッグログには以下がある ステップデバッグログ ステップのログの詳細（ステップステータスや各種コンテキスト）をトレースできる SecretsまたはVariablesに「ACTIONS_STEP_DEBUG」をtrueで登録しておくことで、これらの値も確認できる 他は内部実装者向けだったりするので、割愛 Bashのトレーシングオプション デバッグログよりシンプルで、どんなコマンドが実行され、結果はなんだったのかを知りたいケースで使用する Bashのトレーシングオプションは、set -xを実行するだけなので、手軽だが強力 全てのコマンドが実行前に表示されるようになり、どのコマンドがどのような引数で実行されているかを確認できる ログのグルーピング、手動マスク等もある レポーティング アノテーション echo \u0026quot;::error::This is error\u0026quot;みたいな形で書くとジョブページにみやすい形で表示 ジョブサマリー シンプルなテキストならアノテーションで十分だが、複数行表示したい場合等はマークダウン形式で出力される${GITHUB_STEP_SUMMARY}が便利 複数ジョブの実行制御 デフォルトでは複数のジョブを実行すると並列実行される 並列実行は、全体の実行時間を短縮できる もしジョブの実行時間の長さに問題がある場合は、ジョブを細かく分割し、並列実行させるというアプローチもある 逐次実行させたい場合は、needsを使用する ジョブ間のデータ共有 $GITHUB_OUTPUT環境変数に出力し、stepsコンテキスト経由で受け渡す 受け取る側は、needsコンテキストを経由で受け取る Environments 環境差分をパラメータ化でき、VariablesとSecretsがある 参照方法は、通常のVariablesとSecretsと同一(vars.xxx, secrets.xxx) よくあるのはワークフローの入力値で環境名をもらい、それをenvironmentsにセットし、同じ変数名(環境ごとに値が異なる)を参照 キャッシュ actions/cachedでGHA上にキャッシュとその利用が可能 実行時のパラメータとして key: キャッシュキー。生成と保存に利用する。 path: キャッシュ対象となるディレクトリ/ファイルパス。 restore-keys: キャッシュミス時のリストアキーを複数指定する。 キャッシュ復元時に挙動 ①keyキーに定義したキャッシュキーと厳密に一致するキャッシュを探す ②リストアキーの定義順に、プレフィックスが一致するキャッシュを探す リストアキーは省力可能であり、これはパッケージマネージャーと併用するときに威力を発揮する 大半のパッケージマネージャーはキャッシュにないファイルだけダウンロードするように振る舞う キャッシュは、7日以上アクセスされないと自動削除される ブラウザからリポジトリ画面で手動削除も可能 合計サイズは、リポジトリで10GBまで キャッシュキーの設計 プラットフォームごとに異なるキャッシュを利用するようにする キャッシュは最低でもOSごとに分離する 他にもCPUアーキテクチャや言語バージョン、パッケージマネージャーもキャッシュキーの候補 例えば、OSとCPUアーキテクチャでキャッシュを分離するなら: key: example-${{ runner.os }}-${{ runner.arch }} 依存関係を更新した時だけキャッシュを変更するようにする package-lock.jsonのようなロックファイルがある場合、そのファイルハッシュをハッシュキーに指定する hashfiles('**/package-lock.json) ロックファイルが更新されない限り、キャッシュが利用されるようになる アーティファクト ワークフロー内で生成したファイルをアーティファクトと呼ぶ アーティファクトはGitHubストレージへ一時的に保存ができる ビルドしたバイナリやメトリクスデータの保存に利用できる アーティファクトの保存はデフォルト90日で、保存時にパラメータ(retention-days)で指定可能 プライベートリポジトリだとストレージ容量は課金対象のため、保存期間を短くすると節約できる 6章 アクションによるモジュール化 ここでいう「アクションによるモジュール化」とは、ワークフローにおける小さな部品（ステップやコマンドの小さな単位）をモジュール化すること ランナーは、呼び出し元ワークフローに依存する アクションの実装方式は以下の3つがある Composite: YAMLで定義 JavaScript: JSで定義 Docker Container: Dockerで動かす(ビルド・起動するDockerfileを指定) これらはrunsのusingキーで指定する(ex: using: composite) アクションのロケーションは「ローカル」と「リモート」がある リモート: uses: actions/checkout@v4 URLと連動する @v4の部分はGitのタグ（ブランチやコミットハッシュも指定可能） ローカル: uses: ./.github/actions/hello/ 先頭部分が.であることが目印 ルートディレクトリを起点にパスを記述する CompositeAction メタデータファイル(action.yml)が必要 メタデータ構文のワークフロー構文との違いや注意点 シェル指定が必須 githubコンテキストのeventプロパティの使用は避ける アクションはトリガー指定ができないので、呼び出し元のワークフローによりeventの中身がガラリと変わるため variablesとsecretsは直接参照できない inputとして渡す必要あり secretsを渡したらログ出力時のマスクはしてくれる 環境変数のスコープはワークフローに準拠する ワークフロー側で定義した環境変数は参照できるし、アクション側で書き出した環境変数はワークフロー側からも参照可能 パーミッション定義できない ワークフロー側で制御するようにする つまり呼び出し側ワークフローでパーミッション定義を忘れると実行エラーが発生するので、どのようなパーミッションが必要かはREADMEなどに残しておくのがオススメ アクション設計プラクティス 認知負荷の低減 利用者はコードが読みたいのではなく、アクションを使いたいだけ なのでアクションの名前と概要はきちんとわかりやすいように書く（input/outputも） secrets.GITHUB_TOKENの取り方 アクションからsecretsは参照できないのでsecrets.GITHUB_TOKENは参照できないが、github.tokenで同じ値を参照できる スクリプトの切り出し 内部ロジックが大きくなってきたらshファイルとして別で切り出すと良い 切り出したshファイルは、GITHUB_ACTION_PATH環境変数で実行する必要がある run句に単純なshファイルへの相対パスを指定するだけでは実行できない 環境変数による暗黙的な依存の回避 ワークフローとアクションで相互に環境変数は参照できるが、必要な値はinputs/outputsで明示的に受け渡すようにするのが良い コードが追いづらくなるのと、意図せず壊れてしまうリスクがある ロググループ化の活用 まず大前提としてきちんとログを出力する（デバッグ効率が圧倒的に良くなるため） CompositeActionのログはステップごとに分割されないのでログを追うのが難しくなる なのでロググループ化を活用する アクションとNodeバージョン GitHubが提供する多くのアクションはJSで実装されている Nodeバージョンが上がるとアクションのメジャーバージョンが上がることが多い このバージョンアップ作業が地味に大変な作業\u0026hellip; 7章 クリーンなリポジトリの維持 リポジトリルール ブランチプロテクションルールを設定しよう コードオーナーを設定して全てのコードにオーナーシップを維持しよう 自動でコードオーナーにレビュー依頼が飛ぶ シークレットスキャンを導入して、秘匿情報混入を検出しよう コードやIssueの本文やコメントなどもチェックしてくれる GitHubが定期的にチェックする（つまり事後） プッシュプロテクションをEnableにすると、プッシュするタイミングでチェックが走る ドキュメント READMEは読み手のことを考える LICENSEは確認するようにする MITは、責任とらないけど自由に使ってねくらいのニュアンス コミュニティヘルスファイル CONTRIBUTING.md: コントリビューション方法のガイド（PRやIssueの出し方、コーディング規約） CODE_OF_CONDUCT.md: 行動規範 SECURITY.md: 脆弱性報告方法など 8章 Dependabotによる依存関係バージョンアップ ソフトウェアは何もしないと壊れるので、変更し続ける必要がある 依存関係の管理には、検知・把握・実装・テストという活動が必要 Dependabotには以下3つの依存関係の管理をサポートする機能がある Dependabot version updates: 最新バージョンへの自動アップデート Dependabot security updates: 脆弱性を含むバージョンの自動アップデート Dependabot alerts: 脆弱性が含まれるバージョンのアラート通知 ワークフローで実践 ブランチプロテクションルールを設定し、全てのステータスチェックを行ってからマージしたい場合 GitHub CLIのmergeコマンドに--autoをつけることで、全ワークフローの成功状態になった後に、自動でマージしてくれる Dependabotが起動したワークフローは通常のsecretsへのアクセスができないので、Dependabot用のsecretsを登録する必要があるので注意 厄介なのが何もエラーが出ず、空文字で処理が進むので、頭の片隅に入れておくと良い dependabot/fetch-metadataアクションを活用する Dependabotが起動するワークフローで使用可能で、バージョンアップ・依存関係の種類、パッケージエコシステムを取得できる 有効活用の例 パッチバージョンの場合は自動マージ 開発環境向けの変更は自動マージ GHA向けの変更は自動マージ このように少しでも手動対応量を減らすことで、少しでも楽をする 9章 GitHub Releasesによるリリース自動化 バージョニング いつどんな変更が行われたのかをバージョンを併記してユーザーに知らせることができる トラブル時はバージョン情報をやり取りすることで関係者間の意思疎通が楽になる 開発者としてもどのバージョンで不具合が発生したかがわかれば、修正が楽になる セマンティックバージョニング メジャー.マイナー.パッチという構成のバージョニング方式 順序性だけでなく、後方互換性に関心を寄せているのが特徴 完璧ではない（後方互換性が個人の考え方やスキルに依存する点）が、有名であること視認性が高いことで、選択としては無難である Gitタグの保護はやっておこう（ブランチ保護と同じような感じ） ReleasesがGitタグに依存しており、そのGitタグが削除された場合、リリースノートは下書き状態となってしまうため 10章 GitHub Packagesによるパッケージ管理 パッケージエコシステム npmやMavenなどの言語パッケージ、HomebrewなどのOSパッケージ、Dockerなどのコンテナイメージもパッケージの一種 ソフトウェアのインストール・管理（依存関係の把握、ライブラリが足りなければ自動でダウンロード、新しいバージョンの検知、最新版へのアップデート等）を容易にする 提供者はパッケージマネージャークライアントを通じてパッケージを作成・登録＆メタデータを提供し、利用者はパッケージマネージャークライアントを通じてパッケージを検索・取得・更新＆依存関係を解決する（そしてこの両者をつなぐのがパッケージレジストリ） ContainerRegistryの話がメインで、使いそうもないのでスキップ 11章 OpenID Connectによるセキュアなクラウド連携 クラウドプロバイダのクレデンシャル クラウドプロバイダは誰がアクセスしようとしているかを「認証」によって判断する クレデンシャルは、その認証に利用するもので、ユーザーIDとパスワードもその一種 認証する側が、アクセスキーやAPIキーといった呼び名のランダム文字列を発行し、それをクレデンシャルとして利用する プログラムがリクエスト時にそのクレデンシャルを一緒に送信することで、認証と認証情報が正しければ正常レスポンスを受け取れるという仕組み 静的クレデンシャル 長期にわたって変更しないパスワードのようなクレデンシャルを静的クレデンシャルという 静的クレデンシャルは長命という欠点があり、漏洩した場合の被害が拡大しやすい 一時クレデンシャル こちらは必要なタイミングで都度払い出すので短命 ローテーション作業もないので運用も楽 OpenID Connectというプロトコルによって実現する クラウド連携のアンチパターン 静的クレデンシャルは使用してはいけない かつてはそれしか選択肢がなかったので、記事を探すときは要注意 OpenID Connect(OIDC) これは複数の異なるドメインで認証結果を共有し、協調してサービスを提供するオープンなプロトコル（アイデンティ連携を実現する） OAuth2.0を拡張する形で設計されている 利点として、GitHub上で静的クレデンシャルの管理が不要になる(一時クレデンシャルを取得するため)＋認証時にアクセス元を細かく制限できる（GHAの場合特定リポジトリのみに許可できる） 一時クレデンシャルの取得フロー ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider) OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ) 一時クレデンシャルで操作 大抵の処理は隠蔽されており、私たちは行う作業は以下の2つのみ（準備に若干手間はかかるがメリットが大きい） クラウドプロバイダ側でOIDCに必要なコンポーネントを作成する ワークフローへクラウドプロバイダの認証アクションを組み込む OIDC TrustとCloud Roles クラウドプロバイダで準備するコンポーネントは以下の2つ OIDC Trust: クラウドプロバイダが信頼するOIDC Providerを設定(GitHub OIDC Provider) OIDCトークンで一時クレデンシャルを取得できる理由は、クラウドプロバイダがOIDC Providerを信頼しているため（OIDC Trust） OIDCトークンはJWT形式で、GitHub OIDC Providerの公開鍵を使って署名等の検証が行われる Cloud Roles: 一時クレデンシャルのアクセス先とアクセス元を制御 一時クレデンシャルの「アクセス先」を管理する AWSでいうIAMロールのこと 認証アクション 各クラウドプロバイダは公式で認証アクションを提供しているので、ワークフローからはそのアクションを呼び出すだけで、OIDCが扱える 検証作業のリスクヘッジ プライベートリポジトリで試す 認証パラメータ(AWSアカウントIDやIAMロール名)はSecretsで管理する これらクレデンシャルではないものの、ログ出力時にマスクされるので、謝ってパブリックリポジトリでワークフローを実行しても、第三者へ余計な情報が漏れない AWSにおけるOIDC利用準備と連携 以下の2つを作成する OIDC Provider AWSがGitHub OIDC Providerを信頼するように設定 IAMロール 一時クレデンシャルのアクセス先とアクセス元を制御する GHAワークフロー側での設定作業 Secrets登録 AWSアカウントID IAMロール名 ワークフロー実装 permissions id-token: writeの設定が必要 GitHub OIDC ProviderからOIDCトークン取得に必要 aws-actions/configure-aws-credentialsを利用 ロールARNとセッション名、デフォルトリージョンをパラメータとして指定する セッション名は、トレーザビリティを目的に、AssumeRole APIに渡すパラメータ名であり、CloudTrailのセッション名として記録される 「誰が・いつ・どのジョブでこのセッションを作ったか分かる」ような情報を含めると便利 例：\u0026quot;${{ github.workflow }}-${{ github.run_id }}-${{ github.actor }}\u0026quot; CloudRolesのセキュアな運用 他のリポジトリからアクセスできないことを確認しておく CloudRolesは目的ごとに分離する（必要最小限の権限だけ） クラウドプロバイダの設定作業にIaCを導入する 12章 コンテナオーケストレーションのデプロイメント デプロイ自動化の流れ コンテナビルドアクション：コンテナイメージのビルド＆プッシュ コンテナデプロイアクション：タスク定義の書き換えとサービスの更新 本番環境へのデプロイはルールを制限したい Deployment branches and tagsを設定する Environmentsからブランチ名パターンを登録することでパターン外のブランチでワークフローを起動できなくなる Required Reviewers ワークフローの起動に承認を必須とする デプロイメント設計 デプロイの設計では「ユーザー影響」と「ロールバック」の観点に着目する ローリングアップデート ECSのデプロイ方式 新しいバージョンへ少しずつ置き換える 無停止 ロールバック ローリングアップデートの場合は特別な仕組みはないので、リバートコミットを追加し、再デプロイする（あまり速くない） 人間が切り戻しを検知・判断するので、別途監視の仕組みが必要となる 第14章 GitHub Actionsの高度な使い方 Reusable Workflows アクションは比較的小さな処理をカプセル化するのに対し、Reusable Workflowsはワークフロー全体を丸ごとカプセル化する パーミッション パーミッション定義を省略した場合は呼び出し側ワークフローのパーミッションを暗黙的に継承する 呼び出し側より厳しくできるが、緩めることはできない なので、呼び出し側ではジョブレベルでパーミッションを定義すると良い（Reusable Workflowsの権限が最小限になるため＋ドキュメンテーションとなり可読性が向上する） コンテキスト 呼び出し側ワークフローのコンテキストを直接参照できる ただしReusable Workflowsが制御できないgithub.eventプロパティを参照すると再利用性は低下するので注意が必要 Secrets 呼び出し側ワークフローのコンテキストを直接参照できない 入力パラメータ経由で渡す or 呼び出し側でsecrets: inheritを指定するとまとめて継承可能 暗黙的な継承となりコードが追いづらくなるので個別で入力パラメータとして渡すのが良い 環境変数 こちらも参照できないので入力パラメータ経由で渡す fromJSON関数 動的なワークフロー定義 事前にマトリクスを生成できない場合、fromJSON()をmatrixに指定することで動的にマトリクスを生成できる 文字列の型変換 ワークフロー構文の環境変数はstring型として扱われてしまう その際string型の文字列をnumber型やboolean型に変換できる エラーハンドリング Continue on Error デフォルトではエラーが発生するとその時点でワークフローが停止する continue-on-error: trueを指定すると、エラーを握りつぶし、次の処理に進む これを指定すると、途中でエラーが発生しても、ワークフロー自体は正常終了扱いされる ログを見ない限りエラーには気づけないので、リカバリー不要な場合のみ使用する マトリックスのフェイルファスト マトリックスを使うと複数のジョブが並列に起動する 途中でエラーが発生した場合、他のジョブが止まる fail-fast: falseを指定することで他のジョブを継続可能とできる コンテキストによるフロー制御 終了状態を取得できるコンテキスト stepsコンテキスト：ステップの終了状態を保持 outcomeプロパティはContinue on Error適用前の終了状態（つまり生情報） conclusionプロパティはContinue on Error適用後の終了状態 needsコンテキスト：（依存している）ジョブの終了状態を保持 resultプロパティのみ コンテキストとステータスチェック関数の併用 「前のステップが失敗したら」という条件式を書きたい場合 if: ${{ failure() \u0026amp;\u0026amp; steps.stepName.outcome == 'failure' }}とする必要がある このようにステータスチェック関数とコンテキスト参照を併用する必要がある理由として、failure()が記述されていない場合、暗黙的にsuccess()関数が存在すると解釈されるため 15章 GitHub Actionsのセキュリティ この章では「ソフトウェアサプライチェーン」に着目する ソフトウェアサプライチェーンとは、コード書いてから実行環境へリリースまでに含まれる一連のアクティビティを意味する GHAはさまざまなシステムと連携するため、強力な権限が集中するため、悪意ある人にとってはとても魅力な攻撃対象になる セキュリティのCIA CIAとは、機密性・完全性・可用性のこと CIAの観点から、守るべき資産はコード・クレデンシャル・アーティファクトとなる 闇雲に対策するのではなく、利便性とのトレードオフとなる セキュリティの設計原則 脅威を完全に排除することは難しいので、脅威の軽減を目標とする アタックサーフェス＝攻撃される恐れのある場所を小さくする シンプルな設計を意識する（複雑な設計では意図しないこれ↑を生みやすいので） 複数のセキュリティレイヤを用意して、多層防御にする 最小権限 攻撃されても被害を小さくできる 一時クレデンシャルのような権限の行使に時間の制約があるようなものも有効だと思われる Githubのサービス特性 上記の設計原則を踏まえて考えていく GitHubはデフォルトの設定は利便性重視なので注意する コードをプッシュできる人はワークフローの実行ができるという仕様を理解する 悪意ある人もコントリビューション可能であることを認識する サードパーティアクション サードパーティのアクションがリポジトリのコードを参照できるかはパーミションによるが、ほとんどのワークフローではコードにチェックアウトするので、大半のアクションはコードを参照できる サードパーティアクション導入時は、そのサードパーティを信頼するかを意識的に決断するようにする 本当に信頼して良いかを考えるクセをつけるのが重要 リポジトリ設定で利用制限も可能 呼び出し時にコミットハッシュによる固定を行えば、アクションを不変リソースとして扱える ハッシュ指定だけでは分かりづらいので、コメントでバージョン情報を併記しておくと分かりやすい 筆者の考えとしては「ある程度の車輪の再発明は仕方ない」それくらいサードパーティアクションの使用は慎重になるべき スクリプトインジェクション 外からやってくるデータ（例：PRのタイトル）に悪意あるスクリプトが仕込まれていた場合、それがワークフローの中で読み込まれてスクリプトとして実行されてしまうリスクがある 対策として、 中間環境変数による無害化 env: PR_TITLE: ${{ github.event.pull_request.title }}というような形でスクリプトインジェクションを防げる どのプロパティが危険かを正確に判断するのは困難なので、コンテキストは常に中間環境変数で参照するようにするのが確実で楽 ShellCheckによる静的解析 Github-Hosted Runnerには最初からインストールされている actionlintは内部的にShellCheckを実行していて、yamlに直接書いたスクリプトもチェックしてくれる 最小権限のパーミッション パーミッションはpermissionキーで設定可能 省略可能で、省略した場合はコード参照が許可される 明示的な記述を習慣化することで、自然とパーミッションを意識するようになる 具体的には、 ワークフローレベルでのパーミッション無効化(permissions: {})の設定を入れることで、コード参照すら明示的な許可が必要になる 各ジョブへ都度、必要なパーミッションを定義する 面倒に見えるが、やってみると慣れるのは早い ジョブ分割によるパーミッションの分離 パーミッションのスコープはいくつかあるが、特に注意すべきなのが以下の4つ contents: 改竄されたコードをプッシュされるリスク packages: 悪意あるパッケージをパブリッシュされるリスク actions: 別のワークフローを意図せず起動されるリスク id-token: OIDCでクラウドプロバイダにアクセスされるリスク これらのパーミッションを複数扱う場合はジョブの分割を検討すると良い パーミッションをジョブ単位で記述すれば、ジョブがセキュリティ境界となる シークレットマネジメント まずはクレデンシャルの把握をすべき 最小権限・一時クレデンシャルを優先・定期的なローテーション OpenID Connectハードニング OpenID Connectを深掘りするパート (再掲)一時クレデンシャルの取得フロー ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider) OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ) 一時クレデンシャルで操作 IDトークン 上記の1のOIDCトークンと呼んでいるものはOIDCの世界ではIDトークンと呼ぶ これには主体に認証情報を含んでおり、リポジトリやワークフローの情報が含まれている これらの属性情報を受け取ったクラウドプロバイダ側で検証し、アクセス可否を判断している IDトークンの実体は、JWTである ヘッダ・ペイロード・署名をピリオド区切りでBase64URLエンコードしたもの ペイロードのデータ構造は決まっており、JSONの各フィールドはクレームと呼ぶ IDトークンにはいくつかの必須クレームがあり、この必須クレームがセキュリティ上重要となる IDトークンの検証フロー ワークフローはGitHub OIDC Providerから取得したIDトークンをクラウドプロバイダに渡す クラウドプロバイダはIDトークンの署名を検証し、JWTクレームを検証する この検証に成功したら、一時クレデンシャルをワークフローに返送する IDトークンの署名検証 本当にGitHub OIDC Providerが発行したIDトークンなのか確認する 署名の検証には、GitHub OIDC Providerの公開鍵を探し出す必要がある どこを探すかというと、OIDC Trust(AWSの場合はOpenID Connect Provider)にGitHub OIDC ProviderのURLを設定していて、このURLが公開鍵の検索に使用される（https://token.actions.githubusercontent.com） 注意点として、上記のURLは全アカウントで共通のため、アカウントやリポジトリの識別ができない（GitHubが生成したという内容しか検証できない） そこでJWTクレーム検証でその部分を補う形で検証する IDトークンのJWTクレーム検証 IDトークンの署名だけではGitHub利用者が誰でもアクセスできてしまうため、JWTクレームでも検証を行う JWTクレーム検証はクラウドプロバイダによって異なるが、AWSではAssumeRoleポリシーのCondition定義に基づいて検証を行う subクレーム もっとも重要な検証対象となる 認証された主体の識別子が格納される（一般的にはユーザーIDなど） GitHub Actionsでは少し毛色が異なり、ワークフローの属性情報を連結した値が入る（アカウント名やリポジトリ名など） ワークフローの実行方法によって値が異なるが、repo:/:のような文字列はどの方法でも含まれる なのでアカウント名やリポジトリ名が正しいかの判断は可能 GitHubのカスタムクレーム IDトークンは拡張が認めらていて、任意のカスタムクレームを追加可能 クラウドプロバイダによってサポート状況が異なっているので注意（AWSはサポートしていない） クラウドプロバイダのJWTクレーム検証設定 AssumeRoleポリシーのConditionに以下のように記述する \u0026quot;token.actions.githubusercontent.com:sub\u0026quot;: \u0026quot;repo:\u0026lt;OWNER\u0026gt;/\u0026lt;REPO\u0026gt;:*\u0026quot; 左辺のキーはsubクレームを指している 他の値もsubクレームで検証するとセキュリティがより強固になる Environmentsの検証 subクレームに含まれるEnvironmentsの値を検証することで、商用環境にアクセスできるのはレビュー済みのワークフローのみとしたいといった制御が可能 JWTクレームの検証はOpenID Connectのキモであり、特にsubクレームは重要となる 16章 セキュリティのシフトレフト セキュリティは後回しにしがちだが早めに取り組むのが良い戦略 これがシフトレフトという考え方（痛い目に遭うくらいなら早めに対処しよう） 依存関係の脆弱性スキャン 最新に保ち続けられるならそれで十分だけど現実はそうもいかない そこで活用したいのが依存関係の脆弱性を検出するサービス Dependabot Alerts 依存関係の脆弱性を発見するとアラートを送信する 「新たなコードのプッシュでDependency Graphが更新された時（例えばpackage.jsonなどのファイルが更新された時と同意かな？）」と「脆弱性データベースであるGitHub Advisory Databaseに脆弱性が登録された時」のタイミングでリポジトリをチェックしてくれる Dependabot security updates Alertsは情報提供で、これはプルリクエスト作成まで行ってくれるサービス 「security updates」は脆弱性のパッチを当てたバージョンへあげるもの（「version updates」の方は常に最新バージョンにあげるという違いがある） 設定ファイルについて .github/dependabot.ymlは、security updatesとversion updatesで共有される 共有されるということは除外ルールを書いたらどちらでも検知されない なので防御策として、Alertsを合わせて有効化しておくと良い（Alertsは設定ファイルに依存しない）そうすれば検出漏れを最小限にできる シークレットスキャン GitHubのシークレットスキャン機能は経済的理由で導入が困難な場合もある SecretlintというDockerで動かせるAWSやGitHubなどの主要サービスのクレデンシャルを検出できる これをGitHubActionsで動かすと尚良い その際、検出された情報がログ出力されないように注意（--maskSecretsオプションで設定可能） 途中からシークレットスキャンを導入する場合は全ヒストリーをスキャンするGitleaksというツールがある これもDockerで動かせる git push前にスキャンするのがベター .git/hooks/pre-commitファイルへシークレットスキャンコマンドを組み込むとコミット時にスキャンが実行あsれる 個々人で設定可能が必要であり、ストレスに感じる人もいるため、実際にやるかどうかは個人の判断に委ねると良い アプリケーションスキャン Static Application Security Testing(SAST) コードスキャンしてセキュリティ問題を検出する（静的解析） Goだとsecurego/gosec: Go security checkerがそれみたい コンテナイメージの脆弱性スキャン Trivyというツール 他にはコンテナレジストリでスキャン実施できる Infrastructure as Codeセキュリティ IaCで作業ミスは抑制できるが、セキュリティミスは防げない そしてパッと見で正しく動作しているように見えるので意外と発見が難しい セキュリティ設定ミスの防止 ここでもTrivyが活躍する 万事解決とまでいかないが、優れた出発点となる Policy as Code Conftestというツールが使える ポリシールールを設定ファイルに記述し、それを検証してくれる これもDockerで動かせるのでワークフローに簡単に実行できる 選択肢の1つとして持っておくと良い 継続的なセキュリティの改善 誤検出と検出漏れはどうしても発生する（バランス・トレードオフ） 誤検出は想像異常にストレスが大きい またツールを導入しすぎるたりして検出される問題が多すぎるとアラート疲れも発生する 時々立ち返って運用を見返すのが良い 18章 継続的デリバリーの実践 組織パフォーマンスを研究しているGoogleのDORAというチーム曰く「ソフトウェアデリバリーパフォーマンスは組織パフォーマンスと高い相関がある」と学術的な方法で示したこと DORAの研究では「スピードが速い組織ほど品質も高い」を提唱している 加えて、個人の幸福や組織文化にも寄与すると考えられている この章では「継続的デリバリー」うまく実践するために、何ができるかを紹介していく バージョン管理戦略 継続的デリバリーは適切なバージョン管理から始まる 大原則は「ソフトウェアの実行に必要なあらゆるものをバージョン管理する」 ソースコードだけではなく、テスト・ビルド・デプロイ・データベースマイグレーション・運用などのスクリプト・インフラ設定もバージョン管理の対象（つまりクレデンシャル以外） 1日に1回はデフォルトブランチにマージする短命なブランチ運用＝トランクベース開発をすることで、コード変更量が小さいのでレビューしやすかったりコンフリクトが発生しづらかったりする 実装途中の機能を一時的に無効化したい場合は「フィーチャートグル」を使えば良い 詳細: 機能トグル（別名機能フラグ） テスト戦略 CDの品質改善では、4章で説明した自動テストが重要な役割を担う それ以外の異なる観点を提供するものとして、以下の2つがある 探索的テスト 自動化できないテストのこと テストの目的は「調査」と「検証」がある 自動テストは記事の問題を「検証「することで、探索的テストは人間が手動で未知の問題を「調査」すること（目的が異なる） Testing in Production リリース後も本番環境でテストする A/Bテストやシンセティックテストなど リリース戦略 恐怖の克服 いくら自動化しても経験しないと恐怖は薄れない 自分の手でリリースすることが大切 ロールバック ロールバックも全員が慣れておく 頻度が少ないためにやり方を知らない人がいるので手順を周知し、平時にロールバックの練習をしておく デプロイとリリースの分離 分離していない場合にデプロイに問題があった時は全ユーザーに影響がある 分離する方法として、デプロイ後にユーザートラフィックを少しずつ新しい環境に流す「カナリアリリース」がある データベースの変更管理 手作業でデータベースコマンドを実行してはダメ マイグレーションスクリプト経由で実行すると、ヒューマンエラーも発生しない ロールバック用のスクリプトも用意するようにする IaCの変更管理 IaCはソフトウェアとライフサイクルが異なるため、固有の考慮点が存在する ツールにドライ欄があるならそれを使用する 毎回手動実行は大変なので、プルリクエスト作成時に自動で実行し、それをコメントに貼り付ける 「本番環境への適用はデフォルトブランチにマージした時のみ」という規律を設けるべき IaCはローカルからの変更は事故が起きやすいので止める 実行環境は強力な権限が必要なので、絶対消されてはいけないDB等のリソース削除を禁止したり、権限昇格なIAM操作を禁止すべき 構成ドリフト（実態とコードの差分がある状態）は定期的にドライランを実行して通知させよう 疎結合なアーキテクチャ 疎結合はCDがとても実践しやすい テストやデプロイの容易性 ",
  "keywords": [
    
  ],
  "articleBody": "1章 ソフトウェア開発とGitHub 継続的インテグレーションとは？ コードの変更を頻繁にコードベースに統合し、正しく動作するかを繰り返し検証する 統合頻度が上がるとコンフリクトが減る 繰り返して検証を行うとバグを発見すれば素早く修正できる ソフトウェアが安定して動けば、ユーザーの満足度も向上する 継続的デリバリーとは？ リリースしないとユーザーには価値を提供できない いつでも安全にリリースできる状態を保ち、ソフトウェアを繰り返し改善する CIとCDは同列の概念に見えるが、CIはCDに包含される 2章 GitHubActionsの基礎概念 実行時エラー コマンドの終了ステータスが0ならば成功、0以外ならば失敗見なされる なので、ワークフローでは終了ステータスを適切に返すことが大事 手動実行 on: workflow_dispatchで手動実行できる inputとして、列挙型となるchoice型の指定が可能 定期実行 on: schedule: cron()で定期実行できる 時刻はUTCなので注意 実行環境 GitHub-Hosted Runners GitHubが提供するマネージドな実行環境 LargerRunnersというマシンスペック向上したものも利用可能（有料） サポートOSとしては、Linux(Ubuntu)/Windows/macOSがある よく使用するDocker,Node.js,npmなどは既にインストールされている ただし、バージョン固定はできないので、バージョン固定で使用したい場合は、ワークフローの中で自分でインストールする必要ある エフェメラルという特性 ジョブ終了時に破棄されるので、毎回クリーンな環境でジョブを実行できる この特性は一貫性向上に貢献している Self-Hosted Runners 利用者が実行環境を用意する MarketPlace 再利用できるワークフローが公開されている 著名な組織にはVerifiedCreatorsマークがついているので、そういうのを利用するとセキュリティ不安が低減する（100%安全とは言い切れないが） 料金 パブリックリポジトリなら無料 プライベートは使用時間とストレージ使用量で計算される 月毎に無料枠があり、それを超えると課金が発生するが、支払い設定をしていない場合は実行できなくなるだけ（なので安心できる） 使用時間は、実行時間×ランナーごとの料率で計算される 料率はubuntuが1,Windowsが2,macOSが10なので、なるべくUbuntuを利用するのがオススメ 3章 ワークフロー構文の基礎 環境変数 単一のワークフローで使用できる envで定義する ワークフロー・ジョブ・ステップで定義可能 定義した場所で、環境変数のスコープが異なる 中間環境変数 コンテキスト(github.base_refのように参照できるもの)は、各ジョブ(ステップ)の中で直接スクリプトに埋め込むのはNG 理由: スクリプトインジェクションにリスクがあるため envの中で一度変数展開し、スクリプト内ではダブルクオテーションで囲むことが推奨される 変数展開することでメモリ上で保存されるので、スクリプト生成プロセスには生成プロセスには相互作用しないため GHAに限らず、シェルスクリプト全体で言えること Variables 複数のワークフローで使用できる varsコンテキストでアクセスする こちらも参照時は中間環境変数経由(envの中で環境変数に展開してから)が推奨 Secrets 以下の特徴がある 登録した値は暗号化され、GitHub内で安全に管理される ログ出力時はマスクされる 登録後の値確認は不可となる ログマスクのアルゴリズムは完全一致のみ、1文字スペースを加えたりするだけで出力されてしまうので、ログマスクは当てにしないようにする そもそもsecretsの値はログ出力しないようにしましょう expressions(式) ${ example }のような形で定義 リテラルや演算子などが使用可能 比較演算の際、GHAでは異なる型の値を比較すると、勝手に値が変換されるので注意 オブジェクトフィルター 配列やオブジェクトから指定したプロパティを抜き出し、配列を生成する ${{ github.event.*.html_url }}のような形で*を使用する 条件分岐(if) ifの少し面白い使い方として、最初のジョブへ条件分岐を定義し、特定の条件でスキップするようにすると、ワークフロー自体の実行がスキップできる 使用時間もゼロになり、コスト削減につながる ネーミング 実行ログが見やすくなるのでジョブ名やステップ名はきちんと書く run-nameは、nameとは異なり、コンテキストが利用できる run-name: Run by ${{ github.actor }} ステップ間のデータ共有 2つのやり方がある GITHUB_OUTPUT環境変数 定義: echo “=” » “${GITHUB_OUTPUT}” 参照: ${{ steps..outputs. }} 参照方法を見ると分かる通り、ステップ間の依存関係が明白 GITHUB_ENV環境変数 定義: echo “=” » “${GITHUB_ENV}” 参照: ${GITHUB_ENV} ステップIDの指定が不要なので、どのステップで環境変数を設定したかを意識する必要ない 異なる複数のステップで、同じ値を参照する場合に使える（ただしステップ間の依存がわかりづらくなる） これで定義したものは、事実上グローバル変数なので、ワークフローが大きくなるとバグの原因になるので注意が必要 特にこだわりなければ、GITHUB_OUTPUTを使用する GitHub APIの実行 GitHubHostedRunnerの場合は、GitHub CLIがインストールされているのでそれを使うと良い API(CLI)の実行にはトークンが必要 GHAには簡単に使えるクレデンシャルが利用できる ワークフロー開始時に自動生成、終了すると自動的に破棄 有効期限は、ワークフロー実行中のみなので、万が一漏れても影響範囲は限定的 取得方法は、${{ secrets.GITHUB_TOKEN }} もしくは ${{ github.token }} どちらでも良いので、どちらかに統一するのが良い トークンの指定は、GITHUB_TOKENもしくはGH_TOKENという名前の環境変数をセットするだけで、自動で読み込んでくれる パーミッション ジョブレベルとワークフローレベルで指定可能 スコープ(contents, pull-requests等)とそれに対するアクション(read, write, none)を設定する ただしワークフローを実行しているリポジトリ以外のアクセスは許可されない パーミッションを明示的に定義していない場合、自動でソースコードの読み込み許可はされる 一方、明示的な定義をする場合は、この暗黙的な挙動は無視されるので注意 パーミッション周りのトラブルシューティング ワークフロー実行ログのSet up jobの中に、GITHUB_TOKEN Permissionsがあるので、そこで実行時のパーミッションを確認できる スターターワークフロー GitHubリポジトリのActionsからNew Workflowを選択すると、ワークフローのコレクションが並んでいるので、参考にできそう https://github.com/actions/starter-workflows?tab=readme-ov-file 4章 継続的インテグレーションの実践 大体以下の流れでワークフローを構成する checkout setup(ex: actions/setup-go) リントやテストの実行 フィルター pathsと他の条件を指定するとAND条件になる 静的解析 actionlintは、GHAワークフローの静的解析を行ってくれるので便利 使用時間の削減（どのワークフローでも有用な設定） ジョブ・ステップレベルのタイムアウト設定 どのワークフローにも設定するようにする（GHAのデフォルト値は360分と大変長いため） 自動キャンセル（新しいコミットが追加されたら、古いコミットで動作しているワークフローを自動でキャンセルする） シェル ステップごとに起動シェルをshellキーで設定可能 Ubuntuの場合、省略時はbashだが、shellキーの指定有無で起動オプションが変更される 全ステップに書くのは面倒なので、ワークフローのトップレベルにデフォルト設定(defaults句)するのが良い デフォルトシェルにはデメリットは存在しないので、全てのワークフローに機械的に入れるのがオススメ Concurrency ワークフローはイベント駆動なので、イベントが発生すると起動、さらにまたイベントが発生すると起動することになる 起動制御できる仕組みとして、Concurrencyがある concurrency: とすることで、同一グループの多重制御が設定できる さらにcancel-in-progress: trueで自動キャンセルの設定も可能（プルリクエストで最新ではないコミットのCIとかに有効） CIの黄金律 「クリーンに保つ」 全てのステータスチェックが成功した時だけマージできるようにする 「高速に実行する」 CIの実行が遅いと、待ち時間に他の作業→CIで失敗したらその対応する時にコンテキストスイッチが必要になる 時間の無駄だし、開発効率の低下につながる CIのスピードは大切で、理想は5分以内、遅くとも10分以内に終わらせるように 「ノイズを減らす」 CIからのフィードバックで価値ある情報の「シグナル」とそうではない「ノイズ」 判断基準としては、その情報を受け取り、これは気にしなくて良いやと流したならそれがノイズ ノイズがあると、シグナルもスルーされてしまうので、ノイズは意識的に減らす テスト 単体テストの割合を増やす フレーキーテストを放置しない（閾値を超えるとテスト全体が信頼されなくなる） Googleソフトウェアエンジニアリングでは閾値は1％とされている 遅いテストは実行タイミングをPRマージの時に限定するなど工夫する 使用しているテストツールで以下のような機能を利用する 部分実行 並列実行 シャッフル実行（テスト間の隠れた依存関係も洗い出せる） カテゴリ実行（スローテスト用のカテゴリを作ってそれだけ実行しないみたいな） 静的解析 不要な警告は無視するのではなく抑止する ignoreやsuppressのキーワードで検索する 抑止理由はコメントやコミットメッセージに残しておく 第5章 運用しやすいワークフロー設計 長期運用で役立つプラクティスの紹介 ロギング ワークフローの再実行時の「Enable debug logging」を有効にすると、デバッグログが確認できる デバッグログには以下がある ステップデバッグログ ステップのログの詳細（ステップステータスや各種コンテキスト）をトレースできる SecretsまたはVariablesに「ACTIONS_STEP_DEBUG」をtrueで登録しておくことで、これらの値も確認できる 他は内部実装者向けだったりするので、割愛 Bashのトレーシングオプション デバッグログよりシンプルで、どんなコマンドが実行され、結果はなんだったのかを知りたいケースで使用する Bashのトレーシングオプションは、set -xを実行するだけなので、手軽だが強力 全てのコマンドが実行前に表示されるようになり、どのコマンドがどのような引数で実行されているかを確認できる ログのグルーピング、手動マスク等もある レポーティング アノテーション echo \"::error::This is error\"みたいな形で書くとジョブページにみやすい形で表示 ジョブサマリー シンプルなテキストならアノテーションで十分だが、複数行表示したい場合等はマークダウン形式で出力される${GITHUB_STEP_SUMMARY}が便利 複数ジョブの実行制御 デフォルトでは複数のジョブを実行すると並列実行される 並列実行は、全体の実行時間を短縮できる もしジョブの実行時間の長さに問題がある場合は、ジョブを細かく分割し、並列実行させるというアプローチもある 逐次実行させたい場合は、needsを使用する ジョブ間のデータ共有 $GITHUB_OUTPUT環境変数に出力し、stepsコンテキスト経由で受け渡す 受け取る側は、needsコンテキストを経由で受け取る Environments 環境差分をパラメータ化でき、VariablesとSecretsがある 参照方法は、通常のVariablesとSecretsと同一(vars.xxx, secrets.xxx) よくあるのはワークフローの入力値で環境名をもらい、それをenvironmentsにセットし、同じ変数名(環境ごとに値が異なる)を参照 キャッシュ actions/cachedでGHA上にキャッシュとその利用が可能 実行時のパラメータとして key: キャッシュキー。生成と保存に利用する。 path: キャッシュ対象となるディレクトリ/ファイルパス。 restore-keys: キャッシュミス時のリストアキーを複数指定する。 キャッシュ復元時に挙動 ①keyキーに定義したキャッシュキーと厳密に一致するキャッシュを探す ②リストアキーの定義順に、プレフィックスが一致するキャッシュを探す リストアキーは省力可能であり、これはパッケージマネージャーと併用するときに威力を発揮する 大半のパッケージマネージャーはキャッシュにないファイルだけダウンロードするように振る舞う キャッシュは、7日以上アクセスされないと自動削除される ブラウザからリポジトリ画面で手動削除も可能 合計サイズは、リポジトリで10GBまで キャッシュキーの設計 プラットフォームごとに異なるキャッシュを利用するようにする キャッシュは最低でもOSごとに分離する 他にもCPUアーキテクチャや言語バージョン、パッケージマネージャーもキャッシュキーの候補 例えば、OSとCPUアーキテクチャでキャッシュを分離するなら: key: example-${{ runner.os }}-${{ runner.arch }} 依存関係を更新した時だけキャッシュを変更するようにする package-lock.jsonのようなロックファイルがある場合、そのファイルハッシュをハッシュキーに指定する hashfiles('**/package-lock.json) ロックファイルが更新されない限り、キャッシュが利用されるようになる アーティファクト ワークフロー内で生成したファイルをアーティファクトと呼ぶ アーティファクトはGitHubストレージへ一時的に保存ができる ビルドしたバイナリやメトリクスデータの保存に利用できる アーティファクトの保存はデフォルト90日で、保存時にパラメータ(retention-days)で指定可能 プライベートリポジトリだとストレージ容量は課金対象のため、保存期間を短くすると節約できる 6章 アクションによるモジュール化 ここでいう「アクションによるモジュール化」とは、ワークフローにおける小さな部品（ステップやコマンドの小さな単位）をモジュール化すること ランナーは、呼び出し元ワークフローに依存する アクションの実装方式は以下の3つがある Composite: YAMLで定義 JavaScript: JSで定義 Docker Container: Dockerで動かす(ビルド・起動するDockerfileを指定) これらはrunsのusingキーで指定する(ex: using: composite) アクションのロケーションは「ローカル」と「リモート」がある リモート: uses: actions/checkout@v4 URLと連動する @v4の部分はGitのタグ（ブランチやコミットハッシュも指定可能） ローカル: uses: ./.github/actions/hello/ 先頭部分が.であることが目印 ルートディレクトリを起点にパスを記述する CompositeAction メタデータファイル(action.yml)が必要 メタデータ構文のワークフロー構文との違いや注意点 シェル指定が必須 githubコンテキストのeventプロパティの使用は避ける アクションはトリガー指定ができないので、呼び出し元のワークフローによりeventの中身がガラリと変わるため variablesとsecretsは直接参照できない inputとして渡す必要あり secretsを渡したらログ出力時のマスクはしてくれる 環境変数のスコープはワークフローに準拠する ワークフロー側で定義した環境変数は参照できるし、アクション側で書き出した環境変数はワークフロー側からも参照可能 パーミッション定義できない ワークフロー側で制御するようにする つまり呼び出し側ワークフローでパーミッション定義を忘れると実行エラーが発生するので、どのようなパーミッションが必要かはREADMEなどに残しておくのがオススメ アクション設計プラクティス 認知負荷の低減 利用者はコードが読みたいのではなく、アクションを使いたいだけ なのでアクションの名前と概要はきちんとわかりやすいように書く（input/outputも） secrets.GITHUB_TOKENの取り方 アクションからsecretsは参照できないのでsecrets.GITHUB_TOKENは参照できないが、github.tokenで同じ値を参照できる スクリプトの切り出し 内部ロジックが大きくなってきたらshファイルとして別で切り出すと良い 切り出したshファイルは、GITHUB_ACTION_PATH環境変数で実行する必要がある run句に単純なshファイルへの相対パスを指定するだけでは実行できない 環境変数による暗黙的な依存の回避 ワークフローとアクションで相互に環境変数は参照できるが、必要な値はinputs/outputsで明示的に受け渡すようにするのが良い コードが追いづらくなるのと、意図せず壊れてしまうリスクがある ロググループ化の活用 まず大前提としてきちんとログを出力する（デバッグ効率が圧倒的に良くなるため） CompositeActionのログはステップごとに分割されないのでログを追うのが難しくなる なのでロググループ化を活用する アクションとNodeバージョン GitHubが提供する多くのアクションはJSで実装されている Nodeバージョンが上がるとアクションのメジャーバージョンが上がることが多い このバージョンアップ作業が地味に大変な作業… 7章 クリーンなリポジトリの維持 リポジトリルール ブランチプロテクションルールを設定しよう コードオーナーを設定して全てのコードにオーナーシップを維持しよう 自動でコードオーナーにレビュー依頼が飛ぶ シークレットスキャンを導入して、秘匿情報混入を検出しよう コードやIssueの本文やコメントなどもチェックしてくれる GitHubが定期的にチェックする（つまり事後） プッシュプロテクションをEnableにすると、プッシュするタイミングでチェックが走る ドキュメント READMEは読み手のことを考える LICENSEは確認するようにする MITは、責任とらないけど自由に使ってねくらいのニュアンス コミュニティヘルスファイル CONTRIBUTING.md: コントリビューション方法のガイド（PRやIssueの出し方、コーディング規約） CODE_OF_CONDUCT.md: 行動規範 SECURITY.md: 脆弱性報告方法など 8章 Dependabotによる依存関係バージョンアップ ソフトウェアは何もしないと壊れるので、変更し続ける必要がある 依存関係の管理には、検知・把握・実装・テストという活動が必要 Dependabotには以下3つの依存関係の管理をサポートする機能がある Dependabot version updates: 最新バージョンへの自動アップデート Dependabot security updates: 脆弱性を含むバージョンの自動アップデート Dependabot alerts: 脆弱性が含まれるバージョンのアラート通知 ワークフローで実践 ブランチプロテクションルールを設定し、全てのステータスチェックを行ってからマージしたい場合 GitHub CLIのmergeコマンドに--autoをつけることで、全ワークフローの成功状態になった後に、自動でマージしてくれる Dependabotが起動したワークフローは通常のsecretsへのアクセスができないので、Dependabot用のsecretsを登録する必要があるので注意 厄介なのが何もエラーが出ず、空文字で処理が進むので、頭の片隅に入れておくと良い dependabot/fetch-metadataアクションを活用する Dependabotが起動するワークフローで使用可能で、バージョンアップ・依存関係の種類、パッケージエコシステムを取得できる 有効活用の例 パッチバージョンの場合は自動マージ 開発環境向けの変更は自動マージ GHA向けの変更は自動マージ このように少しでも手動対応量を減らすことで、少しでも楽をする 9章 GitHub Releasesによるリリース自動化 バージョニング いつどんな変更が行われたのかをバージョンを併記してユーザーに知らせることができる トラブル時はバージョン情報をやり取りすることで関係者間の意思疎通が楽になる 開発者としてもどのバージョンで不具合が発生したかがわかれば、修正が楽になる セマンティックバージョニング メジャー.マイナー.パッチという構成のバージョニング方式 順序性だけでなく、後方互換性に関心を寄せているのが特徴 完璧ではない（後方互換性が個人の考え方やスキルに依存する点）が、有名であること視認性が高いことで、選択としては無難である Gitタグの保護はやっておこう（ブランチ保護と同じような感じ） ReleasesがGitタグに依存しており、そのGitタグが削除された場合、リリースノートは下書き状態となってしまうため 10章 GitHub Packagesによるパッケージ管理 パッケージエコシステム npmやMavenなどの言語パッケージ、HomebrewなどのOSパッケージ、Dockerなどのコンテナイメージもパッケージの一種 ソフトウェアのインストール・管理（依存関係の把握、ライブラリが足りなければ自動でダウンロード、新しいバージョンの検知、最新版へのアップデート等）を容易にする 提供者はパッケージマネージャークライアントを通じてパッケージを作成・登録＆メタデータを提供し、利用者はパッケージマネージャークライアントを通じてパッケージを検索・取得・更新＆依存関係を解決する（そしてこの両者をつなぐのがパッケージレジストリ） ContainerRegistryの話がメインで、使いそうもないのでスキップ 11章 OpenID Connectによるセキュアなクラウド連携 クラウドプロバイダのクレデンシャル クラウドプロバイダは誰がアクセスしようとしているかを「認証」によって判断する クレデンシャルは、その認証に利用するもので、ユーザーIDとパスワードもその一種 認証する側が、アクセスキーやAPIキーといった呼び名のランダム文字列を発行し、それをクレデンシャルとして利用する プログラムがリクエスト時にそのクレデンシャルを一緒に送信することで、認証と認証情報が正しければ正常レスポンスを受け取れるという仕組み 静的クレデンシャル 長期にわたって変更しないパスワードのようなクレデンシャルを静的クレデンシャルという 静的クレデンシャルは長命という欠点があり、漏洩した場合の被害が拡大しやすい 一時クレデンシャル こちらは必要なタイミングで都度払い出すので短命 ローテーション作業もないので運用も楽 OpenID Connectというプロトコルによって実現する クラウド連携のアンチパターン 静的クレデンシャルは使用してはいけない かつてはそれしか選択肢がなかったので、記事を探すときは要注意 OpenID Connect(OIDC) これは複数の異なるドメインで認証結果を共有し、協調してサービスを提供するオープンなプロトコル（アイデンティ連携を実現する） OAuth2.0を拡張する形で設計されている 利点として、GitHub上で静的クレデンシャルの管理が不要になる(一時クレデンシャルを取得するため)＋認証時にアクセス元を細かく制限できる（GHAの場合特定リポジトリのみに許可できる） 一時クレデンシャルの取得フロー ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider) OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ) 一時クレデンシャルで操作 大抵の処理は隠蔽されており、私たちは行う作業は以下の2つのみ（準備に若干手間はかかるがメリットが大きい） クラウドプロバイダ側でOIDCに必要なコンポーネントを作成する ワークフローへクラウドプロバイダの認証アクションを組み込む OIDC TrustとCloud Roles クラウドプロバイダで準備するコンポーネントは以下の2つ OIDC Trust: クラウドプロバイダが信頼するOIDC Providerを設定(GitHub OIDC Provider) OIDCトークンで一時クレデンシャルを取得できる理由は、クラウドプロバイダがOIDC Providerを信頼しているため（OIDC Trust） OIDCトークンはJWT形式で、GitHub OIDC Providerの公開鍵を使って署名等の検証が行われる Cloud Roles: 一時クレデンシャルのアクセス先とアクセス元を制御 一時クレデンシャルの「アクセス先」を管理する AWSでいうIAMロールのこと 認証アクション 各クラウドプロバイダは公式で認証アクションを提供しているので、ワークフローからはそのアクションを呼び出すだけで、OIDCが扱える 検証作業のリスクヘッジ プライベートリポジトリで試す 認証パラメータ(AWSアカウントIDやIAMロール名)はSecretsで管理する これらクレデンシャルではないものの、ログ出力時にマスクされるので、謝ってパブリックリポジトリでワークフローを実行しても、第三者へ余計な情報が漏れない AWSにおけるOIDC利用準備と連携 以下の2つを作成する OIDC Provider AWSがGitHub OIDC Providerを信頼するように設定 IAMロール 一時クレデンシャルのアクセス先とアクセス元を制御する GHAワークフロー側での設定作業 Secrets登録 AWSアカウントID IAMロール名 ワークフロー実装 permissions id-token: writeの設定が必要 GitHub OIDC ProviderからOIDCトークン取得に必要 aws-actions/configure-aws-credentialsを利用 ロールARNとセッション名、デフォルトリージョンをパラメータとして指定する セッション名は、トレーザビリティを目的に、AssumeRole APIに渡すパラメータ名であり、CloudTrailのセッション名として記録される 「誰が・いつ・どのジョブでこのセッションを作ったか分かる」ような情報を含めると便利 例：\"${{ github.workflow }}-${{ github.run_id }}-${{ github.actor }}\" CloudRolesのセキュアな運用 他のリポジトリからアクセスできないことを確認しておく CloudRolesは目的ごとに分離する（必要最小限の権限だけ） クラウドプロバイダの設定作業にIaCを導入する 12章 コンテナオーケストレーションのデプロイメント デプロイ自動化の流れ コンテナビルドアクション：コンテナイメージのビルド＆プッシュ コンテナデプロイアクション：タスク定義の書き換えとサービスの更新 本番環境へのデプロイはルールを制限したい Deployment branches and tagsを設定する Environmentsからブランチ名パターンを登録することでパターン外のブランチでワークフローを起動できなくなる Required Reviewers ワークフローの起動に承認を必須とする デプロイメント設計 デプロイの設計では「ユーザー影響」と「ロールバック」の観点に着目する ローリングアップデート ECSのデプロイ方式 新しいバージョンへ少しずつ置き換える 無停止 ロールバック ローリングアップデートの場合は特別な仕組みはないので、リバートコミットを追加し、再デプロイする（あまり速くない） 人間が切り戻しを検知・判断するので、別途監視の仕組みが必要となる 第14章 GitHub Actionsの高度な使い方 Reusable Workflows アクションは比較的小さな処理をカプセル化するのに対し、Reusable Workflowsはワークフロー全体を丸ごとカプセル化する パーミッション パーミッション定義を省略した場合は呼び出し側ワークフローのパーミッションを暗黙的に継承する 呼び出し側より厳しくできるが、緩めることはできない なので、呼び出し側ではジョブレベルでパーミッションを定義すると良い（Reusable Workflowsの権限が最小限になるため＋ドキュメンテーションとなり可読性が向上する） コンテキスト 呼び出し側ワークフローのコンテキストを直接参照できる ただしReusable Workflowsが制御できないgithub.eventプロパティを参照すると再利用性は低下するので注意が必要 Secrets 呼び出し側ワークフローのコンテキストを直接参照できない 入力パラメータ経由で渡す or 呼び出し側でsecrets: inheritを指定するとまとめて継承可能 暗黙的な継承となりコードが追いづらくなるので個別で入力パラメータとして渡すのが良い 環境変数 こちらも参照できないので入力パラメータ経由で渡す fromJSON関数 動的なワークフロー定義 事前にマトリクスを生成できない場合、fromJSON()をmatrixに指定することで動的にマトリクスを生成できる 文字列の型変換 ワークフロー構文の環境変数はstring型として扱われてしまう その際string型の文字列をnumber型やboolean型に変換できる エラーハンドリング Continue on Error デフォルトではエラーが発生するとその時点でワークフローが停止する continue-on-error: trueを指定すると、エラーを握りつぶし、次の処理に進む これを指定すると、途中でエラーが発生しても、ワークフロー自体は正常終了扱いされる ログを見ない限りエラーには気づけないので、リカバリー不要な場合のみ使用する マトリックスのフェイルファスト マトリックスを使うと複数のジョブが並列に起動する 途中でエラーが発生した場合、他のジョブが止まる fail-fast: falseを指定することで他のジョブを継続可能とできる コンテキストによるフロー制御 終了状態を取得できるコンテキスト stepsコンテキスト：ステップの終了状態を保持 outcomeプロパティはContinue on Error適用前の終了状態（つまり生情報） conclusionプロパティはContinue on Error適用後の終了状態 needsコンテキスト：（依存している）ジョブの終了状態を保持 resultプロパティのみ コンテキストとステータスチェック関数の併用 「前のステップが失敗したら」という条件式を書きたい場合 if: ${{ failure() \u0026\u0026 steps.stepName.outcome == 'failure' }}とする必要がある このようにステータスチェック関数とコンテキスト参照を併用する必要がある理由として、failure()が記述されていない場合、暗黙的にsuccess()関数が存在すると解釈されるため 15章 GitHub Actionsのセキュリティ この章では「ソフトウェアサプライチェーン」に着目する ソフトウェアサプライチェーンとは、コード書いてから実行環境へリリースまでに含まれる一連のアクティビティを意味する GHAはさまざまなシステムと連携するため、強力な権限が集中するため、悪意ある人にとってはとても魅力な攻撃対象になる セキュリティのCIA CIAとは、機密性・完全性・可用性のこと CIAの観点から、守るべき資産はコード・クレデンシャル・アーティファクトとなる 闇雲に対策するのではなく、利便性とのトレードオフとなる セキュリティの設計原則 脅威を完全に排除することは難しいので、脅威の軽減を目標とする アタックサーフェス＝攻撃される恐れのある場所を小さくする シンプルな設計を意識する（複雑な設計では意図しないこれ↑を生みやすいので） 複数のセキュリティレイヤを用意して、多層防御にする 最小権限 攻撃されても被害を小さくできる 一時クレデンシャルのような権限の行使に時間の制約があるようなものも有効だと思われる Githubのサービス特性 上記の設計原則を踏まえて考えていく GitHubはデフォルトの設定は利便性重視なので注意する コードをプッシュできる人はワークフローの実行ができるという仕様を理解する 悪意ある人もコントリビューション可能であることを認識する サードパーティアクション サードパーティのアクションがリポジトリのコードを参照できるかはパーミションによるが、ほとんどのワークフローではコードにチェックアウトするので、大半のアクションはコードを参照できる サードパーティアクション導入時は、そのサードパーティを信頼するかを意識的に決断するようにする 本当に信頼して良いかを考えるクセをつけるのが重要 リポジトリ設定で利用制限も可能 呼び出し時にコミットハッシュによる固定を行えば、アクションを不変リソースとして扱える ハッシュ指定だけでは分かりづらいので、コメントでバージョン情報を併記しておくと分かりやすい 筆者の考えとしては「ある程度の車輪の再発明は仕方ない」それくらいサードパーティアクションの使用は慎重になるべき スクリプトインジェクション 外からやってくるデータ（例：PRのタイトル）に悪意あるスクリプトが仕込まれていた場合、それがワークフローの中で読み込まれてスクリプトとして実行されてしまうリスクがある 対策として、 中間環境変数による無害化 env: PR_TITLE: ${{ github.event.pull_request.title }}というような形でスクリプトインジェクションを防げる どのプロパティが危険かを正確に判断するのは困難なので、コンテキストは常に中間環境変数で参照するようにするのが確実で楽 ShellCheckによる静的解析 Github-Hosted Runnerには最初からインストールされている actionlintは内部的にShellCheckを実行していて、yamlに直接書いたスクリプトもチェックしてくれる 最小権限のパーミッション パーミッションはpermissionキーで設定可能 省略可能で、省略した場合はコード参照が許可される 明示的な記述を習慣化することで、自然とパーミッションを意識するようになる 具体的には、 ワークフローレベルでのパーミッション無効化(permissions: {})の設定を入れることで、コード参照すら明示的な許可が必要になる 各ジョブへ都度、必要なパーミッションを定義する 面倒に見えるが、やってみると慣れるのは早い ジョブ分割によるパーミッションの分離 パーミッションのスコープはいくつかあるが、特に注意すべきなのが以下の4つ contents: 改竄されたコードをプッシュされるリスク packages: 悪意あるパッケージをパブリッシュされるリスク actions: 別のワークフローを意図せず起動されるリスク id-token: OIDCでクラウドプロバイダにアクセスされるリスク これらのパーミッションを複数扱う場合はジョブの分割を検討すると良い パーミッションをジョブ単位で記述すれば、ジョブがセキュリティ境界となる シークレットマネジメント まずはクレデンシャルの把握をすべき 最小権限・一時クレデンシャルを優先・定期的なローテーション OpenID Connectハードニング OpenID Connectを深掘りするパート (再掲)一時クレデンシャルの取得フロー ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider) OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ) 一時クレデンシャルで操作 IDトークン 上記の1のOIDCトークンと呼んでいるものはOIDCの世界ではIDトークンと呼ぶ これには主体に認証情報を含んでおり、リポジトリやワークフローの情報が含まれている これらの属性情報を受け取ったクラウドプロバイダ側で検証し、アクセス可否を判断している IDトークンの実体は、JWTである ヘッダ・ペイロード・署名をピリオド区切りでBase64URLエンコードしたもの ペイロードのデータ構造は決まっており、JSONの各フィールドはクレームと呼ぶ IDトークンにはいくつかの必須クレームがあり、この必須クレームがセキュリティ上重要となる IDトークンの検証フロー ワークフローはGitHub OIDC Providerから取得したIDトークンをクラウドプロバイダに渡す クラウドプロバイダはIDトークンの署名を検証し、JWTクレームを検証する この検証に成功したら、一時クレデンシャルをワークフローに返送する IDトークンの署名検証 本当にGitHub OIDC Providerが発行したIDトークンなのか確認する 署名の検証には、GitHub OIDC Providerの公開鍵を探し出す必要がある どこを探すかというと、OIDC Trust(AWSの場合はOpenID Connect Provider)にGitHub OIDC ProviderのURLを設定していて、このURLが公開鍵の検索に使用される（https://token.actions.githubusercontent.com） 注意点として、上記のURLは全アカウントで共通のため、アカウントやリポジトリの識別ができない（GitHubが生成したという内容しか検証できない） そこでJWTクレーム検証でその部分を補う形で検証する IDトークンのJWTクレーム検証 IDトークンの署名だけではGitHub利用者が誰でもアクセスできてしまうため、JWTクレームでも検証を行う JWTクレーム検証はクラウドプロバイダによって異なるが、AWSではAssumeRoleポリシーのCondition定義に基づいて検証を行う subクレーム もっとも重要な検証対象となる 認証された主体の識別子が格納される（一般的にはユーザーIDなど） GitHub Actionsでは少し毛色が異なり、ワークフローの属性情報を連結した値が入る（アカウント名やリポジトリ名など） ワークフローの実行方法によって値が異なるが、repo:/:のような文字列はどの方法でも含まれる なのでアカウント名やリポジトリ名が正しいかの判断は可能 GitHubのカスタムクレーム IDトークンは拡張が認めらていて、任意のカスタムクレームを追加可能 クラウドプロバイダによってサポート状況が異なっているので注意（AWSはサポートしていない） クラウドプロバイダのJWTクレーム検証設定 AssumeRoleポリシーのConditionに以下のように記述する \"token.actions.githubusercontent.com:sub\": \"repo:/:*\" 左辺のキーはsubクレームを指している 他の値もsubクレームで検証するとセキュリティがより強固になる Environmentsの検証 subクレームに含まれるEnvironmentsの値を検証することで、商用環境にアクセスできるのはレビュー済みのワークフローのみとしたいといった制御が可能 JWTクレームの検証はOpenID Connectのキモであり、特にsubクレームは重要となる 16章 セキュリティのシフトレフト セキュリティは後回しにしがちだが早めに取り組むのが良い戦略 これがシフトレフトという考え方（痛い目に遭うくらいなら早めに対処しよう） 依存関係の脆弱性スキャン 最新に保ち続けられるならそれで十分だけど現実はそうもいかない そこで活用したいのが依存関係の脆弱性を検出するサービス Dependabot Alerts 依存関係の脆弱性を発見するとアラートを送信する 「新たなコードのプッシュでDependency Graphが更新された時（例えばpackage.jsonなどのファイルが更新された時と同意かな？）」と「脆弱性データベースであるGitHub Advisory Databaseに脆弱性が登録された時」のタイミングでリポジトリをチェックしてくれる Dependabot security updates Alertsは情報提供で、これはプルリクエスト作成まで行ってくれるサービス 「security updates」は脆弱性のパッチを当てたバージョンへあげるもの（「version updates」の方は常に最新バージョンにあげるという違いがある） 設定ファイルについて .github/dependabot.ymlは、security updatesとversion updatesで共有される 共有されるということは除外ルールを書いたらどちらでも検知されない なので防御策として、Alertsを合わせて有効化しておくと良い（Alertsは設定ファイルに依存しない）そうすれば検出漏れを最小限にできる シークレットスキャン GitHubのシークレットスキャン機能は経済的理由で導入が困難な場合もある SecretlintというDockerで動かせるAWSやGitHubなどの主要サービスのクレデンシャルを検出できる これをGitHubActionsで動かすと尚良い その際、検出された情報がログ出力されないように注意（--maskSecretsオプションで設定可能） 途中からシークレットスキャンを導入する場合は全ヒストリーをスキャンするGitleaksというツールがある これもDockerで動かせる git push前にスキャンするのがベター .git/hooks/pre-commitファイルへシークレットスキャンコマンドを組み込むとコミット時にスキャンが実行あsれる 個々人で設定可能が必要であり、ストレスに感じる人もいるため、実際にやるかどうかは個人の判断に委ねると良い アプリケーションスキャン Static Application Security Testing(SAST) コードスキャンしてセキュリティ問題を検出する（静的解析） Goだとsecurego/gosec: Go security checkerがそれみたい コンテナイメージの脆弱性スキャン Trivyというツール 他にはコンテナレジストリでスキャン実施できる Infrastructure as Codeセキュリティ IaCで作業ミスは抑制できるが、セキュリティミスは防げない そしてパッと見で正しく動作しているように見えるので意外と発見が難しい セキュリティ設定ミスの防止 ここでもTrivyが活躍する 万事解決とまでいかないが、優れた出発点となる Policy as Code Conftestというツールが使える ポリシールールを設定ファイルに記述し、それを検証してくれる これもDockerで動かせるのでワークフローに簡単に実行できる 選択肢の1つとして持っておくと良い 継続的なセキュリティの改善 誤検出と検出漏れはどうしても発生する（バランス・トレードオフ） 誤検出は想像異常にストレスが大きい またツールを導入しすぎるたりして検出される問題が多すぎるとアラート疲れも発生する 時々立ち返って運用を見返すのが良い 18章 継続的デリバリーの実践 組織パフォーマンスを研究しているGoogleのDORAというチーム曰く「ソフトウェアデリバリーパフォーマンスは組織パフォーマンスと高い相関がある」と学術的な方法で示したこと DORAの研究では「スピードが速い組織ほど品質も高い」を提唱している 加えて、個人の幸福や組織文化にも寄与すると考えられている この章では「継続的デリバリー」うまく実践するために、何ができるかを紹介していく バージョン管理戦略 継続的デリバリーは適切なバージョン管理から始まる 大原則は「ソフトウェアの実行に必要なあらゆるものをバージョン管理する」 ソースコードだけではなく、テスト・ビルド・デプロイ・データベースマイグレーション・運用などのスクリプト・インフラ設定もバージョン管理の対象（つまりクレデンシャル以外） 1日に1回はデフォルトブランチにマージする短命なブランチ運用＝トランクベース開発をすることで、コード変更量が小さいのでレビューしやすかったりコンフリクトが発生しづらかったりする 実装途中の機能を一時的に無効化したい場合は「フィーチャートグル」を使えば良い 詳細: 機能トグル（別名機能フラグ） テスト戦略 CDの品質改善では、4章で説明した自動テストが重要な役割を担う それ以外の異なる観点を提供するものとして、以下の2つがある 探索的テスト 自動化できないテストのこと テストの目的は「調査」と「検証」がある 自動テストは記事の問題を「検証「することで、探索的テストは人間が手動で未知の問題を「調査」すること（目的が異なる） Testing in Production リリース後も本番環境でテストする A/Bテストやシンセティックテストなど リリース戦略 恐怖の克服 いくら自動化しても経験しないと恐怖は薄れない 自分の手でリリースすることが大切 ロールバック ロールバックも全員が慣れておく 頻度が少ないためにやり方を知らない人がいるので手順を周知し、平時にロールバックの練習をしておく デプロイとリリースの分離 分離していない場合にデプロイに問題があった時は全ユーザーに影響がある 分離する方法として、デプロイ後にユーザートラフィックを少しずつ新しい環境に流す「カナリアリリース」がある データベースの変更管理 手作業でデータベースコマンドを実行してはダメ マイグレーションスクリプト経由で実行すると、ヒューマンエラーも発生しない ロールバック用のスクリプトも用意するようにする IaCの変更管理 IaCはソフトウェアとライフサイクルが異なるため、固有の考慮点が存在する ツールにドライ欄があるならそれを使用する 毎回手動実行は大変なので、プルリクエスト作成時に自動で実行し、それをコメントに貼り付ける 「本番環境への適用はデフォルトブランチにマージした時のみ」という規律を設けるべき IaCはローカルからの変更は事故が起きやすいので止める 実行環境は強力な権限が必要なので、絶対消されてはいけないDB等のリソース削除を禁止したり、権限昇格なIAM操作を禁止すべき 構成ドリフト（実態とコードの差分がある状態）は定期的にドライランを実行して通知させよう 疎結合なアーキテクチャ 疎結合はCDがとても実践しやすい テストやデプロイの容易性 ",
  "wordCount" : "866",
  "inLanguage": "en",
  "datePublished": "2025-05-27T21:25:40+09:00",
  "dateModified": "2025-05-27T21:25:40+09:00",
  "author":{
    "@type": "Person",
    "name": "nyuusen"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/my-hugo-blog/posts/010_github_cicd%E5%AE%9F%E8%B7%B5%E3%82%AC%E3%82%A4%E3%83%89/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "nyuusen blog",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/my-hugo-blog/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/my-hugo-blog/" accesskey="h" title="nyuusen blog (Alt + H)">nyuusen blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      GitHub CICD実践ガイド
      <span class="entry-hint" title="Draft">
        <svg xmlns="http://www.w3.org/2000/svg" height="35" viewBox="0 -960 960 960" fill="currentColor">
          <path
            d="M160-410v-60h300v60H160Zm0-165v-60h470v60H160Zm0-165v-60h470v60H160Zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22q0 11-4.5 22.5T862.09-380L643-160H520Zm300-263-37-37 37 37ZM580-220h38l121-122-18-19-19-18-122 121v38Zm141-141-19-18 37 37-18-19Z" />
        </svg>
      </span>
    </h1>
    <div class="post-meta"><span title='2025-05-27 21:25:40 +0900 JST'>May 27, 2025</span>&nbsp;·&nbsp;5 min&nbsp;·&nbsp;nyuusen

</div>
  </header> 
  <div class="post-content"><h2 id="1章-ソフトウェア開発とgithub">1章 ソフトウェア開発とGitHub<a hidden class="anchor" aria-hidden="true" href="#1章-ソフトウェア開発とgithub">#</a></h2>
<ul>
<li>継続的インテグレーションとは？
<ul>
<li>コードの変更を頻繁にコードベースに統合し、正しく動作するかを繰り返し検証する</li>
<li>統合頻度が上がるとコンフリクトが減る</li>
<li>繰り返して検証を行うとバグを発見すれば素早く修正できる</li>
<li>ソフトウェアが安定して動けば、ユーザーの満足度も向上する</li>
</ul>
</li>
<li>継続的デリバリーとは？
<ul>
<li>リリースしないとユーザーには価値を提供できない</li>
<li>いつでも安全にリリースできる状態を保ち、ソフトウェアを繰り返し改善する</li>
<li>CIとCDは同列の概念に見えるが、CIはCDに包含される</li>
</ul>
</li>
</ul>
<h2 id="2章-githubactionsの基礎概念">2章 GitHubActionsの基礎概念<a hidden class="anchor" aria-hidden="true" href="#2章-githubactionsの基礎概念">#</a></h2>
<ul>
<li>実行時エラー
<ul>
<li>コマンドの終了ステータスが0ならば成功、0以外ならば失敗見なされる</li>
<li>なので、ワークフローでは終了ステータスを適切に返すことが大事</li>
</ul>
</li>
<li>手動実行
<ul>
<li>on: workflow_dispatchで手動実行できる</li>
<li>inputとして、列挙型となるchoice型の指定が可能</li>
</ul>
</li>
<li>定期実行
<ul>
<li>on: schedule: cron()で定期実行できる</li>
<li>時刻はUTCなので注意</li>
</ul>
</li>
<li>実行環境
<ul>
<li>GitHub-Hosted Runners
<ul>
<li>GitHubが提供するマネージドな実行環境</li>
<li>LargerRunnersというマシンスペック向上したものも利用可能（有料）</li>
<li>サポートOSとしては、Linux(Ubuntu)/Windows/macOSがある</li>
<li>よく使用するDocker,Node.js,npmなどは既にインストールされている
<ul>
<li>ただし、バージョン固定はできないので、バージョン固定で使用したい場合は、ワークフローの中で自分でインストールする必要ある</li>
</ul>
</li>
<li>エフェメラルという特性
<ul>
<li>ジョブ終了時に破棄されるので、毎回クリーンな環境でジョブを実行できる</li>
<li>この特性は一貫性向上に貢献している</li>
</ul>
</li>
</ul>
</li>
<li>Self-Hosted Runners
<ul>
<li>利用者が実行環境を用意する</li>
</ul>
</li>
</ul>
</li>
<li>MarketPlace
<ul>
<li>再利用できるワークフローが公開されている</li>
<li>著名な組織にはVerifiedCreatorsマークがついているので、そういうのを利用するとセキュリティ不安が低減する（100%安全とは言い切れないが）</li>
</ul>
</li>
<li>料金
<ul>
<li>パブリックリポジトリなら無料</li>
<li>プライベートは使用時間とストレージ使用量で計算される</li>
<li>月毎に無料枠があり、それを超えると課金が発生するが、支払い設定をしていない場合は実行できなくなるだけ（なので安心できる）</li>
<li>使用時間は、実行時間×ランナーごとの料率で計算される
<ul>
<li>料率はubuntuが1,Windowsが2,macOSが10なので、なるべくUbuntuを利用するのがオススメ</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="3章-ワークフロー構文の基礎">3章 ワークフロー構文の基礎<a hidden class="anchor" aria-hidden="true" href="#3章-ワークフロー構文の基礎">#</a></h2>
<h3 id="環境変数">環境変数<a hidden class="anchor" aria-hidden="true" href="#環境変数">#</a></h3>
<ul>
<li>単一のワークフローで使用できる</li>
<li>envで定義する</li>
<li>ワークフロー・ジョブ・ステップで定義可能
<ul>
<li>定義した場所で、環境変数のスコープが異なる</li>
</ul>
</li>
<li>中間環境変数
<ul>
<li>コンテキスト(github.base_refのように参照できるもの)は、各ジョブ(ステップ)の中で直接スクリプトに埋め込むのはNG
<ul>
<li>理由: スクリプトインジェクションにリスクがあるため</li>
</ul>
</li>
<li><code>env</code>の中で一度変数展開し、スクリプト内ではダブルクオテーションで囲むことが推奨される
<ul>
<li>変数展開することでメモリ上で保存されるので、スクリプト生成プロセスには生成プロセスには相互作用しないため</li>
</ul>
</li>
<li>GHAに限らず、シェルスクリプト全体で言えること</li>
</ul>
</li>
</ul>
<h3 id="variables">Variables<a hidden class="anchor" aria-hidden="true" href="#variables">#</a></h3>
<ul>
<li>複数のワークフローで使用できる</li>
<li>varsコンテキストでアクセスする</li>
<li>こちらも参照時は中間環境変数経由(envの中で環境変数に展開してから)が推奨</li>
</ul>
<h3 id="secrets">Secrets<a hidden class="anchor" aria-hidden="true" href="#secrets">#</a></h3>
<ul>
<li>以下の特徴がある
<ul>
<li>登録した値は暗号化され、GitHub内で安全に管理される</li>
<li>ログ出力時はマスクされる</li>
<li>登録後の値確認は不可となる</li>
</ul>
</li>
<li>ログマスクのアルゴリズムは完全一致のみ、1文字スペースを加えたりするだけで出力されてしまうので、ログマスクは当てにしないようにする
<ul>
<li>そもそもsecretsの値はログ出力しないようにしましょう</li>
</ul>
</li>
</ul>
<h3 id="expressions式">expressions(式)<a hidden class="anchor" aria-hidden="true" href="#expressions式">#</a></h3>
<ul>
<li><code>${ example }</code>のような形で定義</li>
<li>リテラルや演算子などが使用可能</li>
<li>比較演算の際、GHAでは異なる型の値を比較すると、勝手に値が変換されるので注意</li>
<li>オブジェクトフィルター
<ul>
<li>配列やオブジェクトから指定したプロパティを抜き出し、配列を生成する</li>
<li><code>${{ github.event.*.html_url }}</code>のような形で<code>*</code>を使用する</li>
</ul>
</li>
</ul>
<h3 id="条件分岐if">条件分岐(if)<a hidden class="anchor" aria-hidden="true" href="#条件分岐if">#</a></h3>
<ul>
<li>ifの少し面白い使い方として、最初のジョブへ条件分岐を定義し、特定の条件でスキップするようにすると、ワークフロー自体の実行がスキップできる
<ul>
<li>使用時間もゼロになり、コスト削減につながる</li>
</ul>
</li>
</ul>
<h3 id="ネーミング">ネーミング<a hidden class="anchor" aria-hidden="true" href="#ネーミング">#</a></h3>
<ul>
<li>実行ログが見やすくなるのでジョブ名やステップ名はきちんと書く</li>
<li>run-nameは、nameとは異なり、コンテキストが利用できる
<ul>
<li><code>run-name: Run by ${{ github.actor }}</code></li>
</ul>
</li>
</ul>
<h3 id="ステップ間のデータ共有">ステップ間のデータ共有<a hidden class="anchor" aria-hidden="true" href="#ステップ間のデータ共有">#</a></h3>
<ul>
<li>2つのやり方がある
<ul>
<li>GITHUB_OUTPUT環境変数
<ul>
<li>定義: echo &ldquo;<!-- raw HTML omitted -->=<!-- raw HTML omitted -->&rdquo; &raquo; &ldquo;${GITHUB_OUTPUT}&rdquo;</li>
<li>参照: ${{ steps.<!-- raw HTML omitted -->.outputs.<!-- raw HTML omitted --> }}</li>
<li>参照方法を見ると分かる通り、ステップ間の依存関係が明白</li>
</ul>
</li>
<li>GITHUB_ENV環境変数
<ul>
<li>定義: echo &ldquo;<!-- raw HTML omitted -->=<!-- raw HTML omitted -->&rdquo; &raquo; &ldquo;${GITHUB_ENV}&rdquo;</li>
<li>参照: ${GITHUB_ENV}</li>
<li>ステップIDの指定が不要なので、どのステップで環境変数を設定したかを意識する必要ない</li>
<li>異なる複数のステップで、同じ値を参照する場合に使える（ただしステップ間の依存がわかりづらくなる）</li>
<li>これで定義したものは、事実上グローバル変数なので、ワークフローが大きくなるとバグの原因になるので注意が必要</li>
</ul>
</li>
<li><strong>特にこだわりなければ、GITHUB_OUTPUTを使用する</strong></li>
</ul>
</li>
</ul>
<h3 id="github-apiの実行">GitHub APIの実行<a hidden class="anchor" aria-hidden="true" href="#github-apiの実行">#</a></h3>
<ul>
<li>GitHubHostedRunnerの場合は、GitHub CLIがインストールされているのでそれを使うと良い</li>
<li>API(CLI)の実行にはトークンが必要
<ul>
<li>GHAには簡単に使えるクレデンシャルが利用できる</li>
<li>ワークフロー開始時に自動生成、終了すると自動的に破棄</li>
<li>有効期限は、ワークフロー実行中のみなので、万が一漏れても影響範囲は限定的</li>
<li>取得方法は、<code>${{ secrets.GITHUB_TOKEN }}</code> もしくは <code>${{ github.token }}</code>
<ul>
<li>どちらでも良いので、どちらかに統一するのが良い</li>
</ul>
</li>
<li>トークンの指定は、<code>GITHUB_TOKEN</code>もしくは<code>GH_TOKEN</code>という名前の環境変数をセットするだけで、自動で読み込んでくれる</li>
</ul>
</li>
<li>パーミッション
<ul>
<li>ジョブレベルとワークフローレベルで指定可能</li>
<li>スコープ(contents, pull-requests等)とそれに対するアクション(read, write, none)を設定する</li>
<li>ただしワークフローを実行しているリポジトリ以外のアクセスは許可されない</li>
<li>パーミッションを明示的に定義していない場合、自動でソースコードの読み込み許可はされる
<ul>
<li>一方、明示的な定義をする場合は、この暗黙的な挙動は無視されるので注意</li>
</ul>
</li>
</ul>
</li>
<li>パーミッション周りのトラブルシューティング
<ul>
<li>ワークフロー実行ログのSet up jobの中に、GITHUB_TOKEN Permissionsがあるので、そこで実行時のパーミッションを確認できる</li>
</ul>
</li>
</ul>
<h3 id="スターターワークフロー">スターターワークフロー<a hidden class="anchor" aria-hidden="true" href="#スターターワークフロー">#</a></h3>
<ul>
<li>GitHubリポジトリのActionsからNew Workflowを選択すると、ワークフローのコレクションが並んでいるので、参考にできそう
<ul>
<li><a href="https://github.com/actions/starter-workflows?tab=readme-ov-file">https://github.com/actions/starter-workflows?tab=readme-ov-file</a></li>
</ul>
</li>
</ul>
<h2 id="4章-継続的インテグレーションの実践">4章 継続的インテグレーションの実践<a hidden class="anchor" aria-hidden="true" href="#4章-継続的インテグレーションの実践">#</a></h2>
<ul>
<li>大体以下の流れでワークフローを構成する
<ul>
<li>checkout</li>
<li>setup(ex: actions/setup-go)</li>
<li>リントやテストの実行</li>
</ul>
</li>
<li>フィルター
<ul>
<li>pathsと他の条件を指定するとAND条件になる</li>
</ul>
</li>
<li>静的解析
<ul>
<li>actionlintは、GHAワークフローの静的解析を行ってくれるので便利</li>
</ul>
</li>
<li>使用時間の削減（どのワークフローでも有用な設定）
<ul>
<li>ジョブ・ステップレベルのタイムアウト設定
<ul>
<li>どのワークフローにも設定するようにする（GHAのデフォルト値は360分と大変長いため）</li>
</ul>
</li>
<li>自動キャンセル（新しいコミットが追加されたら、古いコミットで動作しているワークフローを自動でキャンセルする）</li>
</ul>
</li>
<li>シェル
<ul>
<li>ステップごとに起動シェルをshellキーで設定可能</li>
<li>Ubuntuの場合、省略時はbashだが、shellキーの指定有無で起動オプションが変更される</li>
<li>全ステップに書くのは面倒なので、ワークフローのトップレベルにデフォルト設定(defaults句)するのが良い</li>
<li>デフォルトシェルにはデメリットは存在しないので、全てのワークフローに機械的に入れるのがオススメ</li>
</ul>
</li>
</ul>
<h3 id="concurrency">Concurrency<a hidden class="anchor" aria-hidden="true" href="#concurrency">#</a></h3>
<ul>
<li>ワークフローはイベント駆動なので、イベントが発生すると起動、さらにまたイベントが発生すると起動することになる</li>
<li>起動制御できる仕組みとして、Concurrencyがある</li>
<li><code>concurrency: &lt;group-name&gt;</code>とすることで、同一グループの多重制御が設定できる
<ul>
<li>さらに<code>cancel-in-progress: true</code>で自動キャンセルの設定も可能（プルリクエストで最新ではないコミットのCIとかに有効）</li>
</ul>
</li>
</ul>
<h3 id="ciの黄金律">CIの黄金律<a hidden class="anchor" aria-hidden="true" href="#ciの黄金律">#</a></h3>
<ul>
<li>「クリーンに保つ」
<ul>
<li>全てのステータスチェックが成功した時だけマージできるようにする</li>
</ul>
</li>
<li>「高速に実行する」
<ul>
<li>CIの実行が遅いと、待ち時間に他の作業→CIで失敗したらその対応する時にコンテキストスイッチが必要になる</li>
<li>時間の無駄だし、開発効率の低下につながる</li>
<li>CIのスピードは大切で、理想は5分以内、遅くとも10分以内に終わらせるように</li>
</ul>
</li>
<li>「ノイズを減らす」
<ul>
<li>CIからのフィードバックで価値ある情報の「シグナル」とそうではない「ノイズ」</li>
<li>判断基準としては、その情報を受け取り、これは気にしなくて良いやと流したならそれがノイズ</li>
<li>ノイズがあると、シグナルもスルーされてしまうので、ノイズは意識的に減らす</li>
</ul>
</li>
</ul>
<h3 id="テスト">テスト<a hidden class="anchor" aria-hidden="true" href="#テスト">#</a></h3>
<ul>
<li>単体テストの割合を増やす</li>
<li>フレーキーテストを放置しない（閾値を超えるとテスト全体が信頼されなくなる）
<ul>
<li>Googleソフトウェアエンジニアリングでは閾値は1％とされている</li>
</ul>
</li>
<li>遅いテストは実行タイミングをPRマージの時に限定するなど工夫する</li>
<li>使用しているテストツールで以下のような機能を利用する
<ul>
<li>部分実行</li>
<li>並列実行</li>
<li>シャッフル実行（テスト間の隠れた依存関係も洗い出せる）</li>
<li>カテゴリ実行（スローテスト用のカテゴリを作ってそれだけ実行しないみたいな）</li>
</ul>
</li>
</ul>
<h3 id="静的解析">静的解析<a hidden class="anchor" aria-hidden="true" href="#静的解析">#</a></h3>
<ul>
<li>不要な警告は無視するのではなく抑止する
<ul>
<li>ignoreやsuppressのキーワードで検索する</li>
<li>抑止理由はコメントやコミットメッセージに残しておく</li>
</ul>
</li>
</ul>
<h2 id="第5章-運用しやすいワークフロー設計">第5章 運用しやすいワークフロー設計<a hidden class="anchor" aria-hidden="true" href="#第5章-運用しやすいワークフロー設計">#</a></h2>
<ul>
<li>長期運用で役立つプラクティスの紹介</li>
</ul>
<h3 id="ロギング">ロギング<a hidden class="anchor" aria-hidden="true" href="#ロギング">#</a></h3>
<ul>
<li>ワークフローの再実行時の「Enable debug logging」を有効にすると、デバッグログが確認できる</li>
<li>デバッグログには以下がある
<ul>
<li>ステップデバッグログ
<ul>
<li>ステップのログの詳細（ステップステータスや各種コンテキスト）をトレースできる</li>
<li>SecretsまたはVariablesに「<code>ACTIONS_STEP_DEBUG</code>」をtrueで登録しておくことで、これらの値も確認できる</li>
</ul>
</li>
<li>他は内部実装者向けだったりするので、割愛</li>
</ul>
</li>
<li>Bashのトレーシングオプション
<ul>
<li>デバッグログよりシンプルで、どんなコマンドが実行され、結果はなんだったのかを知りたいケースで使用する</li>
<li>Bashのトレーシングオプションは、<code>set -x</code>を実行するだけなので、手軽だが強力</li>
<li>全てのコマンドが実行前に表示されるようになり、どのコマンドがどのような引数で実行されているかを確認できる</li>
</ul>
</li>
<li>ログのグルーピング、手動マスク等もある</li>
</ul>
<h3 id="レポーティング">レポーティング<a hidden class="anchor" aria-hidden="true" href="#レポーティング">#</a></h3>
<ul>
<li>アノテーション
<ul>
<li><code>echo &quot;::error::This is error&quot;</code>みたいな形で書くとジョブページにみやすい形で表示</li>
</ul>
</li>
<li>ジョブサマリー
<ul>
<li>シンプルなテキストならアノテーションで十分だが、複数行表示したい場合等はマークダウン形式で出力される<code>${GITHUB_STEP_SUMMARY}</code>が便利</li>
</ul>
</li>
</ul>
<h3 id="複数ジョブの実行制御">複数ジョブの実行制御<a hidden class="anchor" aria-hidden="true" href="#複数ジョブの実行制御">#</a></h3>
<ul>
<li>デフォルトでは複数のジョブを実行すると並列実行される
<ul>
<li>並列実行は、全体の実行時間を短縮できる</li>
<li>もしジョブの実行時間の長さに問題がある場合は、ジョブを細かく分割し、並列実行させるというアプローチもある</li>
</ul>
</li>
<li>逐次実行させたい場合は、<code>needs</code>を使用する</li>
<li>ジョブ間のデータ共有
<ul>
<li>$GITHUB_OUTPUT環境変数に出力し、stepsコンテキスト経由で受け渡す</li>
<li>受け取る側は、needsコンテキストを経由で受け取る</li>
</ul>
</li>
</ul>
<h3 id="environments">Environments<a hidden class="anchor" aria-hidden="true" href="#environments">#</a></h3>
<ul>
<li>環境差分をパラメータ化でき、VariablesとSecretsがある</li>
<li>参照方法は、通常のVariablesとSecretsと同一(vars.xxx, secrets.xxx)</li>
<li>よくあるのはワークフローの入力値で環境名をもらい、それをenvironmentsにセットし、同じ変数名(環境ごとに値が異なる)を参照</li>
</ul>
<h3 id="キャッシュ">キャッシュ<a hidden class="anchor" aria-hidden="true" href="#キャッシュ">#</a></h3>
<ul>
<li>actions/cachedでGHA上にキャッシュとその利用が可能</li>
<li>実行時のパラメータとして
<ul>
<li>key: キャッシュキー。生成と保存に利用する。</li>
<li>path: キャッシュ対象となるディレクトリ/ファイルパス。</li>
<li>restore-keys: キャッシュミス時のリストアキーを複数指定する。</li>
</ul>
</li>
<li>キャッシュ復元時に挙動
<ul>
<li>①keyキーに定義したキャッシュキーと厳密に一致するキャッシュを探す</li>
<li>②リストアキーの定義順に、プレフィックスが一致するキャッシュを探す</li>
<li>リストアキーは省力可能であり、これはパッケージマネージャーと併用するときに威力を発揮する
<ul>
<li>大半のパッケージマネージャーはキャッシュにないファイルだけダウンロードするように振る舞う</li>
</ul>
</li>
</ul>
</li>
<li>キャッシュは、7日以上アクセスされないと自動削除される
<ul>
<li>ブラウザからリポジトリ画面で手動削除も可能</li>
</ul>
</li>
<li>合計サイズは、リポジトリで10GBまで</li>
</ul>
<h4 id="キャッシュキーの設計">キャッシュキーの設計<a hidden class="anchor" aria-hidden="true" href="#キャッシュキーの設計">#</a></h4>
<ul>
<li>プラットフォームごとに異なるキャッシュを利用するようにする
<ul>
<li>キャッシュは最低でもOSごとに分離する</li>
<li>他にもCPUアーキテクチャや言語バージョン、パッケージマネージャーもキャッシュキーの候補</li>
<li>例えば、OSとCPUアーキテクチャでキャッシュを分離するなら: <code>key: example-${{ runner.os }}-${{ runner.arch }}</code></li>
</ul>
</li>
<li>依存関係を更新した時だけキャッシュを変更するようにする
<ul>
<li>package-lock.jsonのようなロックファイルがある場合、そのファイルハッシュをハッシュキーに指定する
<ul>
<li><code>hashfiles('**/package-lock.json)</code></li>
</ul>
</li>
<li>ロックファイルが更新されない限り、キャッシュが利用されるようになる</li>
</ul>
</li>
</ul>
<h3 id="アーティファクト">アーティファクト<a hidden class="anchor" aria-hidden="true" href="#アーティファクト">#</a></h3>
<ul>
<li>ワークフロー内で生成したファイルをアーティファクトと呼ぶ</li>
<li>アーティファクトはGitHubストレージへ一時的に保存ができる
<ul>
<li>ビルドしたバイナリやメトリクスデータの保存に利用できる</li>
</ul>
</li>
<li>アーティファクトの保存はデフォルト90日で、保存時にパラメータ(retention-days)で指定可能
<ul>
<li>プライベートリポジトリだとストレージ容量は課金対象のため、保存期間を短くすると節約できる</li>
</ul>
</li>
</ul>
<h2 id="6章-アクションによるモジュール化">6章 アクションによるモジュール化<a hidden class="anchor" aria-hidden="true" href="#6章-アクションによるモジュール化">#</a></h2>
<ul>
<li>ここでいう「アクションによるモジュール化」とは、ワークフローにおける小さな部品（ステップやコマンドの小さな単位）をモジュール化すること</li>
<li>ランナーは、呼び出し元ワークフローに依存する</li>
<li>アクションの実装方式は以下の3つがある
<ul>
<li>Composite: YAMLで定義</li>
<li>JavaScript: JSで定義</li>
<li>Docker Container: Dockerで動かす(ビルド・起動するDockerfileを指定)
<ul>
<li>これらはrunsのusingキーで指定する(ex: <code>using: composite</code>)</li>
</ul>
</li>
</ul>
</li>
<li>アクションのロケーションは「ローカル」と「リモート」がある
<ul>
<li>リモート: <code>uses: actions/checkout@v4</code>
<ul>
<li>URLと連動する</li>
<li><code>@v4</code>の部分はGitのタグ（ブランチやコミットハッシュも指定可能）</li>
</ul>
</li>
<li>ローカル: <code>uses: ./.github/actions/hello/</code>
<ul>
<li>先頭部分が.であることが目印</li>
<li>ルートディレクトリを起点にパスを記述する</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="compositeaction">CompositeAction<a hidden class="anchor" aria-hidden="true" href="#compositeaction">#</a></h3>
<ul>
<li>メタデータファイル(action.yml)が必要</li>
<li>メタデータ構文のワークフロー構文との違いや注意点
<ul>
<li>シェル指定が必須</li>
<li>githubコンテキストのeventプロパティの使用は避ける
<ul>
<li>アクションはトリガー指定ができないので、呼び出し元のワークフローによりeventの中身がガラリと変わるため</li>
</ul>
</li>
<li>variablesとsecretsは直接参照できない
<ul>
<li>inputとして渡す必要あり
<ul>
<li>secretsを渡したらログ出力時のマスクはしてくれる</li>
</ul>
</li>
</ul>
</li>
<li>環境変数のスコープはワークフローに準拠する
<ul>
<li>ワークフロー側で定義した環境変数は参照できるし、アクション側で書き出した環境変数はワークフロー側からも参照可能</li>
</ul>
</li>
<li>パーミッション定義できない
<ul>
<li>ワークフロー側で制御するようにする</li>
<li>つまり呼び出し側ワークフローでパーミッション定義を忘れると実行エラーが発生するので、どのようなパーミッションが必要かはREADMEなどに残しておくのがオススメ</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="アクション設計プラクティス">アクション設計プラクティス<a hidden class="anchor" aria-hidden="true" href="#アクション設計プラクティス">#</a></h3>
<ul>
<li>認知負荷の低減
<ul>
<li>利用者はコードが読みたいのではなく、アクションを使いたいだけ</li>
<li>なのでアクションの名前と概要はきちんとわかりやすいように書く（input/outputも）</li>
</ul>
</li>
<li><code>secrets.GITHUB_TOKEN</code>の取り方
<ul>
<li>アクションからsecretsは参照できないので<code>secrets.GITHUB_TOKEN</code>は参照できないが、<code>github.token</code>で同じ値を参照できる</li>
</ul>
</li>
<li>スクリプトの切り出し
<ul>
<li>内部ロジックが大きくなってきたらshファイルとして別で切り出すと良い</li>
<li>切り出したshファイルは、<code>GITHUB_ACTION_PATH</code>環境変数で実行する必要がある
<ul>
<li>run句に単純なshファイルへの相対パスを指定するだけでは実行できない</li>
</ul>
</li>
</ul>
</li>
<li>環境変数による暗黙的な依存の回避
<ul>
<li>ワークフローとアクションで相互に環境変数は参照できるが、必要な値はinputs/outputsで明示的に受け渡すようにするのが良い</li>
<li>コードが追いづらくなるのと、意図せず壊れてしまうリスクがある</li>
</ul>
</li>
<li>ロググループ化の活用
<ul>
<li>まず大前提としてきちんとログを出力する（デバッグ効率が圧倒的に良くなるため）</li>
<li>CompositeActionのログはステップごとに分割されないのでログを追うのが難しくなる</li>
<li>なのでロググループ化を活用する</li>
</ul>
</li>
</ul>
<h3 id="アクションとnodeバージョン">アクションとNodeバージョン<a hidden class="anchor" aria-hidden="true" href="#アクションとnodeバージョン">#</a></h3>
<ul>
<li>GitHubが提供する多くのアクションはJSで実装されている</li>
<li>Nodeバージョンが上がるとアクションのメジャーバージョンが上がることが多い</li>
<li>このバージョンアップ作業が地味に大変な作業&hellip;</li>
</ul>
<h2 id="7章-クリーンなリポジトリの維持">7章 クリーンなリポジトリの維持<a hidden class="anchor" aria-hidden="true" href="#7章-クリーンなリポジトリの維持">#</a></h2>
<h3 id="リポジトリルール">リポジトリルール<a hidden class="anchor" aria-hidden="true" href="#リポジトリルール">#</a></h3>
<ul>
<li>ブランチプロテクションルールを設定しよう</li>
<li>コードオーナーを設定して全てのコードにオーナーシップを維持しよう
<ul>
<li>自動でコードオーナーにレビュー依頼が飛ぶ</li>
</ul>
</li>
<li>シークレットスキャンを導入して、秘匿情報混入を検出しよう
<ul>
<li>コードやIssueの本文やコメントなどもチェックしてくれる</li>
<li>GitHubが定期的にチェックする（つまり事後）</li>
<li>プッシュプロテクションをEnableにすると、プッシュするタイミングでチェックが走る</li>
</ul>
</li>
</ul>
<h3 id="ドキュメント">ドキュメント<a hidden class="anchor" aria-hidden="true" href="#ドキュメント">#</a></h3>
<ul>
<li>READMEは読み手のことを考える</li>
<li>LICENSEは確認するようにする
<ul>
<li>MITは、責任とらないけど自由に使ってねくらいのニュアンス</li>
</ul>
</li>
<li>コミュニティヘルスファイル
<ul>
<li>CONTRIBUTING.md: コントリビューション方法のガイド（PRやIssueの出し方、コーディング規約）</li>
<li>CODE_OF_CONDUCT.md: 行動規範</li>
<li>SECURITY.md: 脆弱性報告方法など</li>
</ul>
</li>
</ul>
<h2 id="8章-dependabotによる依存関係バージョンアップ">8章 Dependabotによる依存関係バージョンアップ<a hidden class="anchor" aria-hidden="true" href="#8章-dependabotによる依存関係バージョンアップ">#</a></h2>
<ul>
<li>ソフトウェアは何もしないと壊れるので、変更し続ける必要がある
<ul>
<li>依存関係の管理には、検知・把握・実装・テストという活動が必要</li>
</ul>
</li>
<li>Dependabotには以下3つの依存関係の管理をサポートする機能がある
<ul>
<li>Dependabot version updates: 最新バージョンへの自動アップデート</li>
<li>Dependabot security updates: 脆弱性を含むバージョンの自動アップデート</li>
<li>Dependabot alerts: 脆弱性が含まれるバージョンのアラート通知</li>
</ul>
</li>
<li>ワークフローで実践
<ul>
<li>ブランチプロテクションルールを設定し、全てのステータスチェックを行ってからマージしたい場合
<ul>
<li>GitHub CLIのmergeコマンドに<code>--auto</code>をつけることで、全ワークフローの成功状態になった後に、自動でマージしてくれる</li>
</ul>
</li>
</ul>
</li>
<li>Dependabotが起動したワークフローは通常のsecretsへのアクセスができないので、Dependabot用のsecretsを登録する必要があるので注意
<ul>
<li>厄介なのが何もエラーが出ず、空文字で処理が進むので、頭の片隅に入れておくと良い</li>
</ul>
</li>
<li>dependabot/fetch-metadataアクションを活用する
<ul>
<li>Dependabotが起動するワークフローで使用可能で、バージョンアップ・依存関係の種類、パッケージエコシステムを取得できる</li>
<li>有効活用の例
<ul>
<li>パッチバージョンの場合は自動マージ</li>
<li>開発環境向けの変更は自動マージ</li>
<li>GHA向けの変更は自動マージ</li>
<li>このように少しでも手動対応量を減らすことで、少しでも楽をする</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="9章-github-releasesによるリリース自動化">9章 GitHub Releasesによるリリース自動化<a hidden class="anchor" aria-hidden="true" href="#9章-github-releasesによるリリース自動化">#</a></h2>
<ul>
<li>バージョニング
<ul>
<li>いつどんな変更が行われたのかをバージョンを併記してユーザーに知らせることができる</li>
<li>トラブル時はバージョン情報をやり取りすることで関係者間の意思疎通が楽になる</li>
<li>開発者としてもどのバージョンで不具合が発生したかがわかれば、修正が楽になる</li>
</ul>
</li>
<li>セマンティックバージョニング
<ul>
<li>メジャー.マイナー.パッチという構成のバージョニング方式</li>
<li>順序性だけでなく、後方互換性に関心を寄せているのが特徴</li>
<li>完璧ではない（後方互換性が個人の考え方やスキルに依存する点）が、有名であること視認性が高いことで、選択としては無難である</li>
</ul>
</li>
<li>Gitタグの保護はやっておこう（ブランチ保護と同じような感じ）
<ul>
<li>ReleasesがGitタグに依存しており、そのGitタグが削除された場合、リリースノートは下書き状態となってしまうため</li>
</ul>
</li>
</ul>
<h2 id="10章-github-packagesによるパッケージ管理">10章 GitHub Packagesによるパッケージ管理<a hidden class="anchor" aria-hidden="true" href="#10章-github-packagesによるパッケージ管理">#</a></h2>
<ul>
<li>パッケージエコシステム
<ul>
<li>npmやMavenなどの言語パッケージ、HomebrewなどのOSパッケージ、Dockerなどのコンテナイメージもパッケージの一種</li>
<li>ソフトウェアのインストール・管理（依存関係の把握、ライブラリが足りなければ自動でダウンロード、新しいバージョンの検知、最新版へのアップデート等）を容易にする</li>
<li>提供者はパッケージマネージャークライアントを通じてパッケージを作成・登録＆メタデータを提供し、利用者はパッケージマネージャークライアントを通じてパッケージを検索・取得・更新＆依存関係を解決する（そしてこの両者をつなぐのがパッケージレジストリ）</li>
</ul>
</li>
<li>ContainerRegistryの話がメインで、使いそうもないのでスキップ</li>
</ul>
<h2 id="11章-openid-connectによるセキュアなクラウド連携">11章 OpenID Connectによるセキュアなクラウド連携<a hidden class="anchor" aria-hidden="true" href="#11章-openid-connectによるセキュアなクラウド連携">#</a></h2>
<h3 id="クラウドプロバイダのクレデンシャル">クラウドプロバイダのクレデンシャル<a hidden class="anchor" aria-hidden="true" href="#クラウドプロバイダのクレデンシャル">#</a></h3>
<ul>
<li>クラウドプロバイダは誰がアクセスしようとしているかを「認証」によって判断する</li>
<li>クレデンシャルは、その認証に利用するもので、ユーザーIDとパスワードもその一種</li>
<li>認証する側が、アクセスキーやAPIキーといった呼び名のランダム文字列を発行し、それをクレデンシャルとして利用する</li>
<li>プログラムがリクエスト時にそのクレデンシャルを一緒に送信することで、認証と認証情報が正しければ正常レスポンスを受け取れるという仕組み</li>
<li>静的クレデンシャル
<ul>
<li>長期にわたって変更しないパスワードのようなクレデンシャルを静的クレデンシャルという</li>
<li>静的クレデンシャルは長命という欠点があり、漏洩した場合の被害が拡大しやすい</li>
</ul>
</li>
<li>一時クレデンシャル
<ul>
<li>こちらは必要なタイミングで都度払い出すので短命</li>
<li>ローテーション作業もないので運用も楽</li>
<li>OpenID Connectというプロトコルによって実現する</li>
</ul>
</li>
<li>クラウド連携のアンチパターン
<ul>
<li>静的クレデンシャルは使用してはいけない</li>
<li>かつてはそれしか選択肢がなかったので、記事を探すときは要注意</li>
</ul>
</li>
</ul>
<h3 id="openid-connectoidc">OpenID Connect(OIDC)<a hidden class="anchor" aria-hidden="true" href="#openid-connectoidc">#</a></h3>
<ul>
<li>これは複数の異なるドメインで認証結果を共有し、協調してサービスを提供するオープンなプロトコル（アイデンティ連携を実現する）</li>
<li>OAuth2.0を拡張する形で設計されている</li>
<li>利点として、GitHub上で静的クレデンシャルの管理が不要になる(一時クレデンシャルを取得するため)＋認証時にアクセス元を細かく制限できる（GHAの場合特定リポジトリのみに許可できる）</li>
</ul>
<h3 id="一時クレデンシャルの取得フロー">一時クレデンシャルの取得フロー<a hidden class="anchor" aria-hidden="true" href="#一時クレデンシャルの取得フロー">#</a></h3>
<ul>
<li>ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する</li>
</ul>
<ol>
<li>GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider)</li>
<li>OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ)</li>
<li>一時クレデンシャルで操作</li>
</ol>
<ul>
<li>大抵の処理は隠蔽されており、私たちは行う作業は以下の2つのみ（準備に若干手間はかかるがメリットが大きい）
<ul>
<li>クラウドプロバイダ側でOIDCに必要なコンポーネントを作成する</li>
<li>ワークフローへクラウドプロバイダの認証アクションを組み込む</li>
</ul>
</li>
</ul>
<h3 id="oidc-trustとcloud-roles">OIDC TrustとCloud Roles<a hidden class="anchor" aria-hidden="true" href="#oidc-trustとcloud-roles">#</a></h3>
<ul>
<li>クラウドプロバイダで準備するコンポーネントは以下の2つ
<ul>
<li><strong>OIDC Trust</strong>: クラウドプロバイダが信頼するOIDC Providerを設定(GitHub OIDC Provider)
<ul>
<li>OIDCトークンで一時クレデンシャルを取得できる理由は、クラウドプロバイダがOIDC Providerを信頼しているため（OIDC Trust）</li>
<li>OIDCトークンはJWT形式で、GitHub OIDC Providerの公開鍵を使って署名等の検証が行われる</li>
</ul>
</li>
<li><strong>Cloud Roles</strong>: 一時クレデンシャルのアクセス先とアクセス元を制御
<ul>
<li>一時クレデンシャルの「アクセス先」を管理する</li>
<li>AWSでいうIAMロールのこと</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="認証アクション">認証アクション<a hidden class="anchor" aria-hidden="true" href="#認証アクション">#</a></h3>
<ul>
<li>各クラウドプロバイダは公式で認証アクションを提供しているので、ワークフローからはそのアクションを呼び出すだけで、OIDCが扱える</li>
</ul>
<h3 id="検証作業のリスクヘッジ">検証作業のリスクヘッジ<a hidden class="anchor" aria-hidden="true" href="#検証作業のリスクヘッジ">#</a></h3>
<ul>
<li>プライベートリポジトリで試す</li>
<li>認証パラメータ(AWSアカウントIDやIAMロール名)はSecretsで管理する
<ul>
<li>これらクレデンシャルではないものの、ログ出力時にマスクされるので、謝ってパブリックリポジトリでワークフローを実行しても、第三者へ余計な情報が漏れない</li>
</ul>
</li>
</ul>
<h3 id="awsにおけるoidc利用準備と連携">AWSにおけるOIDC利用準備と連携<a hidden class="anchor" aria-hidden="true" href="#awsにおけるoidc利用準備と連携">#</a></h3>
<ul>
<li>以下の2つを作成する
<ul>
<li>OIDC Provider
<ul>
<li>AWSがGitHub OIDC Providerを信頼するように設定</li>
</ul>
</li>
<li>IAMロール
<ul>
<li>一時クレデンシャルのアクセス先とアクセス元を制御する</li>
</ul>
</li>
</ul>
</li>
<li>GHAワークフロー側での設定作業
<ul>
<li>Secrets登録
<ul>
<li>AWSアカウントID</li>
<li>IAMロール名</li>
</ul>
</li>
</ul>
</li>
<li>ワークフロー実装
<ul>
<li>permissions
<ul>
<li><code>id-token: write</code>の設定が必要
<ul>
<li>GitHub OIDC ProviderからOIDCトークン取得に必要</li>
</ul>
</li>
</ul>
</li>
<li>aws-actions/configure-aws-credentialsを利用
<ul>
<li>ロールARNとセッション名、デフォルトリージョンをパラメータとして指定する</li>
<li>セッション名は、トレーザビリティを目的に、AssumeRole APIに渡すパラメータ名であり、CloudTrailのセッション名として記録される
<ul>
<li>「誰が・いつ・どのジョブでこのセッションを作ったか分かる」ような情報を含めると便利</li>
<li>例：<code>&quot;${{ github.workflow }}-${{ github.run_id }}-${{ github.actor }}&quot;</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>CloudRolesのセキュアな運用
<ul>
<li>他のリポジトリからアクセスできないことを確認しておく</li>
<li>CloudRolesは目的ごとに分離する（必要最小限の権限だけ）</li>
<li>クラウドプロバイダの設定作業にIaCを導入する</li>
</ul>
</li>
</ul>
<h2 id="12章-コンテナオーケストレーションのデプロイメント">12章 コンテナオーケストレーションのデプロイメント<a hidden class="anchor" aria-hidden="true" href="#12章-コンテナオーケストレーションのデプロイメント">#</a></h2>
<ul>
<li>デプロイ自動化の流れ
<ul>
<li>コンテナビルドアクション：コンテナイメージのビルド＆プッシュ</li>
<li>コンテナデプロイアクション：タスク定義の書き換えとサービスの更新</li>
</ul>
</li>
<li>本番環境へのデプロイはルールを制限したい
<ul>
<li>Deployment branches and tagsを設定する
<ul>
<li>Environmentsからブランチ名パターンを登録することでパターン外のブランチでワークフローを起動できなくなる</li>
</ul>
</li>
<li>Required Reviewers
<ul>
<li>ワークフローの起動に承認を必須とする</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="デプロイメント設計">デプロイメント設計<a hidden class="anchor" aria-hidden="true" href="#デプロイメント設計">#</a></h3>
<ul>
<li>デプロイの設計では「ユーザー影響」と「ロールバック」の観点に着目する</li>
<li>ローリングアップデート
<ul>
<li>ECSのデプロイ方式</li>
<li>新しいバージョンへ少しずつ置き換える</li>
<li>無停止</li>
</ul>
</li>
<li>ロールバック
<ul>
<li>ローリングアップデートの場合は特別な仕組みはないので、リバートコミットを追加し、再デプロイする（あまり速くない）</li>
<li>人間が切り戻しを検知・判断するので、別途監視の仕組みが必要となる</li>
</ul>
</li>
</ul>
<h2 id="第14章-github-actionsの高度な使い方">第14章 GitHub Actionsの高度な使い方<a hidden class="anchor" aria-hidden="true" href="#第14章-github-actionsの高度な使い方">#</a></h2>
<h3 id="reusable-workflows">Reusable Workflows<a hidden class="anchor" aria-hidden="true" href="#reusable-workflows">#</a></h3>
<ul>
<li>アクションは比較的小さな処理をカプセル化するのに対し、Reusable Workflowsはワークフロー全体を丸ごとカプセル化する</li>
<li>パーミッション
<ul>
<li>パーミッション定義を省略した場合は呼び出し側ワークフローのパーミッションを暗黙的に継承する</li>
<li>呼び出し側より厳しくできるが、緩めることはできない
<ul>
<li>なので、呼び出し側ではジョブレベルでパーミッションを定義すると良い（Reusable Workflowsの権限が最小限になるため＋ドキュメンテーションとなり可読性が向上する）</li>
</ul>
</li>
</ul>
</li>
<li>コンテキスト
<ul>
<li>呼び出し側ワークフローのコンテキストを直接参照できる</li>
<li>ただしReusable Workflowsが制御できないgithub.eventプロパティを参照すると再利用性は低下するので注意が必要</li>
</ul>
</li>
<li>Secrets
<ul>
<li>呼び出し側ワークフローのコンテキストを直接参照できない</li>
<li>入力パラメータ経由で渡す or 呼び出し側で<code>secrets: inherit</code>を指定するとまとめて継承可能
<ul>
<li>暗黙的な継承となりコードが追いづらくなるので個別で入力パラメータとして渡すのが良い</li>
</ul>
</li>
</ul>
</li>
<li>環境変数
<ul>
<li>こちらも参照できないので入力パラメータ経由で渡す</li>
</ul>
</li>
</ul>
<h3 id="fromjson関数">fromJSON関数<a hidden class="anchor" aria-hidden="true" href="#fromjson関数">#</a></h3>
<ul>
<li>動的なワークフロー定義
<ul>
<li>事前にマトリクスを生成できない場合、fromJSON()をmatrixに指定することで動的にマトリクスを生成できる</li>
</ul>
</li>
<li>文字列の型変換
<ul>
<li>ワークフロー構文の環境変数はstring型として扱われてしまう</li>
<li>その際string型の文字列をnumber型やboolean型に変換できる</li>
</ul>
</li>
</ul>
<h3 id="エラーハンドリング">エラーハンドリング<a hidden class="anchor" aria-hidden="true" href="#エラーハンドリング">#</a></h3>
<ul>
<li>Continue on Error
<ul>
<li>デフォルトではエラーが発生するとその時点でワークフローが停止する</li>
<li><code>continue-on-error: true</code>を指定すると、エラーを握りつぶし、次の処理に進む</li>
<li>これを指定すると、途中でエラーが発生しても、ワークフロー自体は正常終了扱いされる</li>
<li>ログを見ない限りエラーには気づけないので、リカバリー不要な場合のみ使用する</li>
</ul>
</li>
<li>マトリックスのフェイルファスト
<ul>
<li>マトリックスを使うと複数のジョブが並列に起動する</li>
<li>途中でエラーが発生した場合、他のジョブが止まる</li>
<li><code>fail-fast: false</code>を指定することで他のジョブを継続可能とできる</li>
</ul>
</li>
</ul>
<h3 id="コンテキストによるフロー制御">コンテキストによるフロー制御<a hidden class="anchor" aria-hidden="true" href="#コンテキストによるフロー制御">#</a></h3>
<ul>
<li>終了状態を取得できるコンテキスト
<ul>
<li>stepsコンテキスト：ステップの終了状態を保持
<ul>
<li>outcomeプロパティはContinue on Error適用前の終了状態（つまり生情報）</li>
<li>conclusionプロパティはContinue on Error適用後の終了状態</li>
</ul>
</li>
<li>needsコンテキスト：（依存している）ジョブの終了状態を保持
<ul>
<li>resultプロパティのみ</li>
</ul>
</li>
</ul>
</li>
<li>コンテキストとステータスチェック関数の併用
<ul>
<li>「前のステップが失敗したら」という条件式を書きたい場合
<ul>
<li><code>if: ${{ failure() &amp;&amp; steps.stepName.outcome == 'failure' }}</code>とする必要がある</li>
<li>このようにステータスチェック関数とコンテキスト参照を併用する必要がある理由として、<code>failure()</code>が記述されていない場合、暗黙的に<code>success()</code>関数が存在すると解釈されるため</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="15章-github-actionsのセキュリティ">15章 GitHub Actionsのセキュリティ<a hidden class="anchor" aria-hidden="true" href="#15章-github-actionsのセキュリティ">#</a></h2>
<ul>
<li>この章では「ソフトウェアサプライチェーン」に着目する
<ul>
<li>ソフトウェアサプライチェーンとは、コード書いてから実行環境へリリースまでに含まれる一連のアクティビティを意味する</li>
</ul>
</li>
<li>GHAはさまざまなシステムと連携するため、強力な権限が集中するため、悪意ある人にとってはとても魅力な攻撃対象になる</li>
</ul>
<h3 id="セキュリティのcia">セキュリティのCIA<a hidden class="anchor" aria-hidden="true" href="#セキュリティのcia">#</a></h3>
<ul>
<li>CIAとは、機密性・完全性・可用性のこと</li>
<li>CIAの観点から、守るべき資産はコード・クレデンシャル・アーティファクトとなる</li>
<li>闇雲に対策するのではなく、利便性とのトレードオフとなる</li>
</ul>
<h3 id="セキュリティの設計原則">セキュリティの設計原則<a hidden class="anchor" aria-hidden="true" href="#セキュリティの設計原則">#</a></h3>
<ul>
<li>脅威を完全に排除することは難しいので、脅威の軽減を目標とする</li>
<li>アタックサーフェス＝攻撃される恐れのある場所を小さくする
<ul>
<li>シンプルな設計を意識する（複雑な設計では意図しないこれ↑を生みやすいので）</li>
</ul>
</li>
<li>複数のセキュリティレイヤを用意して、多層防御にする</li>
<li>最小権限
<ul>
<li>攻撃されても被害を小さくできる</li>
<li>一時クレデンシャルのような権限の行使に時間の制約があるようなものも有効だと思われる</li>
</ul>
</li>
</ul>
<h3 id="githubのサービス特性">Githubのサービス特性<a hidden class="anchor" aria-hidden="true" href="#githubのサービス特性">#</a></h3>
<ul>
<li>上記の設計原則を踏まえて考えていく</li>
<li>GitHubはデフォルトの設定は利便性重視なので注意する</li>
<li>コードをプッシュできる人はワークフローの実行ができるという仕様を理解する</li>
<li>悪意ある人もコントリビューション可能であることを認識する</li>
</ul>
<h3 id="サードパーティアクション">サードパーティアクション<a hidden class="anchor" aria-hidden="true" href="#サードパーティアクション">#</a></h3>
<ul>
<li>サードパーティのアクションがリポジトリのコードを参照できるかはパーミションによるが、ほとんどのワークフローではコードにチェックアウトするので、大半のアクションはコードを参照できる</li>
<li>サードパーティアクション導入時は、そのサードパーティを信頼するかを意識的に決断するようにする
<ul>
<li>本当に信頼して良いかを考えるクセをつけるのが重要</li>
</ul>
</li>
<li>リポジトリ設定で利用制限も可能</li>
<li>呼び出し時にコミットハッシュによる固定を行えば、アクションを不変リソースとして扱える
<ul>
<li>ハッシュ指定だけでは分かりづらいので、コメントでバージョン情報を併記しておくと分かりやすい</li>
</ul>
</li>
<li>筆者の考えとしては「ある程度の車輪の再発明は仕方ない」それくらいサードパーティアクションの使用は慎重になるべき</li>
</ul>
<h3 id="スクリプトインジェクション">スクリプトインジェクション<a hidden class="anchor" aria-hidden="true" href="#スクリプトインジェクション">#</a></h3>
<ul>
<li>外からやってくるデータ（例：PRのタイトル）に悪意あるスクリプトが仕込まれていた場合、それがワークフローの中で読み込まれてスクリプトとして実行されてしまうリスクがある</li>
<li>対策として、
<ul>
<li>中間環境変数による無害化
<ul>
<li><code>env: PR_TITLE: ${{ github.event.pull_request.title }}</code>というような形でスクリプトインジェクションを防げる</li>
<li>どのプロパティが危険かを正確に判断するのは困難なので、コンテキストは常に中間環境変数で参照するようにするのが確実で楽</li>
</ul>
</li>
<li>ShellCheckによる静的解析
<ul>
<li>Github-Hosted Runnerには最初からインストールされている</li>
<li>actionlintは内部的にShellCheckを実行していて、yamlに直接書いたスクリプトもチェックしてくれる</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="最小権限のパーミッション">最小権限のパーミッション<a hidden class="anchor" aria-hidden="true" href="#最小権限のパーミッション">#</a></h3>
<ul>
<li>パーミッションはpermissionキーで設定可能</li>
<li>省略可能で、省略した場合はコード参照が許可される</li>
<li>明示的な記述を習慣化することで、自然とパーミッションを意識するようになる
<ul>
<li>具体的には、
<ul>
<li>ワークフローレベルでのパーミッション無効化(<code>permissions: {}</code>)の設定を入れることで、コード参照すら明示的な許可が必要になる</li>
<li>各ジョブへ都度、必要なパーミッションを定義する</li>
</ul>
</li>
<li>面倒に見えるが、やってみると慣れるのは早い</li>
</ul>
</li>
</ul>
<h3 id="ジョブ分割によるパーミッションの分離">ジョブ分割によるパーミッションの分離<a hidden class="anchor" aria-hidden="true" href="#ジョブ分割によるパーミッションの分離">#</a></h3>
<ul>
<li>パーミッションのスコープはいくつかあるが、特に注意すべきなのが以下の4つ
<ul>
<li>contents: 改竄されたコードをプッシュされるリスク</li>
<li>packages: 悪意あるパッケージをパブリッシュされるリスク</li>
<li>actions: 別のワークフローを意図せず起動されるリスク</li>
<li>id-token: OIDCでクラウドプロバイダにアクセスされるリスク</li>
</ul>
</li>
<li>これらのパーミッションを複数扱う場合はジョブの分割を検討すると良い
<ul>
<li>パーミッションをジョブ単位で記述すれば、ジョブがセキュリティ境界となる</li>
</ul>
</li>
</ul>
<h3 id="シークレットマネジメント">シークレットマネジメント<a hidden class="anchor" aria-hidden="true" href="#シークレットマネジメント">#</a></h3>
<ul>
<li>まずはクレデンシャルの把握をすべき</li>
<li>最小権限・一時クレデンシャルを優先・定期的なローテーション</li>
</ul>
<h3 id="openid-connectハードニング">OpenID Connectハードニング<a hidden class="anchor" aria-hidden="true" href="#openid-connectハードニング">#</a></h3>
<ul>
<li>OpenID Connectを深掘りするパート</li>
<li>(再掲)一時クレデンシャルの取得フロー
<ul>
<li>ワークフローで以下の流れで、クラウドプロバイダから最終的に一時クレデンシャルを取得する
<ol>
<li>GitHub OIDC ProviderからOIDCトークンを取得(ワークフロー→GitHub OIDC Provider)</li>
<li>OIDCトークンと一時クレデンシャルを交換(GitHub OIDC Provider→クラウドプロバイダ)</li>
<li>一時クレデンシャルで操作</li>
</ol>
</li>
<li>IDトークン
<ul>
<li>上記の1のOIDCトークンと呼んでいるものはOIDCの世界ではIDトークンと呼ぶ</li>
<li>これには主体に認証情報を含んでおり、リポジトリやワークフローの情報が含まれている</li>
<li>これらの属性情報を受け取ったクラウドプロバイダ側で検証し、アクセス可否を判断している</li>
<li>IDトークンの実体は、JWTである
<ul>
<li>ヘッダ・ペイロード・署名をピリオド区切りでBase64URLエンコードしたもの</li>
<li>ペイロードのデータ構造は決まっており、JSONの各フィールドはクレームと呼ぶ</li>
<li>IDトークンにはいくつかの必須クレームがあり、この必須クレームがセキュリティ上重要となる</li>
</ul>
</li>
<li>IDトークンの検証フロー
<ul>
<li>ワークフローはGitHub OIDC Providerから取得したIDトークンをクラウドプロバイダに渡す</li>
<li>クラウドプロバイダはIDトークンの署名を検証し、JWTクレームを検証する</li>
<li>この検証に成功したら、一時クレデンシャルをワークフローに返送する</li>
</ul>
</li>
<li>IDトークンの署名検証
<ul>
<li>本当にGitHub OIDC Providerが発行したIDトークンなのか確認する</li>
<li>署名の検証には、GitHub OIDC Providerの公開鍵を探し出す必要がある</li>
<li>どこを探すかというと、OIDC Trust(AWSの場合はOpenID Connect Provider)にGitHub OIDC ProviderのURLを設定していて、このURLが公開鍵の検索に使用される（https://token.actions.githubusercontent.com）</li>
<li>注意点として、上記のURLは全アカウントで共通のため、アカウントやリポジトリの識別ができない（GitHubが生成したという内容しか検証できない）
<ul>
<li>そこでJWTクレーム検証でその部分を補う形で検証する</li>
</ul>
</li>
</ul>
</li>
<li>IDトークンのJWTクレーム検証
<ul>
<li>IDトークンの署名だけではGitHub利用者が誰でもアクセスできてしまうため、JWTクレームでも検証を行う</li>
<li>JWTクレーム検証はクラウドプロバイダによって異なるが、AWSではAssumeRoleポリシーのCondition定義に基づいて検証を行う</li>
<li><strong>subクレーム</strong>
<ul>
<li>もっとも重要な検証対象となる</li>
<li>認証された主体の識別子が格納される（一般的にはユーザーIDなど）</li>
<li>GitHub Actionsでは少し毛色が異なり、ワークフローの属性情報を連結した値が入る（アカウント名やリポジトリ名など）
<ul>
<li>ワークフローの実行方法によって値が異なるが、repo:<!-- raw HTML omitted -->/<!-- raw HTML omitted -->:のような文字列はどの方法でも含まれる</li>
<li>なのでアカウント名やリポジトリ名が正しいかの判断は可能</li>
</ul>
</li>
</ul>
</li>
<li><strong>GitHubのカスタムクレーム</strong>
<ul>
<li>IDトークンは拡張が認めらていて、任意のカスタムクレームを追加可能</li>
<li>クラウドプロバイダによってサポート状況が異なっているので注意（AWSはサポートしていない）</li>
</ul>
</li>
<li><strong>クラウドプロバイダのJWTクレーム検証設定</strong>
<ul>
<li>AssumeRoleポリシーのConditionに以下のように記述する
<ul>
<li><code>&quot;token.actions.githubusercontent.com:sub&quot;: &quot;repo:&lt;OWNER&gt;/&lt;REPO&gt;:*&quot;</code></li>
</ul>
</li>
<li>左辺のキーはsubクレームを指している</li>
<li>他の値もsubクレームで検証するとセキュリティがより強固になる</li>
</ul>
</li>
<li>Environmentsの検証
<ul>
<li>subクレームに含まれるEnvironmentsの値を検証することで、商用環境にアクセスできるのはレビュー済みのワークフローのみとしたいといった制御が可能</li>
</ul>
</li>
<li>JWTクレームの検証はOpenID Connectのキモであり、特にsubクレームは重要となる</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="16章-セキュリティのシフトレフト">16章 セキュリティのシフトレフト<a hidden class="anchor" aria-hidden="true" href="#16章-セキュリティのシフトレフト">#</a></h2>
<ul>
<li>セキュリティは後回しにしがちだが早めに取り組むのが良い戦略
<ul>
<li>これがシフトレフトという考え方（痛い目に遭うくらいなら早めに対処しよう）</li>
</ul>
</li>
<li>依存関係の脆弱性スキャン
<ul>
<li>最新に保ち続けられるならそれで十分だけど現実はそうもいかない</li>
<li>そこで活用したいのが依存関係の脆弱性を検出するサービス
<ul>
<li>Dependabot Alerts
<ul>
<li>依存関係の脆弱性を発見するとアラートを送信する</li>
<li>「新たなコードのプッシュでDependency Graphが更新された時（例えばpackage.jsonなどのファイルが更新された時と同意かな？）」と「脆弱性データベースであるGitHub Advisory Databaseに脆弱性が登録された時」のタイミングでリポジトリをチェックしてくれる</li>
</ul>
</li>
<li>Dependabot security updates
<ul>
<li>Alertsは情報提供で、これはプルリクエスト作成まで行ってくれるサービス</li>
<li>「security updates」は脆弱性のパッチを当てたバージョンへあげるもの（「version updates」の方は常に最新バージョンにあげるという違いがある）</li>
</ul>
</li>
<li>設定ファイルについて
<ul>
<li>.github/dependabot.ymlは、security updatesとversion updatesで共有される
<ul>
<li>共有されるということは除外ルールを書いたらどちらでも検知されない</li>
</ul>
</li>
<li>なので防御策として、Alertsを合わせて有効化しておくと良い（Alertsは設定ファイルに依存しない）そうすれば検出漏れを最小限にできる</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>シークレットスキャン
<ul>
<li>GitHubのシークレットスキャン機能は経済的理由で導入が困難な場合もある</li>
<li>SecretlintというDockerで動かせるAWSやGitHubなどの主要サービスのクレデンシャルを検出できる
<ul>
<li>これをGitHubActionsで動かすと尚良い</li>
<li>その際、検出された情報がログ出力されないように注意（<code>--maskSecrets</code>オプションで設定可能）</li>
</ul>
</li>
<li>途中からシークレットスキャンを導入する場合は全ヒストリーをスキャンするGitleaksというツールがある
<ul>
<li>これもDockerで動かせる</li>
</ul>
</li>
<li>git push前にスキャンするのがベター
<ul>
<li>.git/hooks/pre-commitファイルへシークレットスキャンコマンドを組み込むとコミット時にスキャンが実行あsれる</li>
<li>個々人で設定可能が必要であり、ストレスに感じる人もいるため、実際にやるかどうかは個人の判断に委ねると良い</li>
</ul>
</li>
</ul>
</li>
<li>アプリケーションスキャン
<ul>
<li>Static Application Security Testing(SAST)
<ul>
<li>コードスキャンしてセキュリティ問題を検出する（静的解析）</li>
<li>Goだと<a href="https://github.com/securego/gosec">securego/gosec: Go security checker</a>がそれみたい</li>
</ul>
</li>
<li>コンテナイメージの脆弱性スキャン
<ul>
<li>Trivyというツール</li>
<li>他にはコンテナレジストリでスキャン実施できる</li>
</ul>
</li>
</ul>
</li>
<li>Infrastructure as Codeセキュリティ
<ul>
<li>IaCで作業ミスは抑制できるが、セキュリティミスは防げない</li>
<li>そしてパッと見で正しく動作しているように見えるので意外と発見が難しい</li>
<li>セキュリティ設定ミスの防止
<ul>
<li>ここでもTrivyが活躍する</li>
<li>万事解決とまでいかないが、優れた出発点となる</li>
</ul>
</li>
<li>Policy as Code
<ul>
<li>Conftestというツールが使える</li>
<li>ポリシールールを設定ファイルに記述し、それを検証してくれる</li>
<li>これもDockerで動かせるのでワークフローに簡単に実行できる</li>
<li>選択肢の1つとして持っておくと良い</li>
</ul>
</li>
</ul>
</li>
<li>継続的なセキュリティの改善
<ul>
<li>誤検出と検出漏れはどうしても発生する（バランス・トレードオフ）</li>
<li>誤検出は想像異常にストレスが大きい</li>
<li>またツールを導入しすぎるたりして検出される問題が多すぎるとアラート疲れも発生する</li>
<li>時々立ち返って運用を見返すのが良い</li>
</ul>
</li>
</ul>
<h2 id="18章-継続的デリバリーの実践">18章 継続的デリバリーの実践<a hidden class="anchor" aria-hidden="true" href="#18章-継続的デリバリーの実践">#</a></h2>
<ul>
<li>組織パフォーマンスを研究しているGoogleのDORAというチーム曰く「ソフトウェアデリバリーパフォーマンスは組織パフォーマンスと高い相関がある」と学術的な方法で示したこと</li>
<li>DORAの研究では「スピードが速い組織ほど品質も高い」を提唱している</li>
<li>加えて、個人の幸福や組織文化にも寄与すると考えられている</li>
<li>この章では「継続的デリバリー」うまく実践するために、何ができるかを紹介していく</li>
</ul>
<h3 id="バージョン管理戦略">バージョン管理戦略<a hidden class="anchor" aria-hidden="true" href="#バージョン管理戦略">#</a></h3>
<ul>
<li>継続的デリバリーは適切なバージョン管理から始まる</li>
<li>大原則は「ソフトウェアの実行に必要なあらゆるものをバージョン管理する」
<ul>
<li>ソースコードだけではなく、テスト・ビルド・デプロイ・データベースマイグレーション・運用などのスクリプト・インフラ設定もバージョン管理の対象（つまりクレデンシャル以外）</li>
</ul>
</li>
<li>1日に1回はデフォルトブランチにマージする短命なブランチ運用＝トランクベース開発をすることで、コード変更量が小さいのでレビューしやすかったりコンフリクトが発生しづらかったりする
<ul>
<li>実装途中の機能を一時的に無効化したい場合は「フィーチャートグル」を使えば良い</li>
<li>詳細: <a href="https://martinfowler.com/articles/feature-toggles.html">機能トグル（別名機能フラグ）</a></li>
</ul>
</li>
</ul>
<h3 id="テスト戦略">テスト戦略<a hidden class="anchor" aria-hidden="true" href="#テスト戦略">#</a></h3>
<ul>
<li>CDの品質改善では、4章で説明した自動テストが重要な役割を担う</li>
<li>それ以外の異なる観点を提供するものとして、以下の2つがある</li>
</ul>
<h4 id="探索的テスト">探索的テスト<a hidden class="anchor" aria-hidden="true" href="#探索的テスト">#</a></h4>
<ul>
<li>自動化できないテストのこと</li>
<li>テストの目的は「調査」と「検証」がある</li>
<li>自動テストは記事の問題を「検証「することで、探索的テストは人間が手動で未知の問題を「調査」すること（目的が異なる）</li>
</ul>
<h4 id="testing-in-production">Testing in Production<a hidden class="anchor" aria-hidden="true" href="#testing-in-production">#</a></h4>
<ul>
<li>リリース後も本番環境でテストする</li>
<li>A/Bテストやシンセティックテストなど</li>
</ul>
<h3 id="リリース戦略">リリース戦略<a hidden class="anchor" aria-hidden="true" href="#リリース戦略">#</a></h3>
<ul>
<li>恐怖の克服
<ul>
<li>いくら自動化しても経験しないと恐怖は薄れない</li>
<li>自分の手でリリースすることが大切</li>
</ul>
</li>
<li>ロールバック
<ul>
<li>ロールバックも全員が慣れておく</li>
<li>頻度が少ないためにやり方を知らない人がいるので手順を周知し、平時にロールバックの練習をしておく</li>
</ul>
</li>
<li>デプロイとリリースの分離
<ul>
<li>分離していない場合にデプロイに問題があった時は全ユーザーに影響がある</li>
<li>分離する方法として、デプロイ後にユーザートラフィックを少しずつ新しい環境に流す「カナリアリリース」がある</li>
</ul>
</li>
</ul>
<h3 id="データベースの変更管理">データベースの変更管理<a hidden class="anchor" aria-hidden="true" href="#データベースの変更管理">#</a></h3>
<ul>
<li>手作業でデータベースコマンドを実行してはダメ</li>
<li>マイグレーションスクリプト経由で実行すると、ヒューマンエラーも発生しない
<ul>
<li>ロールバック用のスクリプトも用意するようにする</li>
</ul>
</li>
</ul>
<h3 id="iacの変更管理">IaCの変更管理<a hidden class="anchor" aria-hidden="true" href="#iacの変更管理">#</a></h3>
<ul>
<li>IaCはソフトウェアとライフサイクルが異なるため、固有の考慮点が存在する</li>
<li>ツールにドライ欄があるならそれを使用する
<ul>
<li>毎回手動実行は大変なので、プルリクエスト作成時に自動で実行し、それをコメントに貼り付ける</li>
</ul>
</li>
<li>「本番環境への適用はデフォルトブランチにマージした時のみ」という規律を設けるべき</li>
<li>IaCはローカルからの変更は事故が起きやすいので止める</li>
<li>実行環境は強力な権限が必要なので、絶対消されてはいけないDB等のリソース削除を禁止したり、権限昇格なIAM操作を禁止すべき</li>
<li>構成ドリフト（実態とコードの差分がある状態）は定期的にドライランを実行して通知させよう</li>
</ul>
<h3 id="疎結合なアーキテクチャ">疎結合なアーキテクチャ<a hidden class="anchor" aria-hidden="true" href="#疎結合なアーキテクチャ">#</a></h3>
<ul>
<li>疎結合はCDがとても実践しやすい</li>
<li>テストやデプロイの容易性</li>
</ul>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share GitHub CICD実践ガイド on x"
            href="https://x.com/intent/tweet/?text=GitHub%20CICD%e5%ae%9f%e8%b7%b5%e3%82%ac%e3%82%a4%e3%83%89&amp;url=http%3a%2f%2flocalhost%3a1313%2fmy-hugo-blog%2fposts%2f010_github_cicd%25E5%25AE%259F%25E8%25B7%25B5%25E3%2582%25AC%25E3%2582%25A4%25E3%2583%2589%2f&amp;hashtags=">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share GitHub CICD実践ガイド on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fmy-hugo-blog%2fposts%2f010_github_cicd%25E5%25AE%259F%25E8%25B7%25B5%25E3%2582%25AC%25E3%2582%25A4%25E3%2583%2589%2f&amp;title=GitHub%20CICD%e5%ae%9f%e8%b7%b5%e3%82%ac%e3%82%a4%e3%83%89&amp;summary=GitHub%20CICD%e5%ae%9f%e8%b7%b5%e3%82%ac%e3%82%a4%e3%83%89&amp;source=http%3a%2f%2flocalhost%3a1313%2fmy-hugo-blog%2fposts%2f010_github_cicd%25E5%25AE%259F%25E8%25B7%25B5%25E3%2582%25AC%25E3%2582%25A4%25E3%2583%2589%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share GitHub CICD実践ガイド on reddit"
            href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fmy-hugo-blog%2fposts%2f010_github_cicd%25E5%25AE%259F%25E8%25B7%25B5%25E3%2582%25AC%25E3%2582%25A4%25E3%2583%2589%2f&title=GitHub%20CICD%e5%ae%9f%e8%b7%b5%e3%82%ac%e3%82%a4%e3%83%89">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share GitHub CICD実践ガイド on facebook"
            href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fmy-hugo-blog%2fposts%2f010_github_cicd%25E5%25AE%259F%25E8%25B7%25B5%25E3%2582%25AC%25E3%2582%25A4%25E3%2583%2589%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share GitHub CICD実践ガイド on whatsapp"
            href="https://api.whatsapp.com/send?text=GitHub%20CICD%e5%ae%9f%e8%b7%b5%e3%82%ac%e3%82%a4%e3%83%89%20-%20http%3a%2f%2flocalhost%3a1313%2fmy-hugo-blog%2fposts%2f010_github_cicd%25E5%25AE%259F%25E8%25B7%25B5%25E3%2582%25AC%25E3%2582%25A4%25E3%2583%2589%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share GitHub CICD実践ガイド on telegram"
            href="https://telegram.me/share/url?text=GitHub%20CICD%e5%ae%9f%e8%b7%b5%e3%82%ac%e3%82%a4%e3%83%89&amp;url=http%3a%2f%2flocalhost%3a1313%2fmy-hugo-blog%2fposts%2f010_github_cicd%25E5%25AE%259F%25E8%25B7%25B5%25E3%2582%25AC%25E3%2582%25A4%25E3%2583%2589%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share GitHub CICD実践ガイド on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=GitHub%20CICD%e5%ae%9f%e8%b7%b5%e3%82%ac%e3%82%a4%e3%83%89&u=http%3a%2f%2flocalhost%3a1313%2fmy-hugo-blog%2fposts%2f010_github_cicd%25E5%25AE%259F%25E8%25B7%25B5%25E3%2582%25AC%25E3%2582%25A4%25E3%2583%2589%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/my-hugo-blog/">nyuusen blog</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
